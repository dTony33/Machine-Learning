{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dTony33/Machine-Learning/blob/main/Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0r3zeKdIuib8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "from keras import datasets, layers, models\n",
        "from keras.optimizers import SGD, Adam, RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6LYNgOeuiYe"
      },
      "outputs": [],
      "source": [
        "(x_mnist_train,y_mnist_train),(x_mnist_test,y_mnist_test) = datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpF2A8oFuiVu",
        "outputId": "20a38c03-b30f-4830-e75c-c72d5aecf24b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "uint8\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "uint8\n"
          ]
        }
      ],
      "source": [
        "print(x_mnist_train.dtype)\n",
        "print(x_mnist_train.shape)\n",
        "print(y_mnist_train.shape)\n",
        "print(y_mnist_train.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iir6ccTizeyx"
      },
      "outputs": [],
      "source": [
        "x_mnist_train = x_mnist_train.astype('float32')\n",
        "x_mnist_test = x_mnist_test.astype('float32')\n",
        "x_mnist_train /= 255\n",
        "x_mnist_test /= 255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRDCXJUpzcdZ"
      },
      "outputs": [],
      "source": [
        "x_mnist_train = x_mnist_train[:,:,:,np.newaxis]\n",
        "x_mnist_test = x_mnist_test[:,:,:,np.newaxis]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85TcnPwD2ADl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXoDozLDuiTQ"
      },
      "outputs": [],
      "source": [
        "y_mnist_train = np_utils.to_categorical(y_mnist_train,10)\n",
        "y_mnist_test = np_utils.to_categorical(y_mnist_test,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cavsVv-T95Dh",
        "outputId": "8b02097a-7fca-40fc-e5dc-2eac34ec5da1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_mnist_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgz15bgxuiQZ"
      },
      "outputs": [],
      "source": [
        "cnn_increase = models.Sequential()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KRkIkTTuiN5",
        "outputId": "3708ef01-5f4a-4941-ffa9-47075651bf79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_30 (Conv2D)          (None, 28, 28, 6)         156       \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 28, 28, 7)         1057      \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 14, 14, 7)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 14, 14, 8)         1408      \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 14, 14, 9)         1809      \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 7, 7, 9)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 7, 7, 10)          2260      \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 7, 7, 11)          2761      \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 4, 4, 11)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 4, 4, 12)          3312      \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 4, 4, 13)          3913      \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 2, 2, 13)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 2, 2, 14)          4564      \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 2, 2, 15)          5265      \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 60)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                610       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,115\n",
            "Trainable params: 27,115\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.layers.reshaping.flatten import Flatten\n",
        "cnn_increase.add(layers.Conv2D(6, kernel_size=(5,5), padding = \"same\", input_shape = (28,28,1)))\n",
        "cnn_increase.add(layers.Conv2D(7, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_increase.add(layers.MaxPooling2D(pool_size =(5,5),strides=2, padding = \"same\"))\n",
        "cnn_increase.add(layers.Conv2D(8, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_increase.add(layers.Conv2D(9, kernel_size=(5,5), padding = \"same\"))\n",
        "\n",
        "cnn_increase.add(layers.MaxPooling2D(pool_size =(5,5),strides=2, padding = \"same\"))\n",
        "cnn_increase.add(layers.Conv2D(10, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_increase.add(layers.Conv2D(11, kernel_size=(5,5), padding = \"same\"))\n",
        "\n",
        "cnn_increase.add(layers.MaxPooling2D(pool_size =(5,5),strides=2, padding = \"same\"))\n",
        "cnn_increase.add(layers.Conv2D(12, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_increase.add(layers.Conv2D(13, kernel_size=(5,5), padding = \"same\"))\n",
        "\n",
        "cnn_increase.add(layers.MaxPooling2D(pool_size =(5,5),strides=2, padding = \"same\"))\n",
        "cnn_increase.add(layers.Conv2D(14, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_increase.add(layers.Conv2D(15, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_increase.add(layers.Flatten())\n",
        "cnn_increase.add(layers.Dense(10, activation= 'softmax'))\n",
        "cnn_increase.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VeqX3k37qz1"
      },
      "outputs": [],
      "source": [
        "# from keras.optimizers import SGD, Adam, RMSprop\n",
        "# optimizers_list = [SGD(),Adam(),RMSprop()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Spu6RT2w9UKE"
      },
      "outputs": [],
      "source": [
        "# for k in optimizers_list:\n",
        "#   print(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXuIUjcuuiLM",
        "outputId": "b1bd02c2-2e22-4f17-8f1b-cf952985a043"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "192/192 [==============================] - 33s 169ms/step - loss: 1.0147 - accuracy: 0.6710 - val_loss: 0.5994 - val_accuracy: 0.8013\n",
            "Epoch 2/25\n",
            "192/192 [==============================] - 35s 183ms/step - loss: 0.4683 - accuracy: 0.8531 - val_loss: 0.3168 - val_accuracy: 0.8994\n",
            "Epoch 3/25\n",
            "192/192 [==============================] - 35s 183ms/step - loss: 0.2667 - accuracy: 0.9166 - val_loss: 0.1999 - val_accuracy: 0.9384\n",
            "Epoch 4/25\n",
            "192/192 [==============================] - 36s 189ms/step - loss: 0.1915 - accuracy: 0.9397 - val_loss: 0.1531 - val_accuracy: 0.9543\n",
            "Epoch 5/25\n",
            "192/192 [==============================] - 38s 196ms/step - loss: 0.1542 - accuracy: 0.9516 - val_loss: 0.1587 - val_accuracy: 0.9513\n",
            "Epoch 6/25\n",
            "192/192 [==============================] - 39s 203ms/step - loss: 0.5166 - accuracy: 0.8648 - val_loss: 0.1759 - val_accuracy: 0.9502\n",
            "Epoch 7/25\n",
            "192/192 [==============================] - 38s 198ms/step - loss: 0.1455 - accuracy: 0.9555 - val_loss: 0.1335 - val_accuracy: 0.9617\n",
            "Epoch 8/25\n",
            "192/192 [==============================] - 38s 200ms/step - loss: 0.1167 - accuracy: 0.9643 - val_loss: 0.1214 - val_accuracy: 0.9650\n",
            "Epoch 9/25\n",
            "192/192 [==============================] - 41s 212ms/step - loss: 0.1046 - accuracy: 0.9675 - val_loss: 0.1038 - val_accuracy: 0.9696\n",
            "Epoch 10/25\n",
            "192/192 [==============================] - 39s 205ms/step - loss: 0.0938 - accuracy: 0.9708 - val_loss: 0.0947 - val_accuracy: 0.9742\n",
            "Epoch 11/25\n",
            "192/192 [==============================] - 37s 195ms/step - loss: 0.0893 - accuracy: 0.9719 - val_loss: 0.1107 - val_accuracy: 0.9694\n",
            "Epoch 12/25\n",
            "192/192 [==============================] - 39s 203ms/step - loss: 0.0813 - accuracy: 0.9741 - val_loss: 0.0956 - val_accuracy: 0.9712\n",
            "Epoch 13/25\n",
            "192/192 [==============================] - 42s 219ms/step - loss: 0.0765 - accuracy: 0.9753 - val_loss: 0.0831 - val_accuracy: 0.9764\n",
            "Epoch 14/25\n",
            "192/192 [==============================] - 40s 210ms/step - loss: 0.0731 - accuracy: 0.9766 - val_loss: 0.0834 - val_accuracy: 0.9755\n",
            "Epoch 15/25\n",
            "192/192 [==============================] - 37s 195ms/step - loss: 0.0691 - accuracy: 0.9785 - val_loss: 0.0799 - val_accuracy: 0.9780\n",
            "Epoch 16/25\n",
            "192/192 [==============================] - 36s 188ms/step - loss: 0.0657 - accuracy: 0.9793 - val_loss: 0.0787 - val_accuracy: 0.9764\n",
            "Epoch 17/25\n",
            "192/192 [==============================] - 36s 189ms/step - loss: 0.0624 - accuracy: 0.9802 - val_loss: 0.0741 - val_accuracy: 0.9787\n",
            "Epoch 18/25\n",
            "192/192 [==============================] - 36s 190ms/step - loss: 0.0627 - accuracy: 0.9800 - val_loss: 0.0745 - val_accuracy: 0.9789\n",
            "Epoch 19/25\n",
            "192/192 [==============================] - 37s 191ms/step - loss: 0.0580 - accuracy: 0.9816 - val_loss: 0.0690 - val_accuracy: 0.9797\n",
            "Epoch 20/25\n",
            "192/192 [==============================] - 37s 191ms/step - loss: 0.0556 - accuracy: 0.9821 - val_loss: 0.0681 - val_accuracy: 0.9802\n",
            "Epoch 21/25\n",
            "192/192 [==============================] - 37s 191ms/step - loss: 0.0529 - accuracy: 0.9834 - val_loss: 0.0698 - val_accuracy: 0.9795\n",
            "Epoch 22/25\n",
            "192/192 [==============================] - 37s 191ms/step - loss: 0.0513 - accuracy: 0.9843 - val_loss: 0.0637 - val_accuracy: 0.9813\n",
            "Epoch 23/25\n",
            "192/192 [==============================] - 38s 196ms/step - loss: 0.0505 - accuracy: 0.9839 - val_loss: 0.0688 - val_accuracy: 0.9802\n",
            "Epoch 24/25\n",
            "192/192 [==============================] - 37s 193ms/step - loss: 0.0493 - accuracy: 0.9844 - val_loss: 0.0615 - val_accuracy: 0.9819\n",
            "Epoch 25/25\n",
            "192/192 [==============================] - 36s 190ms/step - loss: 0.0466 - accuracy: 0.9851 - val_loss: 0.0707 - val_accuracy: 0.9785\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.0597 - accuracy: 0.9810\n",
            "0.01 250 SGD 0.9810000061988831\n",
            "Epoch 1/25\n",
            "96/96 [==============================] - 32s 333ms/step - loss: 0.0411 - accuracy: 0.9870 - val_loss: 0.0649 - val_accuracy: 0.9812\n",
            "Epoch 2/25\n",
            "96/96 [==============================] - 32s 328ms/step - loss: 0.0401 - accuracy: 0.9874 - val_loss: 0.0599 - val_accuracy: 0.9835\n",
            "Epoch 3/25\n",
            "96/96 [==============================] - 35s 364ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.0589 - val_accuracy: 0.9832\n",
            "Epoch 4/25\n",
            "96/96 [==============================] - 38s 398ms/step - loss: 0.0388 - accuracy: 0.9876 - val_loss: 0.0571 - val_accuracy: 0.9835\n",
            "Epoch 5/25\n",
            "96/96 [==============================] - 38s 394ms/step - loss: 0.0379 - accuracy: 0.9880 - val_loss: 0.0587 - val_accuracy: 0.9824\n",
            "Epoch 6/25\n",
            "96/96 [==============================] - 38s 393ms/step - loss: 0.0370 - accuracy: 0.9883 - val_loss: 0.0585 - val_accuracy: 0.9835\n",
            "Epoch 7/25\n",
            "96/96 [==============================] - 39s 403ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 0.0604 - val_accuracy: 0.9824\n",
            "Epoch 8/25\n",
            "96/96 [==============================] - 38s 400ms/step - loss: 0.0365 - accuracy: 0.9887 - val_loss: 0.0583 - val_accuracy: 0.9835\n",
            "Epoch 9/25\n",
            "96/96 [==============================] - 38s 396ms/step - loss: 0.0362 - accuracy: 0.9882 - val_loss: 0.0585 - val_accuracy: 0.9837\n",
            "Epoch 10/25\n",
            "96/96 [==============================] - 39s 409ms/step - loss: 0.0347 - accuracy: 0.9891 - val_loss: 0.0588 - val_accuracy: 0.9831\n",
            "Epoch 11/25\n",
            "96/96 [==============================] - 38s 399ms/step - loss: 0.0346 - accuracy: 0.9892 - val_loss: 0.0600 - val_accuracy: 0.9829\n",
            "Epoch 12/25\n",
            "96/96 [==============================] - 40s 421ms/step - loss: 0.0347 - accuracy: 0.9891 - val_loss: 0.0569 - val_accuracy: 0.9835\n",
            "Epoch 13/25\n",
            "96/96 [==============================] - 38s 394ms/step - loss: 0.0337 - accuracy: 0.9894 - val_loss: 0.0594 - val_accuracy: 0.9828\n",
            "Epoch 14/25\n",
            "96/96 [==============================] - 38s 395ms/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 0.0570 - val_accuracy: 0.9842\n",
            "Epoch 15/25\n",
            "96/96 [==============================] - 38s 401ms/step - loss: 0.0323 - accuracy: 0.9895 - val_loss: 0.0721 - val_accuracy: 0.9801\n",
            "Epoch 16/25\n",
            "96/96 [==============================] - 38s 400ms/step - loss: 0.0325 - accuracy: 0.9894 - val_loss: 0.0596 - val_accuracy: 0.9843\n",
            "Epoch 17/25\n",
            "96/96 [==============================] - 38s 395ms/step - loss: 0.0317 - accuracy: 0.9898 - val_loss: 0.0571 - val_accuracy: 0.9843\n",
            "Epoch 18/25\n",
            "96/96 [==============================] - 37s 390ms/step - loss: 0.0307 - accuracy: 0.9906 - val_loss: 0.0555 - val_accuracy: 0.9840\n",
            "Epoch 19/25\n",
            "96/96 [==============================] - 34s 353ms/step - loss: 0.0308 - accuracy: 0.9901 - val_loss: 0.0587 - val_accuracy: 0.9836\n",
            "Epoch 20/25\n",
            "96/96 [==============================] - 44s 459ms/step - loss: 0.0308 - accuracy: 0.9894 - val_loss: 0.0591 - val_accuracy: 0.9837\n",
            "Epoch 21/25\n",
            "96/96 [==============================] - 43s 451ms/step - loss: 0.0301 - accuracy: 0.9907 - val_loss: 0.0604 - val_accuracy: 0.9822\n",
            "Epoch 22/25\n",
            "96/96 [==============================] - 38s 398ms/step - loss: 0.0296 - accuracy: 0.9905 - val_loss: 0.0620 - val_accuracy: 0.9829\n",
            "Epoch 23/25\n",
            "96/96 [==============================] - 37s 390ms/step - loss: 0.0284 - accuracy: 0.9908 - val_loss: 0.0576 - val_accuracy: 0.9834\n",
            "Epoch 24/25\n",
            "96/96 [==============================] - 38s 394ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 0.0584 - val_accuracy: 0.9830\n",
            "Epoch 25/25\n",
            "96/96 [==============================] - 44s 460ms/step - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.0603 - val_accuracy: 0.9829\n",
            "313/313 [==============================] - 10s 30ms/step - loss: 0.0502 - accuracy: 0.9861\n",
            "0.01 500 SGD 0.9861000180244446\n",
            "Epoch 1/25\n",
            "64/64 [==============================] - 35s 539ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 0.0549 - val_accuracy: 0.9848\n",
            "Epoch 2/25\n",
            "64/64 [==============================] - 38s 600ms/step - loss: 0.0262 - accuracy: 0.9916 - val_loss: 0.0541 - val_accuracy: 0.9851\n",
            "Epoch 3/25\n",
            "64/64 [==============================] - 37s 587ms/step - loss: 0.0260 - accuracy: 0.9922 - val_loss: 0.0558 - val_accuracy: 0.9850\n",
            "Epoch 4/25\n",
            "64/64 [==============================] - 37s 585ms/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.0560 - val_accuracy: 0.9838\n",
            "Epoch 5/25\n",
            "64/64 [==============================] - 37s 578ms/step - loss: 0.0254 - accuracy: 0.9919 - val_loss: 0.0543 - val_accuracy: 0.9852\n",
            "Epoch 6/25\n",
            "64/64 [==============================] - 38s 589ms/step - loss: 0.0257 - accuracy: 0.9917 - val_loss: 0.0552 - val_accuracy: 0.9846\n",
            "Epoch 7/25\n",
            "64/64 [==============================] - 37s 575ms/step - loss: 0.0254 - accuracy: 0.9921 - val_loss: 0.0551 - val_accuracy: 0.9844\n",
            "Epoch 8/25\n",
            "64/64 [==============================] - 37s 580ms/step - loss: 0.0248 - accuracy: 0.9924 - val_loss: 0.0544 - val_accuracy: 0.9850\n",
            "Epoch 9/25\n",
            "64/64 [==============================] - 38s 598ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.0568 - val_accuracy: 0.9843\n",
            "Epoch 10/25\n",
            "64/64 [==============================] - 36s 570ms/step - loss: 0.0241 - accuracy: 0.9924 - val_loss: 0.0550 - val_accuracy: 0.9845\n",
            "Epoch 11/25\n",
            "64/64 [==============================] - 37s 575ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.0546 - val_accuracy: 0.9847\n",
            "Epoch 12/25\n",
            "64/64 [==============================] - 38s 590ms/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.0587 - val_accuracy: 0.9845\n",
            "Epoch 13/25\n",
            "64/64 [==============================] - 37s 573ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.0570 - val_accuracy: 0.9843\n",
            "Epoch 14/25\n",
            "64/64 [==============================] - 37s 587ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
            "Epoch 15/25\n",
            "64/64 [==============================] - 37s 580ms/step - loss: 0.0229 - accuracy: 0.9927 - val_loss: 0.0553 - val_accuracy: 0.9852\n",
            "Epoch 16/25\n",
            "64/64 [==============================] - 37s 577ms/step - loss: 0.0223 - accuracy: 0.9929 - val_loss: 0.0545 - val_accuracy: 0.9853\n",
            "Epoch 17/25\n",
            "64/64 [==============================] - 36s 564ms/step - loss: 0.0226 - accuracy: 0.9928 - val_loss: 0.0549 - val_accuracy: 0.9845\n",
            "Epoch 18/25\n",
            "64/64 [==============================] - 37s 571ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 0.0548 - val_accuracy: 0.9857\n",
            "Epoch 19/25\n",
            "64/64 [==============================] - 37s 575ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.0579 - val_accuracy: 0.9841\n",
            "Epoch 20/25\n",
            "64/64 [==============================] - 43s 675ms/step - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.0561 - val_accuracy: 0.9837\n",
            "Epoch 21/25\n",
            "64/64 [==============================] - 40s 624ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 0.0605 - val_accuracy: 0.9827\n",
            "Epoch 22/25\n",
            "64/64 [==============================] - 39s 617ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0638 - val_accuracy: 0.9829\n",
            "Epoch 23/25\n",
            "64/64 [==============================] - 38s 590ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.0601 - val_accuracy: 0.9836\n",
            "Epoch 24/25\n",
            "64/64 [==============================] - 37s 575ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.0592 - val_accuracy: 0.9844\n",
            "Epoch 25/25\n",
            "64/64 [==============================] - 37s 582ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.0560 - val_accuracy: 0.9843\n",
            "313/313 [==============================] - 10s 31ms/step - loss: 0.0482 - accuracy: 0.9860\n",
            "0.01 750 SGD 0.9860000014305115\n",
            "Epoch 1/25\n",
            "192/192 [==============================] - 41s 208ms/step - loss: nan - accuracy: 0.1078 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "192/192 [==============================] - 41s 212ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "192/192 [==============================] - 41s 212ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "192/192 [==============================] - 41s 216ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "192/192 [==============================] - 41s 215ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "192/192 [==============================] - 41s 213ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "192/192 [==============================] - 41s 215ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "192/192 [==============================] - 41s 213ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "192/192 [==============================] - 41s 214ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "192/192 [==============================] - 41s 213ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "192/192 [==============================] - 41s 214ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "192/192 [==============================] - 42s 217ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "192/192 [==============================] - 41s 213ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "192/192 [==============================] - 41s 211ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "192/192 [==============================] - 41s 213ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "192/192 [==============================] - 40s 210ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "192/192 [==============================] - 42s 218ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "192/192 [==============================] - 41s 214ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "192/192 [==============================] - 41s 215ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "192/192 [==============================] - 42s 221ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "192/192 [==============================] - 42s 217ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "192/192 [==============================] - 41s 212ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "192/192 [==============================] - 41s 216ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "192/192 [==============================] - 41s 215ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "192/192 [==============================] - 41s 212ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 28ms/step - loss: nan - accuracy: 0.0980\n",
            "0.1 250 SGD 0.09799999743700027\n",
            "Epoch 1/25\n",
            "96/96 [==============================] - 36s 366ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "96/96 [==============================] - 38s 393ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "96/96 [==============================] - 37s 384ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "96/96 [==============================] - 36s 378ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "96/96 [==============================] - 37s 388ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "96/96 [==============================] - 36s 375ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "96/96 [==============================] - 36s 378ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "96/96 [==============================] - 36s 378ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "96/96 [==============================] - 37s 387ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "96/96 [==============================] - 36s 379ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "96/96 [==============================] - 36s 379ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "96/96 [==============================] - 37s 382ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "96/96 [==============================] - 36s 380ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "96/96 [==============================] - 36s 375ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "96/96 [==============================] - 38s 394ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "96/96 [==============================] - 36s 376ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "96/96 [==============================] - 39s 409ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "96/96 [==============================] - 38s 397ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "96/96 [==============================] - 37s 391ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "96/96 [==============================] - 37s 382ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "96/96 [==============================] - 42s 440ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "96/96 [==============================] - 36s 380ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "96/96 [==============================] - 36s 379ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "96/96 [==============================] - 36s 377ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "96/96 [==============================] - 38s 391ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 28ms/step - loss: nan - accuracy: 0.0980\n",
            "0.1 500 SGD 0.09799999743700027\n",
            "Epoch 1/25\n",
            "64/64 [==============================] - 34s 516ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "64/64 [==============================] - 35s 554ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "64/64 [==============================] - 35s 545ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "64/64 [==============================] - 35s 545ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "64/64 [==============================] - 35s 541ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "64/64 [==============================] - 35s 548ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "64/64 [==============================] - 35s 548ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "64/64 [==============================] - 35s 549ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "64/64 [==============================] - 35s 555ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "64/64 [==============================] - 35s 543ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "64/64 [==============================] - 35s 547ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "64/64 [==============================] - 35s 542ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "64/64 [==============================] - 35s 555ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "64/64 [==============================] - 34s 533ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "64/64 [==============================] - 35s 551ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "64/64 [==============================] - 35s 544ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "64/64 [==============================] - 36s 558ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "64/64 [==============================] - 35s 543ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "64/64 [==============================] - 34s 538ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "64/64 [==============================] - 35s 550ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "64/64 [==============================] - 35s 541ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "64/64 [==============================] - 35s 540ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "64/64 [==============================] - 35s 545ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "64/64 [==============================] - 35s 550ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "64/64 [==============================] - 36s 555ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 27ms/step - loss: nan - accuracy: 0.0980\n",
            "0.1 750 SGD 0.09799999743700027\n",
            "Epoch 1/25\n",
            "192/192 [==============================] - 48s 244ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "192/192 [==============================] - 48s 250ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "192/192 [==============================] - 47s 247ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "192/192 [==============================] - 49s 254ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "192/192 [==============================] - 48s 251ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "192/192 [==============================] - 48s 249ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "192/192 [==============================] - 50s 262ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "192/192 [==============================] - 48s 249ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "192/192 [==============================] - 48s 248ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "192/192 [==============================] - 48s 250ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "192/192 [==============================] - 50s 260ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "192/192 [==============================] - 50s 259ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "192/192 [==============================] - 48s 251ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "192/192 [==============================] - 49s 254ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "192/192 [==============================] - 49s 255ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "192/192 [==============================] - 48s 250ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "192/192 [==============================] - 49s 256ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "192/192 [==============================] - 48s 247ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "192/192 [==============================] - 49s 254ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "192/192 [==============================] - 49s 253ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "192/192 [==============================] - 48s 249ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "192/192 [==============================] - 48s 250ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "192/192 [==============================] - 49s 256ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "192/192 [==============================] - 48s 250ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "192/192 [==============================] - 48s 252ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 10s 30ms/step - loss: nan - accuracy: 0.0980\n",
            "0.25 250 SGD 0.09799999743700027\n",
            "Epoch 1/25\n",
            "96/96 [==============================] - 39s 398ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "96/96 [==============================] - 40s 417ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "96/96 [==============================] - 40s 420ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "96/96 [==============================] - 40s 418ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "96/96 [==============================] - 41s 425ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "96/96 [==============================] - 40s 421ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "96/96 [==============================] - 41s 419ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "96/96 [==============================] - 41s 431ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "96/96 [==============================] - 41s 423ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "96/96 [==============================] - 41s 425ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "96/96 [==============================] - 40s 419ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "96/96 [==============================] - 40s 416ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "96/96 [==============================] - 41s 433ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "96/96 [==============================] - 40s 415ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "96/96 [==============================] - 41s 428ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "96/96 [==============================] - 42s 433ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "96/96 [==============================] - 40s 420ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "96/96 [==============================] - 40s 416ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "96/96 [==============================] - 42s 433ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "96/96 [==============================] - 40s 417ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "96/96 [==============================] - 40s 417ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "96/96 [==============================] - 41s 424ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "96/96 [==============================] - 41s 427ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "96/96 [==============================] - 40s 420ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "96/96 [==============================] - 41s 424ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 10s 30ms/step - loss: nan - accuracy: 0.0980\n",
            "0.25 500 SGD 0.09799999743700027\n",
            "Epoch 1/25\n",
            "64/64 [==============================] - 37s 567ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "64/64 [==============================] - 39s 614ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "64/64 [==============================] - 39s 614ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "64/64 [==============================] - 41s 648ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "64/64 [==============================] - 39s 608ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "64/64 [==============================] - 40s 622ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "64/64 [==============================] - 39s 605ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "64/64 [==============================] - 42s 651ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "64/64 [==============================] - 39s 603ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "64/64 [==============================] - 39s 614ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "64/64 [==============================] - 39s 604ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "64/64 [==============================] - 39s 616ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "64/64 [==============================] - 40s 628ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "64/64 [==============================] - 39s 603ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "64/64 [==============================] - 39s 608ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "64/64 [==============================] - 39s 615ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "64/64 [==============================] - 39s 607ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "64/64 [==============================] - 39s 607ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "64/64 [==============================] - 39s 611ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "64/64 [==============================] - 39s 612ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "64/64 [==============================] - 39s 605ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "64/64 [==============================] - 39s 606ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "64/64 [==============================] - 39s 610ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "64/64 [==============================] - 40s 620ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "64/64 [==============================] - 41s 637ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 10s 30ms/step - loss: nan - accuracy: 0.0980\n",
            "0.25 750 SGD 0.09799999743700027\n",
            "Epoch 1/25\n",
            "192/192 [==============================] - 47s 242ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "192/192 [==============================] - 48s 253ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "192/192 [==============================] - 49s 254ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "192/192 [==============================] - 49s 253ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "192/192 [==============================] - 48s 248ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "192/192 [==============================] - 48s 251ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "192/192 [==============================] - 48s 250ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "192/192 [==============================] - 49s 254ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "192/192 [==============================] - 48s 252ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "192/192 [==============================] - 48s 250ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "192/192 [==============================] - 49s 256ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "192/192 [==============================] - 49s 255ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "192/192 [==============================] - 48s 249ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "192/192 [==============================] - 49s 255ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "192/192 [==============================] - 48s 252ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "192/192 [==============================] - 48s 250ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "192/192 [==============================] - 48s 252ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "192/192 [==============================] - 48s 252ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "192/192 [==============================] - 50s 261ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "192/192 [==============================] - 49s 253ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "192/192 [==============================] - 50s 258ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "192/192 [==============================] - 49s 257ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "192/192 [==============================] - 49s 255ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "192/192 [==============================] - 49s 253ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "192/192 [==============================] - 49s 256ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 10s 30ms/step - loss: nan - accuracy: 0.0980\n",
            "0.5 250 SGD 0.09799999743700027\n",
            "Epoch 1/25\n",
            "96/96 [==============================] - 41s 416ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "96/96 [==============================] - 44s 455ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "96/96 [==============================] - 42s 438ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "96/96 [==============================] - 42s 442ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "96/96 [==============================] - 42s 440ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "96/96 [==============================] - 43s 451ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "96/96 [==============================] - 42s 440ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "96/96 [==============================] - 43s 444ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "96/96 [==============================] - 42s 440ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "96/96 [==============================] - 42s 438ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "96/96 [==============================] - 43s 446ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "96/96 [==============================] - 42s 435ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "96/96 [==============================] - 42s 438ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "96/96 [==============================] - 43s 447ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "96/96 [==============================] - 42s 442ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "96/96 [==============================] - 42s 441ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "96/96 [==============================] - 42s 434ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "96/96 [==============================] - 43s 446ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "96/96 [==============================] - 42s 436ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "96/96 [==============================] - 43s 446ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "96/96 [==============================] - 42s 441ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "96/96 [==============================] - 42s 443ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "96/96 [==============================] - 42s 441ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "96/96 [==============================] - 42s 440ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "96/96 [==============================] - 43s 444ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 10s 30ms/step - loss: nan - accuracy: 0.0980\n",
            "0.5 500 SGD 0.09799999743700027\n",
            "Epoch 1/25\n",
            "64/64 [==============================] - 40s 608ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "64/64 [==============================] - 41s 645ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "64/64 [==============================] - 42s 651ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "64/64 [==============================] - 41s 647ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "64/64 [==============================] - 41s 641ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "64/64 [==============================] - 41s 641ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "64/64 [==============================] - 40s 624ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "64/64 [==============================] - 40s 634ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "64/64 [==============================] - 42s 653ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "64/64 [==============================] - 41s 643ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "64/64 [==============================] - 42s 650ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "64/64 [==============================] - 43s 674ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "64/64 [==============================] - 42s 653ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "64/64 [==============================] - 42s 652ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "64/64 [==============================] - 41s 639ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "64/64 [==============================] - 43s 678ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "64/64 [==============================] - 41s 642ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "64/64 [==============================] - 41s 637ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "64/64 [==============================] - 42s 652ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "64/64 [==============================] - 42s 651ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "64/64 [==============================] - 41s 638ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "64/64 [==============================] - 42s 653ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "64/64 [==============================] - 42s 649ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "64/64 [==============================] - 40s 631ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "64/64 [==============================] - 42s 651ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 29ms/step - loss: nan - accuracy: 0.0980\n",
            "0.5 750 SGD 0.09799999743700027\n"
          ]
        }
      ],
      "source": [
        "evaluation = []\n",
        "for i in [0.01,0.1,0.25,0.5]:\n",
        "  for j in [250,500,750]:\n",
        "    # for k in optimizers_list:\n",
        "      cnn_increase.compile(loss = 'categorical_crossentropy', optimizer = SGD(learning_rate=i),\n",
        "                           metrics=['accuracy'])\n",
        "      cnn_increase.fit(x_mnist_train,y_mnist_train,batch_size=j,epochs=25,validation_split=0.2)\n",
        "      score1 = cnn_increase.evaluate(x_mnist_test,y_mnist_test,verbose=1)\n",
        "      print(i,j,'SGD',score1[1])\n",
        "      evaluation.append((i,j,'SGD',score1))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRLw6ztshRNA",
        "outputId": "decc6953-30c3-4981-fa67-fb4125d8e769"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0.01, 250, 'SGD', [0.05969966575503349, 0.9810000061988831]),\n",
              " (0.01, 500, 'SGD', [0.050209105014801025, 0.9861000180244446]),\n",
              " (0.01, 750, 'SGD', [0.048151686787605286, 0.9860000014305115]),\n",
              " (0.1, 250, 'SGD', [nan, 0.09799999743700027]),\n",
              " (0.1, 500, 'SGD', [nan, 0.09799999743700027]),\n",
              " (0.1, 750, 'SGD', [nan, 0.09799999743700027]),\n",
              " (0.25, 250, 'SGD', [nan, 0.09799999743700027]),\n",
              " (0.25, 500, 'SGD', [nan, 0.09799999743700027]),\n",
              " (0.25, 750, 'SGD', [nan, 0.09799999743700027]),\n",
              " (0.5, 250, 'SGD', [nan, 0.09799999743700027]),\n",
              " (0.5, 500, 'SGD', [nan, 0.09799999743700027]),\n",
              " (0.5, 750, 'SGD', [nan, 0.09799999743700027])]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_o5vU7-hRNA",
        "outputId": "6447ad59-6557-4f99-d17b-26c3c0e8215a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>250</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[0.05969966575503349, 0.9810000061988831]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[0.050209105014801025, 0.9861000180244446]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.01</td>\n",
              "      <td>750</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[0.048151686787605286, 0.9860000014305115]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.10</td>\n",
              "      <td>250</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.10</td>\n",
              "      <td>500</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.10</td>\n",
              "      <td>750</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.25</td>\n",
              "      <td>250</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.25</td>\n",
              "      <td>500</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.25</td>\n",
              "      <td>750</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.50</td>\n",
              "      <td>250</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.50</td>\n",
              "      <td>500</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.50</td>\n",
              "      <td>750</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1    2                                           3\n",
              "0   0.01  250  SGD   [0.05969966575503349, 0.9810000061988831]\n",
              "1   0.01  500  SGD  [0.050209105014801025, 0.9861000180244446]\n",
              "2   0.01  750  SGD  [0.048151686787605286, 0.9860000014305115]\n",
              "3   0.10  250  SGD                  [nan, 0.09799999743700027]\n",
              "4   0.10  500  SGD                  [nan, 0.09799999743700027]\n",
              "5   0.10  750  SGD                  [nan, 0.09799999743700027]\n",
              "6   0.25  250  SGD                  [nan, 0.09799999743700027]\n",
              "7   0.25  500  SGD                  [nan, 0.09799999743700027]\n",
              "8   0.25  750  SGD                  [nan, 0.09799999743700027]\n",
              "9   0.50  250  SGD                  [nan, 0.09799999743700027]\n",
              "10  0.50  500  SGD                  [nan, 0.09799999743700027]\n",
              "11  0.50  750  SGD                  [nan, 0.09799999743700027]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas\n",
        "df = pandas.DataFrame(evaluation)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2L7B_NzWuiDb"
      },
      "outputs": [],
      "source": [
        "cnn_decrease = models.Sequential()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zF-sBs5PuiAd",
        "outputId": "43b37b27-f470-40a1-c618-1f5cba1b43ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_40 (Conv2D)          (None, 28, 28, 15)        390       \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 28, 28, 14)        5264      \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 14, 14, 14)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_42 (Conv2D)          (None, 14, 14, 13)        4563      \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 14, 14, 12)        3912      \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 7, 7, 12)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 7, 7, 11)          3311      \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 7, 7, 10)          2760      \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 4, 4, 10)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 4, 4, 9)           2259      \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 4, 4, 8)           1808      \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 2, 2, 8)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_48 (Conv2D)          (None, 2, 2, 7)           1407      \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (None, 2, 2, 6)           1056      \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 24)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                250       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,980\n",
            "Trainable params: 26,980\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.layers.reshaping.flatten import Flatten\n",
        "cnn_decrease.add(layers.Conv2D(15, kernel_size=(5,5), padding = \"same\", input_shape = (28,28,1)))\n",
        "cnn_decrease.add(layers.Conv2D(14, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_decrease.add(layers.MaxPooling2D(pool_size =(5,5),strides=2, padding = \"same\"))\n",
        "cnn_decrease.add(layers.Conv2D(13, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_decrease.add(layers.Conv2D(12, kernel_size=(5,5), padding = \"same\"))\n",
        "\n",
        "cnn_decrease.add(layers.MaxPooling2D(pool_size =(5,5),strides=2, padding = \"same\"))\n",
        "cnn_decrease.add(layers.Conv2D(11, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_decrease.add(layers.Conv2D(10, kernel_size=(5,5), padding = \"same\"))\n",
        "\n",
        "cnn_decrease.add(layers.MaxPooling2D(pool_size =(5,5),strides=2, padding = \"same\"))\n",
        "cnn_decrease.add(layers.Conv2D(9, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_decrease.add(layers.Conv2D(8, kernel_size=(5,5), padding = \"same\"))\n",
        "\n",
        "cnn_decrease.add(layers.MaxPooling2D(pool_size =(5,5),strides=2, padding = \"same\"))\n",
        "cnn_decrease.add(layers.Conv2D(7, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_decrease.add(layers.Conv2D(6, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_decrease.add(layers.Flatten())\n",
        "cnn_decrease.add(layers.Dense(10, activation= 'softmax'))\n",
        "cnn_decrease.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-O_G5Nuuh9P",
        "outputId": "cd42d6e1-26b3-4ef3-a4ef-bf8173d4778b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "192/192 [==============================] - 30s 151ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "192/192 [==============================] - 36s 188ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "192/192 [==============================] - 36s 188ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "192/192 [==============================] - 115s 601ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "192/192 [==============================] - 45s 236ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "192/192 [==============================] - 107s 557ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "192/192 [==============================] - 113s 587ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "192/192 [==============================] - 62s 325ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "192/192 [==============================] - 37s 191ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "192/192 [==============================] - 36s 187ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "192/192 [==============================] - 36s 189ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "192/192 [==============================] - 37s 195ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "192/192 [==============================] - 38s 195ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "192/192 [==============================] - 36s 189ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "192/192 [==============================] - 36s 190ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "192/192 [==============================] - 39s 205ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "192/192 [==============================] - 43s 225ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "192/192 [==============================] - 38s 199ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "192/192 [==============================] - 41s 215ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "192/192 [==============================] - 38s 200ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "192/192 [==============================] - 39s 200ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "192/192 [==============================] - 41s 213ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "192/192 [==============================] - 38s 196ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "192/192 [==============================] - 38s 196ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "192/192 [==============================] - 38s 198ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 28ms/step - loss: nan - accuracy: 0.0980\n",
            "0.01 250 Adam 0.09799999743700027\n",
            "Epoch 1/25\n",
            "96/96 [==============================] - 32s 326ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "96/96 [==============================] - 32s 330ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "96/96 [==============================] - 31s 325ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "96/96 [==============================] - 30s 311ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "96/96 [==============================] - 30s 318ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "96/96 [==============================] - 31s 324ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "96/96 [==============================] - 30s 314ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "96/96 [==============================] - 31s 326ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "96/96 [==============================] - 31s 327ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "96/96 [==============================] - 30s 313ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "96/96 [==============================] - 30s 313ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "96/96 [==============================] - 32s 334ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "96/96 [==============================] - 33s 342ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "96/96 [==============================] - 32s 335ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "96/96 [==============================] - 31s 324ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "96/96 [==============================] - 30s 310ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "96/96 [==============================] - 32s 332ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "96/96 [==============================] - 32s 335ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "96/96 [==============================] - 34s 352ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "96/96 [==============================] - 33s 344ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "96/96 [==============================] - 32s 332ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "96/96 [==============================] - 33s 340ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "96/96 [==============================] - 32s 339ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "96/96 [==============================] - 31s 319ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "96/96 [==============================] - 32s 329ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 8s 23ms/step - loss: nan - accuracy: 0.0980\n",
            "0.01 500 Adam 0.09799999743700027\n",
            "Epoch 1/25\n",
            "64/64 [==============================] - 33s 514ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "64/64 [==============================] - 30s 463ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "64/64 [==============================] - 29s 448ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "64/64 [==============================] - 29s 452ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "64/64 [==============================] - 30s 472ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "64/64 [==============================] - 31s 490ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "64/64 [==============================] - 30s 473ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "64/64 [==============================] - 30s 472ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "64/64 [==============================] - 34s 525ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "64/64 [==============================] - 32s 492ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "64/64 [==============================] - 30s 471ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "64/64 [==============================] - 31s 489ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "64/64 [==============================] - 30s 470ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "64/64 [==============================] - 31s 479ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "64/64 [==============================] - 31s 482ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "64/64 [==============================] - 30s 474ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "64/64 [==============================] - 29s 457ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "64/64 [==============================] - 35s 552ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "64/64 [==============================] - 34s 533ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "64/64 [==============================] - 33s 509ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "64/64 [==============================] - 32s 506ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "64/64 [==============================] - 36s 556ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "64/64 [==============================] - 35s 551ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "64/64 [==============================] - 34s 536ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "64/64 [==============================] - 35s 548ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 28ms/step - loss: nan - accuracy: 0.0980\n",
            "0.01 750 Adam 0.09799999743700027\n",
            "Epoch 1/25\n",
            "192/192 [==============================] - 39s 198ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "192/192 [==============================] - 40s 210ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "192/192 [==============================] - 41s 212ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "192/192 [==============================] - 39s 203ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "192/192 [==============================] - 42s 218ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "192/192 [==============================] - 40s 211ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "192/192 [==============================] - 40s 208ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "192/192 [==============================] - 40s 208ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "192/192 [==============================] - 40s 210ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "192/192 [==============================] - 40s 207ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "192/192 [==============================] - 40s 208ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "192/192 [==============================] - 41s 211ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "192/192 [==============================] - 39s 203ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "192/192 [==============================] - 40s 207ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "192/192 [==============================] - 41s 216ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "192/192 [==============================] - 39s 202ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "192/192 [==============================] - 39s 203ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "192/192 [==============================] - 41s 215ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "192/192 [==============================] - 40s 208ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "192/192 [==============================] - 41s 212ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "192/192 [==============================] - 40s 207ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "192/192 [==============================] - 42s 221ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "192/192 [==============================] - 39s 205ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "192/192 [==============================] - 40s 207ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "192/192 [==============================] - 40s 206ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 29ms/step - loss: nan - accuracy: 0.0980\n",
            "0.1 250 Adam 0.09799999743700027\n",
            "Epoch 1/25\n",
            "96/96 [==============================] - 32s 319ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "96/96 [==============================] - 33s 348ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "96/96 [==============================] - 36s 380ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "96/96 [==============================] - 36s 374ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "96/96 [==============================] - 34s 356ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "96/96 [==============================] - 33s 344ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "96/96 [==============================] - 35s 367ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "96/96 [==============================] - 35s 370ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "96/96 [==============================] - 34s 357ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "96/96 [==============================] - 34s 349ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "96/96 [==============================] - 34s 358ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "96/96 [==============================] - 36s 378ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "96/96 [==============================] - 36s 380ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "96/96 [==============================] - 34s 352ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "96/96 [==============================] - 33s 344ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "96/96 [==============================] - 34s 350ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "96/96 [==============================] - 36s 373ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "96/96 [==============================] - 35s 362ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "96/96 [==============================] - 34s 357ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "96/96 [==============================] - 35s 368ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "96/96 [==============================] - 37s 383ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "96/96 [==============================] - 36s 379ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "96/96 [==============================] - 36s 374ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "96/96 [==============================] - 34s 353ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "96/96 [==============================] - 38s 394ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 28ms/step - loss: nan - accuracy: 0.0980\n",
            "0.1 500 Adam 0.09799999743700027\n",
            "Epoch 1/25\n",
            "64/64 [==============================] - 31s 477ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "64/64 [==============================] - 32s 504ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "64/64 [==============================] - 34s 537ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "64/64 [==============================] - 34s 526ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "64/64 [==============================] - 32s 495ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "64/64 [==============================] - 31s 492ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "64/64 [==============================] - 34s 527ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "64/64 [==============================] - 34s 532ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "64/64 [==============================] - 31s 487ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "64/64 [==============================] - 32s 503ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "64/64 [==============================] - 34s 529ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "64/64 [==============================] - 33s 522ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "64/64 [==============================] - 31s 489ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "64/64 [==============================] - 39s 605ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "64/64 [==============================] - 35s 551ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "64/64 [==============================] - 34s 524ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "64/64 [==============================] - 33s 519ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "64/64 [==============================] - 32s 495ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "64/64 [==============================] - 33s 509ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "64/64 [==============================] - 33s 513ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "64/64 [==============================] - 35s 549ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "64/64 [==============================] - 31s 484ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "64/64 [==============================] - 32s 505ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "64/64 [==============================] - 35s 542ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "64/64 [==============================] - 33s 522ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 29ms/step - loss: nan - accuracy: 0.0980\n",
            "0.1 750 Adam 0.09799999743700027\n",
            "Epoch 1/25\n",
            "192/192 [==============================] - 39s 200ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "192/192 [==============================] - 48s 248ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "192/192 [==============================] - 46s 238ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "192/192 [==============================] - 42s 221ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "192/192 [==============================] - 44s 228ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "192/192 [==============================] - 43s 226ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "192/192 [==============================] - 44s 227ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "192/192 [==============================] - 43s 226ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "192/192 [==============================] - 39s 205ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "192/192 [==============================] - 40s 207ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "192/192 [==============================] - 39s 202ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "192/192 [==============================] - 40s 207ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "192/192 [==============================] - 38s 198ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "192/192 [==============================] - 39s 202ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "192/192 [==============================] - 40s 207ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "192/192 [==============================] - 40s 207ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "192/192 [==============================] - 37s 193ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "192/192 [==============================] - 37s 194ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "192/192 [==============================] - 42s 221ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "192/192 [==============================] - 41s 211ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "192/192 [==============================] - 39s 204ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "192/192 [==============================] - 41s 215ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "192/192 [==============================] - 39s 205ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "192/192 [==============================] - 38s 197ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "192/192 [==============================] - 40s 210ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 28ms/step - loss: nan - accuracy: 0.0980\n",
            "0.25 250 Adam 0.09799999743700027\n",
            "Epoch 1/25\n",
            "96/96 [==============================] - 34s 343ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "96/96 [==============================] - 35s 363ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "96/96 [==============================] - 34s 356ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "96/96 [==============================] - 35s 369ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "96/96 [==============================] - 34s 353ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "96/96 [==============================] - 34s 357ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "96/96 [==============================] - 32s 333ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "96/96 [==============================] - 33s 349ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "96/96 [==============================] - 34s 359ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "96/96 [==============================] - 34s 351ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "96/96 [==============================] - 32s 330ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "96/96 [==============================] - 33s 345ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "96/96 [==============================] - 33s 347ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "96/96 [==============================] - 34s 359ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "96/96 [==============================] - 33s 349ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "96/96 [==============================] - 32s 328ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "96/96 [==============================] - 31s 321ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "96/96 [==============================] - 32s 332ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "96/96 [==============================] - 35s 364ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "96/96 [==============================] - 34s 356ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "96/96 [==============================] - 32s 334ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "96/96 [==============================] - 32s 337ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "96/96 [==============================] - 34s 358ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "96/96 [==============================] - 34s 355ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "96/96 [==============================] - 33s 341ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 28ms/step - loss: nan - accuracy: 0.0980\n",
            "0.25 500 Adam 0.09799999743700027\n",
            "Epoch 1/25\n",
            "64/64 [==============================] - 29s 437ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "64/64 [==============================] - 34s 529ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "64/64 [==============================] - 41s 641ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "64/64 [==============================] - 32s 507ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "64/64 [==============================] - 39s 604ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "64/64 [==============================] - 34s 530ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "64/64 [==============================] - 32s 494ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "64/64 [==============================] - 31s 492ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "64/64 [==============================] - 33s 512ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "64/64 [==============================] - 34s 525ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "64/64 [==============================] - 33s 518ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "64/64 [==============================] - 32s 503ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "64/64 [==============================] - 34s 529ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "64/64 [==============================] - 33s 514ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "64/64 [==============================] - 33s 509ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "64/64 [==============================] - 33s 511ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "64/64 [==============================] - 33s 517ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "64/64 [==============================] - 34s 530ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "64/64 [==============================] - 33s 519ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "64/64 [==============================] - 34s 537ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "64/64 [==============================] - 35s 542ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "64/64 [==============================] - 38s 594ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "64/64 [==============================] - 35s 545ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "64/64 [==============================] - 35s 549ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "64/64 [==============================] - 33s 509ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 29ms/step - loss: nan - accuracy: 0.0980\n",
            "0.25 750 Adam 0.09799999743700027\n"
          ]
        }
      ],
      "source": [
        "decrease_evaluation = []\n",
        "for i in [0.01,0.1,0.25,]:\n",
        "  for j in [250,500,750]:\n",
        "    # for k in optimizers_list:\n",
        "      cnn_increase.compile(loss = 'categorical_crossentropy', optimizer = Adam(learning_rate=i),\n",
        "                           metrics=['accuracy'])\n",
        "      cnn_increase.fit(x_mnist_train,y_mnist_train,batch_size=j,epochs=25,validation_split=0.2)\n",
        "      score4 = cnn_increase.evaluate(x_mnist_test,y_mnist_test,verbose=1)\n",
        "      print(i,j,'Adam',score4[1])\n",
        "      decrease_evaluation.append((i,j,'Adam',score4))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiLbZ_wzhRNB",
        "outputId": "08ca54d2-21e5-4632-b283-68d8d5ab0820"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>250</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.01</td>\n",
              "      <td>750</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.10</td>\n",
              "      <td>250</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.10</td>\n",
              "      <td>500</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.10</td>\n",
              "      <td>750</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.25</td>\n",
              "      <td>250</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.25</td>\n",
              "      <td>500</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.25</td>\n",
              "      <td>750</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1     2                           3\n",
              "0  0.01  250  Adam  [nan, 0.09799999743700027]\n",
              "1  0.01  500  Adam  [nan, 0.09799999743700027]\n",
              "2  0.01  750  Adam  [nan, 0.09799999743700027]\n",
              "3  0.10  250  Adam  [nan, 0.09799999743700027]\n",
              "4  0.10  500  Adam  [nan, 0.09799999743700027]\n",
              "5  0.10  750  Adam  [nan, 0.09799999743700027]\n",
              "6  0.25  250  Adam  [nan, 0.09799999743700027]\n",
              "7  0.25  500  Adam  [nan, 0.09799999743700027]\n",
              "8  0.25  750  Adam  [nan, 0.09799999743700027]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decrease_df = pandas.DataFrame(decrease_evaluation)\n",
        "decrease_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olJ5vRv3uhyG"
      },
      "outputs": [],
      "source": [
        "cnn_hourglass = models.Sequential()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UInx9DEuhsx",
        "outputId": "3958f0ec-d090-4e8d-cb65-c80b463980b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_50 (Conv2D)          (None, 28, 28, 6)         156       \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (None, 28, 28, 7)         1057      \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 14, 14, 7)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (None, 14, 14, 8)         1408      \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (None, 14, 14, 9)         1809      \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 7, 7, 9)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_54 (Conv2D)          (None, 7, 7, 10)          2260      \n",
            "                                                                 \n",
            " conv2d_55 (Conv2D)          (None, 7, 7, 11)          2761      \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 4, 4, 11)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_56 (Conv2D)          (None, 4, 4, 10)          2760      \n",
            "                                                                 \n",
            " conv2d_57 (Conv2D)          (None, 4, 4, 9)           2259      \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 2, 2, 9)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_58 (Conv2D)          (None, 2, 2, 8)           1808      \n",
            "                                                                 \n",
            " conv2d_59 (Conv2D)          (None, 2, 2, 7)           1407      \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 28)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                290       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,975\n",
            "Trainable params: 17,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.layers.reshaping.flatten import Flatten\n",
        "cnn_hourglass.add(layers.Conv2D(6, kernel_size=(5,5), padding = \"same\", input_shape = (28,28,1)))\n",
        "cnn_hourglass.add(layers.Conv2D(7, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_hourglass.add(layers.MaxPooling2D(pool_size =(5,5),strides=2, padding = \"same\"))\n",
        "cnn_hourglass.add(layers.Conv2D(8, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_hourglass.add(layers.Conv2D(9, kernel_size=(5,5), padding = \"same\"))\n",
        "\n",
        "cnn_hourglass.add(layers.MaxPooling2D(pool_size =(5,5),strides=2, padding = \"same\"))\n",
        "cnn_hourglass.add(layers.Conv2D(10, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_hourglass.add(layers.Conv2D(11, kernel_size=(5,5), padding = \"same\"))\n",
        "\n",
        "cnn_hourglass.add(layers.MaxPooling2D(pool_size =(5,5),strides=2, padding = \"same\"))\n",
        "cnn_hourglass.add(layers.Conv2D(10, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_hourglass.add(layers.Conv2D(9, kernel_size=(5,5), padding = \"same\"))\n",
        "\n",
        "cnn_hourglass.add(layers.MaxPooling2D(pool_size =(5,5),strides=2, padding = \"same\"))\n",
        "cnn_hourglass.add(layers.Conv2D(8, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_hourglass.add(layers.Conv2D(7, kernel_size=(5,5), padding = \"same\"))\n",
        "cnn_hourglass.add(layers.Flatten())\n",
        "cnn_hourglass.add(layers.Dense(10, activation= 'softmax'))\n",
        "cnn_hourglass.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTfEo-8cuhn1",
        "outputId": "4bfa3525-09d2-450e-d578-4c4b90e140ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "192/192 [==============================] - 36s 179ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "192/192 [==============================] - 37s 194ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "192/192 [==============================] - 40s 210ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "192/192 [==============================] - 39s 202ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "192/192 [==============================] - 36s 189ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "192/192 [==============================] - 38s 198ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "192/192 [==============================] - 38s 200ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "192/192 [==============================] - 39s 201ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "192/192 [==============================] - 37s 192ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "192/192 [==============================] - 39s 203ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "192/192 [==============================] - 39s 204ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "192/192 [==============================] - 37s 191ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "192/192 [==============================] - 39s 201ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "192/192 [==============================] - 41s 211ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "192/192 [==============================] - 38s 197ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "192/192 [==============================] - 37s 193ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "192/192 [==============================] - 38s 196ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "192/192 [==============================] - 40s 210ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "192/192 [==============================] - 39s 205ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "192/192 [==============================] - 37s 192ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "192/192 [==============================] - 38s 197ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "192/192 [==============================] - 40s 208ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "192/192 [==============================] - 38s 200ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "192/192 [==============================] - 38s 199ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "192/192 [==============================] - 38s 200ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 28ms/step - loss: nan - accuracy: 0.0980\n",
            "0.01 250 RMS 0.09799999743700027\n",
            "Epoch 1/25\n",
            "96/96 [==============================] - 31s 309ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "96/96 [==============================] - 33s 346ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "96/96 [==============================] - 34s 358ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "96/96 [==============================] - 35s 367ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "96/96 [==============================] - 34s 350ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "96/96 [==============================] - 32s 338ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "96/96 [==============================] - 35s 360ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "96/96 [==============================] - 36s 373ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "96/96 [==============================] - 35s 366ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "96/96 [==============================] - 33s 342ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "96/96 [==============================] - 32s 337ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "96/96 [==============================] - 34s 349ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "96/96 [==============================] - 35s 363ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "96/96 [==============================] - 33s 348ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "96/96 [==============================] - 33s 341ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "96/96 [==============================] - 34s 356ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "96/96 [==============================] - 35s 361ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "96/96 [==============================] - 33s 345ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "96/96 [==============================] - 32s 337ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "96/96 [==============================] - 36s 373ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "96/96 [==============================] - 34s 356ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "96/96 [==============================] - 33s 341ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "96/96 [==============================] - 35s 367ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "96/96 [==============================] - 34s 358ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "96/96 [==============================] - 33s 341ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 27ms/step - loss: nan - accuracy: 0.0980\n",
            "0.01 500 RMS 0.09799999743700027\n",
            "Epoch 1/25\n",
            "64/64 [==============================] - 29s 436ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "64/64 [==============================] - 32s 497ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "64/64 [==============================] - 34s 524ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "64/64 [==============================] - 34s 531ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "64/64 [==============================] - 33s 516ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "64/64 [==============================] - 31s 489ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "64/64 [==============================] - 31s 484ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "64/64 [==============================] - 31s 487ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "64/64 [==============================] - 33s 514ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "64/64 [==============================] - 32s 502ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "64/64 [==============================] - 32s 507ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "64/64 [==============================] - 30s 474ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "64/64 [==============================] - 31s 486ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "64/64 [==============================] - 33s 515ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "64/64 [==============================] - 33s 522ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "64/64 [==============================] - 31s 488ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "64/64 [==============================] - 30s 469ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "64/64 [==============================] - 31s 493ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "64/64 [==============================] - 33s 513ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "64/64 [==============================] - 32s 497ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "64/64 [==============================] - 31s 487ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "64/64 [==============================] - 34s 531ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "64/64 [==============================] - 32s 494ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "64/64 [==============================] - 32s 494ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "64/64 [==============================] - 32s 493ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 27ms/step - loss: nan - accuracy: 0.0980\n",
            "0.01 750 RMS 0.09799999743700027\n",
            "Epoch 1/25\n",
            "192/192 [==============================] - 36s 180ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "192/192 [==============================] - 37s 195ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "192/192 [==============================] - 38s 199ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "192/192 [==============================] - 39s 205ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "192/192 [==============================] - 37s 194ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "192/192 [==============================] - 36s 187ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "192/192 [==============================] - 39s 201ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "192/192 [==============================] - 40s 207ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "192/192 [==============================] - 37s 194ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "192/192 [==============================] - 39s 201ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "192/192 [==============================] - 37s 192ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "192/192 [==============================] - 37s 192ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "192/192 [==============================] - 40s 209ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "192/192 [==============================] - 40s 207ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "192/192 [==============================] - 37s 191ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "192/192 [==============================] - 38s 197ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "192/192 [==============================] - 39s 201ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "192/192 [==============================] - 38s 199ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "192/192 [==============================] - 36s 188ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "192/192 [==============================] - 37s 195ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "192/192 [==============================] - 38s 200ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "192/192 [==============================] - 39s 204ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "192/192 [==============================] - 39s 204ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "192/192 [==============================] - 37s 194ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "192/192 [==============================] - 38s 196ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 27ms/step - loss: nan - accuracy: 0.0980\n",
            "0.1 250 RMS 0.09799999743700027\n",
            "Epoch 1/25\n",
            "96/96 [==============================] - 33s 331ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "96/96 [==============================] - 31s 325ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "96/96 [==============================] - 32s 334ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "96/96 [==============================] - 34s 354ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "96/96 [==============================] - 34s 358ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "96/96 [==============================] - 33s 345ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "96/96 [==============================] - 34s 353ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "96/96 [==============================] - 34s 358ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "96/96 [==============================] - 32s 338ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "96/96 [==============================] - 34s 350ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "96/96 [==============================] - 34s 358ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "96/96 [==============================] - 33s 341ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "96/96 [==============================] - 33s 341ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "96/96 [==============================] - 32s 338ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "96/96 [==============================] - 34s 355ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "96/96 [==============================] - 34s 352ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "96/96 [==============================] - 33s 349ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "96/96 [==============================] - 32s 333ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "96/96 [==============================] - 32s 337ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "96/96 [==============================] - 34s 356ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "96/96 [==============================] - 34s 359ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "96/96 [==============================] - 34s 357ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "96/96 [==============================] - 32s 331ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "96/96 [==============================] - 33s 340ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "96/96 [==============================] - 34s 356ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 27ms/step - loss: nan - accuracy: 0.0980\n",
            "0.1 500 RMS 0.09799999743700027\n",
            "Epoch 1/25\n",
            "64/64 [==============================] - 41s 609ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "64/64 [==============================] - 31s 482ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "64/64 [==============================] - 30s 464ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "64/64 [==============================] - 30s 469ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "64/64 [==============================] - 30s 469ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "64/64 [==============================] - 29s 459ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "64/64 [==============================] - 28s 444ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "64/64 [==============================] - 30s 463ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "64/64 [==============================] - 29s 450ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "64/64 [==============================] - 29s 454ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "64/64 [==============================] - 30s 470ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "64/64 [==============================] - 29s 455ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "64/64 [==============================] - 29s 448ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "64/64 [==============================] - 29s 460ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "64/64 [==============================] - 30s 470ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "64/64 [==============================] - 35s 542ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "64/64 [==============================] - 33s 519ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "64/64 [==============================] - 30s 468ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "64/64 [==============================] - 31s 479ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "64/64 [==============================] - 30s 476ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "64/64 [==============================] - 30s 467ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "64/64 [==============================] - 30s 476ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "64/64 [==============================] - 31s 480ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "64/64 [==============================] - 30s 476ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "64/64 [==============================] - 30s 477ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 28ms/step - loss: nan - accuracy: 0.0980\n",
            "0.1 750 RMS 0.09799999743700027\n",
            "Epoch 1/25\n",
            "192/192 [==============================] - 39s 192ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "192/192 [==============================] - 38s 197ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "192/192 [==============================] - 38s 197ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "192/192 [==============================] - 36s 190ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "192/192 [==============================] - 38s 199ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "192/192 [==============================] - 37s 192ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "192/192 [==============================] - 36s 190ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "192/192 [==============================] - 38s 196ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "192/192 [==============================] - 38s 197ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "192/192 [==============================] - 37s 195ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "192/192 [==============================] - 37s 194ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "192/192 [==============================] - 38s 197ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "192/192 [==============================] - 38s 200ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "192/192 [==============================] - 37s 194ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "192/192 [==============================] - 38s 198ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "192/192 [==============================] - 37s 191ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "192/192 [==============================] - 40s 207ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "192/192 [==============================] - 38s 200ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "192/192 [==============================] - 36s 186ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "192/192 [==============================] - 37s 194ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "192/192 [==============================] - 37s 194ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "192/192 [==============================] - 38s 200ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "192/192 [==============================] - 37s 192ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "192/192 [==============================] - 37s 194ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "192/192 [==============================] - 42s 220ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 6s 17ms/step - loss: nan - accuracy: 0.0980\n",
            "0.25 250 RMS 0.09799999743700027\n",
            "Epoch 1/25\n",
            "96/96 [==============================] - 35s 357ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "96/96 [==============================] - 32s 335ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "96/96 [==============================] - 32s 329ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "96/96 [==============================] - 32s 338ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "96/96 [==============================] - 34s 357ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "96/96 [==============================] - 35s 361ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "96/96 [==============================] - 34s 351ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "96/96 [==============================] - 32s 332ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "96/96 [==============================] - 32s 330ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "96/96 [==============================] - 33s 339ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "96/96 [==============================] - 33s 348ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "96/96 [==============================] - 33s 348ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "96/96 [==============================] - 32s 337ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "96/96 [==============================] - 32s 332ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "96/96 [==============================] - 32s 332ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "96/96 [==============================] - 34s 353ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "96/96 [==============================] - 33s 340ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "96/96 [==============================] - 33s 349ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "96/96 [==============================] - 34s 352ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "96/96 [==============================] - 33s 346ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "96/96 [==============================] - 31s 324ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "96/96 [==============================] - 32s 339ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "96/96 [==============================] - 31s 321ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "96/96 [==============================] - 31s 318ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "96/96 [==============================] - 31s 320ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 27ms/step - loss: nan - accuracy: 0.0980\n",
            "0.25 500 RMS 0.09799999743700027\n",
            "Epoch 1/25\n",
            "64/64 [==============================] - 29s 432ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "64/64 [==============================] - 30s 472ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "64/64 [==============================] - 30s 473ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/25\n",
            "64/64 [==============================] - 34s 526ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "64/64 [==============================] - 31s 491ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 6/25\n",
            "64/64 [==============================] - 30s 465ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "64/64 [==============================] - 30s 465ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 8/25\n",
            "64/64 [==============================] - 31s 485ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 9/25\n",
            "64/64 [==============================] - 33s 509ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "64/64 [==============================] - 31s 481ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 11/25\n",
            "64/64 [==============================] - 30s 469ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 12/25\n",
            "64/64 [==============================] - 31s 481ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "64/64 [==============================] - 31s 488ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 14/25\n",
            "64/64 [==============================] - 32s 498ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "64/64 [==============================] - 31s 482ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "64/64 [==============================] - 30s 474ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "64/64 [==============================] - 32s 500ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "64/64 [==============================] - 33s 509ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "64/64 [==============================] - 31s 478ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "64/64 [==============================] - 32s 494ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "64/64 [==============================] - 33s 518ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 22/25\n",
            "64/64 [==============================] - 32s 503ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "64/64 [==============================] - 31s 489ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 24/25\n",
            "64/64 [==============================] - 30s 462ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 25/25\n",
            "64/64 [==============================] - 32s 496ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 9s 27ms/step - loss: nan - accuracy: 0.0980\n",
            "0.25 750 RMS 0.09799999743700027\n"
          ]
        }
      ],
      "source": [
        "hourglass_evaluation = []\n",
        "for i in [0.01,0.1,0.25]:\n",
        "  for j in [250,500,750]:\n",
        "    # for k in optimizers_list:\n",
        "      cnn_increase.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(learning_rate=i),\n",
        "                           metrics=['accuracy'])\n",
        "      cnn_increase.fit(x_mnist_train,y_mnist_train,batch_size=j,epochs=25,validation_split=0.2)\n",
        "      score7 = cnn_increase.evaluate(x_mnist_test,y_mnist_test,verbose=1)\n",
        "      print(i,j,'RMS',score7[1])\n",
        "      hourglass_evaluation.append((i,j,'RMS',score7))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4u-H2qU5-OSg",
        "outputId": "054ab4b6-4183-4891-a478-fd06030d7594"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>250</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.01</td>\n",
              "      <td>750</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.10</td>\n",
              "      <td>250</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.10</td>\n",
              "      <td>500</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.10</td>\n",
              "      <td>750</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.25</td>\n",
              "      <td>250</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.25</td>\n",
              "      <td>500</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.25</td>\n",
              "      <td>750</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1    2                           3\n",
              "0  0.01  250  RMS  [nan, 0.09799999743700027]\n",
              "1  0.01  500  RMS  [nan, 0.09799999743700027]\n",
              "2  0.01  750  RMS  [nan, 0.09799999743700027]\n",
              "3  0.10  250  RMS  [nan, 0.09799999743700027]\n",
              "4  0.10  500  RMS  [nan, 0.09799999743700027]\n",
              "5  0.10  750  RMS  [nan, 0.09799999743700027]\n",
              "6  0.25  250  RMS  [nan, 0.09799999743700027]\n",
              "7  0.25  500  RMS  [nan, 0.09799999743700027]\n",
              "8  0.25  750  RMS  [nan, 0.09799999743700027]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hourglass_df = pandas.DataFrame(hourglass_evaluation)\n",
        "hourglass_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89GCHHut-OHO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rypD9qBodF-o"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras import datasets, layers, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgtTnYruBL3-"
      },
      "outputs": [],
      "source": [
        "# l = list(tf.keras.datasets.cifar10.load_data())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1kdg1SVBOAm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJjIl3Lou5Uh",
        "outputId": "b812fae4-d1cc-4a07-cacd-6b8d69bf08b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBy-oWfmvv7Z",
        "outputId": "d1a69b2d-1650-4376-fd29-0db86e5aea8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwBUlEQVR4nO3de3TU9bn3/c/MJDMJJJkQICc5yKGCyMFKJaZaNhXKYa/HLUp9sNq72Fq9dQfvreye2KvV6t57xW3Xam27KT7Ps61sn1Wk2lv01nurVSyhKqCkUMRDBIwCkgREciaTyczv/kNNGwX9XpDwTeL7tdasRTIXV76/+c7MlcnMfCYUBEEgAABOs7DvBQAAPpsYQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALzJ8L+Cj0um0Dh48qNzcXIVCId/LAQAYBUGglpYWlZaWKhw+8eOcfjeADh48qNGjR/teBgDgFO3fv1+jRo064fl9NoBWrVqln/zkJ6qvr9eMGTP0y1/+UrNmzfrU/5ebmytJKhw+6hMn51/r6Eg4r6sraU0eMtSH0qbOffkIz9LbmsbU1ZUy1Uci7n/pzcnJNfVOdCbdaxPu1xNJCtLul0vYcIySlE532dZi2KLsIdmm3pGw+91AV1enqXdGRqZzbWenbX8iGe7r7uy0rTsre6ip3vW+SpKSSdtaLNIp2205KzvL0Nv9/i2dTuu9o/u6789PpE8G0G9/+1utWLFC99xzj8rKynT33XdrwYIFqqmpUWFh4Sf+3w/vOMPhsPOmhkLumx8K9eUAsnXuLwPIdIySQuZB674/lhuytbel9v3/4H65WHub12LYo7Cxt+Uyt667T3v34d5br4d9eZwW1vu3cDjiXnwSqaGfdj/UJ5fET3/6U1133XX65je/qSlTpuiee+7RkCFD9Otf/7ovfhwAYADq9QHU2dmp6upqzZs37y8/JBzWvHnztHnz5o/VJxIJNTc39zgBAAa/Xh9A7777rlKplIqKinp8v6ioSPX19R+rr6ysVDwe7z7xAgQA+Gzw/j6glStXqqmpqfu0f/9+30sCAJwGvf4ihBEjRigSiaihoaHH9xsaGlRcXPyx+lgsplgs1tvLAAD0c73+CCgajWrmzJnasGFD9/fS6bQ2bNig8vLy3v5xAIABqk9ehr1ixQotW7ZMX/jCFzRr1izdfffdamtr0ze/+c2++HEAgAGoTwbQ0qVLdfjwYd16662qr6/XueeeqyeffPJjL0wAAHx2hQLr2+D7WHNzs+LxuAryi53faJZIGN5VHljfsW54138fJiFYt2noUNs7uS3a29tN9ZbjtL45NzD8FTmVsiU4WN5cGIkY3tAnKZE4Zqq39Le+kvTIkSPOta1trabelud3Q8Z3cmdlub+Lv7GpydQ7M2p7XtpyXbE+552bk+dce/Q929tYLO9Dzcp2f7ySTqf0zjt71NTUpLy8E6/f+6vgAACfTQwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF32SBdcbkp2dhs9Ot0R42CJtIhFD1EvaFsWTNtRbo14scR8dHR2m3n2Z3hSJ2K6SGZlR59rWVluMjCVexbKXJ8Oylq4uQzSVjPtv3PrORKdzbcoSeyUpmUw610aN0TpRY1xOPB53rrVGWTU3u8cIpQPb9TCa4X77CVtye1x79npHAAAcMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF702yy4IB1IIbdco4wM99ymVMoYZmWJmbPU6oNjdBSNumc2SVJbW5tzbSKRMPW2smTHWTPv+jKXztLbmgVnXXYo5H7lOnr0qKl32HCZh1K2vDZLhp31Op6Zmelca81ptIbeRaPuaxk2rNTU25IzFwrZ1t3a6p5LV193yL2x4/WVR0AAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC/6bRRPJOSc5qAglXRvbEsSURB2j0AJGbN4LDElXV1dpt7WaBgLy7qt0mnjBhkiUyLGdVvqu5K2/bFE60i26J7Ozr6Ly4nFsky9YzH3iBrnG/wHcnNynGsnTT7L1PucqZNM9eeee65z7dixZ5p6DxmS7Vx78GCdqfdtt/6Lc21TY6NzbRC43f/wCAgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgRb/NggspcE5WS6cM2VdBxLYOQwZX2pBLJkmBIeArZTlGI3sume04Lf2tmXdB2r13JGzb+3DI/fezkDVnztBbktJpy2Vuu65kZbnnu0UitozB3Dz33hdeeJGp99/93d8515aVnW/qPWJkganekqeXSCRMvTMy3O+ma2vfMvWurz/kXJtIdDrXkgUHAOjXen0A/fjHP1YoFOpxmjx5cm//GADAANcnf4I755xz9Mwzz/zlhxgeQgIAPhv6ZDJkZGSouLi4L1oDAAaJPnkOaPfu3SotLdX48eN19dVXa9++fSesTSQSam5u7nECAAx+vT6AysrKtGbNGj355JNavXq1amtr9aUvfUktLS3Hra+srFQ8Hu8+jR49ureXBADoh3p9AC1atEhXXHGFpk+frgULFui//uu/1NjYqAcffPC49StXrlRTU1P3af/+/b29JABAP9Tnrw7Iz8/XWWedpT179hz3/Fgsplgs1tfLAAD0M33+PqDW1lbt3btXJSUlff2jAAADSK8PoO985zuqqqrSW2+9pRdeeEGXXXaZIpGIvva1r/X2jwIADGC9/ie4AwcO6Gtf+5qOHDmikSNH6qKLLtKWLVs0cuTI3v5R3cKGiJUgsMXOGJJeFHIOD7JLp20RKJb4G2sUT19G95hjfuS+97m5uabelrW0traaeqcco0o+ZLnMs7Ntf9LOyXWPyyn/4kxT769+dbFz7YVfvNDUe2RhoXPtq6++Zur9es2rpvoLLrjAudZ6+0km3eOptmzeaurd3Hj8F4cdT2aG+/XKNYqn1wfQunXrerslAGAQIgsOAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOBFn38cw8kKhcMKhxznoyHfLW0Jd5MUGDLYQpG+y1RLpVKm3n21jpOpl9wz1bq6bBlp0cxM51prnl4ymeyz3pmZUVN99lD3vLYzzigy9f76f7vSufbqq91rJWnYsLhzbVeX7Tre1eW+P9nZ7pefJBUUFJjqMzLc70q7utyz3STp8OHDzrWbjVlwnYacuZyhQ5xr04HbXvIICADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgRb+N4kmn0gpCbhEuIUUMnY2xM2H3+kiGeyyMJCU6E4aF2NYdMUSDWOKGPliMqTocdt8fw7Il2WJNWlpbTL2DtHuEUG5erqn30BxbfU5utnPt1//b10y9Fyy82LnWEjkjSam0+++4kUjf/T48duw44/9w33tJam8/5lybTtsihzZt+qNz7a5dr5p6Z2bGnGuTSfd1B4HbfQqPgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABe9NssuK5wRKGQ23zMcKyTpJAh3+t97jlm0WxbvteEs6c517Yd6zD13vf2m861QdqQSScpHNh+bwkH7pd5SLZcuqwh7vl7sSxbVt/UqVOca//vpVeYemfn5JjqG5uOOtdOnGDLPXvttdeca/fUvm3qPWXKOc61Z5QUm3rbb8vuOhKdpvpEwj0L7p0D9abe//H/3e9c295uu5+IRt0zBlOBe+4iWXAAgH6NAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8KLfZsFNmvZ5RTLclle7Z69z385298wmScrMcs/sOm9Wuan38v9xo3NtJBIy9f7///M+59onHn/c1DvRnjTVJ7vcs+Zyc21XyS/POd+5dsK40abe50yZ6Fw7+0vuuX6SVHqme86cJHV2uWcSNjW3mXqvXfewc20kavudNTPmnr9nzQEsLSpyrm1rtd3uOzps+YjHOtqda1ev/n9Mvf9U/Wfn2qHGjMFUyv0yd4x3e7/WMaaPR0AAAC/MA2jTpk265JJLVFpaqlAopEceeaTH+UEQ6NZbb1VJSYmys7M1b9487d69u7fWCwAYJMwDqK2tTTNmzNCqVauOe/5dd92lX/ziF7rnnnu0detWDR06VAsWLFBHhy0mHAAwuJmfA1q0aJEWLVp03POCINDdd9+tH/7wh7r00kslSffff7+Kior0yCOP6Morrzy11QIABo1efQ6otrZW9fX1mjdvXvf34vG4ysrKtHnz5uP+n0Qioebm5h4nAMDg16sDqL7+/U/6K/rIq1OKioq6z/uoyspKxePx7tPo0bZXKgEABibvr4JbuXKlmpqauk/79+/3vSQAwGnQqwOouPj9z3RvaGjo8f2Ghobu8z4qFospLy+vxwkAMPj16gAaN26ciouLtWHDhu7vNTc3a+vWrSovt71JEwAwuJlfBdfa2qo9e/Z0f11bW6sdO3aooKBAY8aM0c0336x/+Zd/0ec+9zmNGzdOP/rRj1RaWqrFixf35roBAAOceQBt27ZNX/7yl7u/XrFihSRp2bJlWrNmjb73ve+pra1N119/vRobG3XRRRfpySefVFZWlunnfO0b31B29hCn2t8+8KBz31d2vWpax8zzZznXXvffv23qfcGs85xrM0MpU+9xZ3zXubZ45AhT7989+JCpfli+2z5K0jlTxpt6z190sXPt2FElpt7Hmt9zrt38wh9Nvae3uke3SNLEs92vKyMKCky9v/jFMufat/a/aeptSZB6o6bG1Dsj4h7zc6zN9j7EkByzZD7wn/evca59+GH36CNJikTcY5jSaVucUSrlfr8ydEiuYR0pNbd8ep15AM2ZM0fBJwT9hEIh3XHHHbrjjjusrQEAnyHeXwUHAPhsYgABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8MEfxnC4LvnKxcnPdPpohK5bt3Pd/rv9fpnVccdli59rzz5tu6h2kOp1rk0HS1Lu09Pgff3E8N9z43029z578OVP9thc3OdeOLHTPm5KkF//0Z+fa57duM/VeMH+hc+3Ec6eYev/51a2m+qIxY51r48Pcs/ckqbg07lz776vccxclKTBEGM6eM+/Ti/5K/vCiTy/6wJAs22Xyv//XI6b6f//3f3euTXR0mXpHwu5r7+iwZd7FYu4ZnV1d7pvpmknHIyAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBf9NoonNztTuUMynWov+uL5zn1HjBxhWsekM0c51w6NBqbeqbR7vE5XYOvd0XbMuTYatV0NhuW7RSR96Mh7Dc61ZbMmmXq//NDDzrXtHQlT75eGukfUnFFypql3NM/9eiVJ++rcI1b2b3nO1PtX9/zUufbQof2m3lcuvdK5duJEW8RT2nCT+P3Tz5h6//reX5vqW1tanWsjkZipd9oQ2RUfNszUO2WI1zl2rN25NgiI4gEA9GMMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF/02C07plEJpt5yi+NCoc9vzptrypmIx9xmdCrlnNklSKIg412aE3I9RklKB+1qSHW2m3gfefNlUP23SaOfacWOnmHrn5D3vXBvTblPvtsOvOdf+7sHfmXqf/fkyU/2BA9uda9fef7+pd16O+3WrYvktpt5jx5/lXJsO3LIfP/TCi9XOtf/7yf8y9a6vP2Sqj8Xc8xHTabectJOpz4i436dIUmfCcJ8VuOfGiSw4AEB/xgACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB40W+jeDIzMpSZ4bi8IHDuG82wRVWk5R4/EQnbLs5wKORcmzhmi8tJd7Y612ZlJE29R50xwlQ/6Zwx7sVZw0y9iyec41zberDL1Dsvf7hz7fCxhmOU9HqNLRZo83ObnGunTbfFGZWXzXKuPWO07Ti7AveYn+3bd5p6b6t+wbn21Vd2mXp3dbnfNiUpM5LtXhyxRfEkk8eca48ePWrqHQm73x+GDPdXrngEBADwggEEAPDCPIA2bdqkSy65RKWlpQqFQnrkkUd6nH/NNdcoFAr1OC1cuLC31gsAGCTMA6itrU0zZszQqlWrTlizcOFC1dXVdZ8eeOCBU1okAGDwMb8IYdGiRVq0aNEn1sRiMRUXF5/0ogAAg1+fPAe0ceNGFRYWatKkSbrxxht15MiRE9YmEgk1Nzf3OAEABr9eH0ALFy7U/fffrw0bNujf/u3fVFVVpUWLFimVOv7LmSsrKxWPx7tPo0e7f3omAGDg6vX3AV155ZXd/542bZqmT5+uCRMmaOPGjZo7d+7H6leuXKkVK1Z0f93c3MwQAoDPgD5/Gfb48eM1YsQI7dmz57jnx2Ix5eXl9TgBAAa/Ph9ABw4c0JEjR1RSUtLXPwoAMICY/wTX2tra49FMbW2tduzYoYKCAhUUFOj222/XkiVLVFxcrL179+p73/ueJk6cqAULFvTqwgEAA1soCAxBanr/FW5f/vKXP/b9ZcuWafXq1Vq8eLG2b9+uxsZGlZaWav78+frnf/5nFRUVOfVvbm5WPB7Xwbojzn+OSyQ6nNefTttymJR2v3iSXbassUSi3bn2cN3bpt5BV5Nz7bD8fFPvhPEibGhxz6V7acd+U+9I2H0xOYEtBzA3L9e5dufeGlPvF7f+yVQ/dbJ75t25555r6n3GGe5/nQiMv7NWb9/hXNtQb9v755/b4Fz72suvmHpHgiGm+lCQ6VybPSTL1DthyHVMJm25jhFDNuawfPecxnQ6pYP1e9TU1PSJ9+PmR0Bz5szRJ82sp556ytoSAPAZRBYcAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMCLXv88oN6SSnUplXLLVguFQn22jsCQBff2gXpT70jMPT9qf52t98svuedkLb3y66behaPPMtUf3lvrXJtIHDD1Hj7SPZ9qeN5IU+/Nm19wrt399vE/buREJowfb6qPZLjfVAuNyfNdcs8De/313aberW0tzrW1e98w9X6zxn0tEeNdnfU+xVLelbLltaXTx/8wz+PJzHS/T5GkrGz3XDpLjqZrLY+AAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABe9NsonmQyqc6kW2RF2JCD0eXYs7s+5R4/0eGe2iNJ2vD7Kufa8SX5pt5Tppe5F0fzTL3fPnjUVJ9KxZxrx55hi6hJdLU612558XlT7wN17rFA0YxsU++O9oSp/oKyLzrXthl7v9NwyLk2FLFF1Bw54h4hteNPL5l6J9rcb8uxqG1/0iG3GLAPDR2S41wbBO7ROpLUkXA/zszMqKl3osP9utKSdI9VCgKieAAA/RgDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgRb/Ngmts71AqkulUmxV1P4wgacvJamrrcK6NGDLpJOmd2r3Ote3NI0y9Z82a5lz76lv7Tb0TnRFTfVPTMefaY4Z8L0l6s/Z159rDh9419X730GHn2pGFuabeX73iKlN9V8r9uvXnnTtNvQuGD3eubai3XVf+uOH3zrWH690z6SQpy5C/l07ZrleZ2Vmm+rQhM7IrZcuZc81Vk6REp/tt7f3mllr3dShwa8wjIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF/02iqe9rUPhkFsUTyhnqKFz1LSO9464x7E01O0x9T57vHt8y4ZNW0y9X37ZPY5lytnjTb3PnjzFVJ9MpJxr6+rrTL3b2t2jkmrecI/tkaTPz3A/zksuWWjq3drWaqo/2tjmXJuXGzf1fueA+2X+x2efNfV+4/Ua59q8nDxTb6Xdc2SyorZonaT7VVaSdKzTPeIrM8MWZRUOu9en04a4HEkhuUc8hUKWxytE8QAA+jHTAKqsrNT555+v3NxcFRYWavHixaqp6fkbTkdHhyoqKjR8+HDl5ORoyZIlamho6NVFAwAGPtMAqqqqUkVFhbZs2aKnn35ayWRS8+fPV1vbX/48cMstt+ixxx7TQw89pKqqKh08eFCXX355ry8cADCwmZ4DevLJJ3t8vWbNGhUWFqq6ulqzZ89WU1OT7r33Xq1du1YXX3yxJOm+++7T2WefrS1btuiCCy7ovZUDAAa0U3oOqKmpSZJUUFAgSaqurlYymdS8efO6ayZPnqwxY8Zo8+bNx+2RSCTU3Nzc4wQAGPxOegCl02ndfPPNuvDCCzV16lRJUn19vaLRqPLz83vUFhUVqb6+/rh9KisrFY/Hu0+jR48+2SUBAAaQkx5AFRUV2rVrl9atW3dKC1i5cqWampq6T/v32z5xEQAwMJ3U+4CWL1+uxx9/XJs2bdKoUaO6v19cXKzOzk41Njb2eBTU0NCg4uLi4/aKxWKKxWInswwAwABmegQUBIGWL1+u9evX69lnn9W4ceN6nD9z5kxlZmZqw4YN3d+rqanRvn37VF5e3jsrBgAMCqZHQBUVFVq7dq0effRR5ebmdj+vE4/HlZ2drXg8rmuvvVYrVqxQQUGB8vLydNNNN6m8vJxXwAEAejANoNWrV0uS5syZ0+P79913n6655hpJ0s9+9jOFw2EtWbJEiURCCxYs0K9+9ateWSwAYPAIBUHgHqh0GjQ3Nysej6t6+x7l5LplpXV0djn33/7KG6b1dDS951w7psTUWq+8vtW59oG1T5h6Nze7Z96NKLItfOrUyab6aMw9y2rPm2+ZepeMmeRcm5nZbur9lblznGvfO3TM1Pvwe4dM9UOG5jjXvvH6W6bex9rdg8/Ccs/ek6Tnqp5yro2E3XPJJOm9d91zGrOzbFlwjU22rL4gZchrC4xBc0o6V2Zk2LIuUyn37Lhw2P0ZmyBIq7X9kJqampSXd+KMP7LgAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABenNTHMZwOe/bu1ZChQ51qn3vuOee+m17aaVrHlLPGfXrRB945aIvBeOKpZ5xr9765z9S7rck9nqjunQOm3gf37zbVJzvbnGvjw0eael80d6Fz7ZQp7nspSQf3u18uyYQtRqYz6b4/krTjhReca7s6bb9XXnHFVc618dxsU++339rjXvum7XrVmex0rg0bY36CtHtEjSQFgftlnjb2DhmWHgS24wyF3Ncdi7nHGaWDtOSQfMUjIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAX/TYLbt3/fFCZUbdsta2b/uDcN5JTYFpHWu45Ztt2mVorGRrvXDukIGXq3dLyqnNtW3uDqfexfYdM9UEQONeOHT/W1Dsz5t77YF2zqXcq5Z571tRcb+pdvW2Hqb6t1SFY6wNfveIKU++xZ5Y413Z2JEy9P3/e+c61dXXvmHonU+63iZjcrycnw3Id70uBLWZOMmTBpbrcmweOC+EREADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADAi34bxfPHDY8pHHabj8lUzLnvmWfETetoOrTPvbjAPVpHkvLGTHWuzc6KmHrnZ7tHgyQa3zP1bm0+YKovKh3nXPvluX9n6h2OuO99a4t7rJIkHT30rnPt8390j4OSpMbGo6b666+/zrm2bNbnTb0TiWPOtSNH5Jp6f/3rS51rUxnueylJa+//T/fiY7bruDVZJx24xwKFQrbm0WiW+zpSIVNvS4TQsWMdhr5E8QAA+jEGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADAi36bBTckO9s5C27S9C859z161JbB9XbtXufaoW1JU+/CsHvGU7S10dR7+Ihi59qhZ00x9Y6FbZlq555/kXNtRvxMU++WVve17H/rLVPvHS9VO9d2HHPPU5Okr3/9KlP9RReWO9fGYrabdc7QqHNtJGzLGsvLyXauHTthoql37rBC59qGQ++YeocituN0vKuSZM+ZS3W558xJtszISMS93pIbFwQhqevT63gEBADwwjSAKisrdf755ys3N1eFhYVavHixampqetTMmTNHoVCox+mGG27o1UUDAAY+0wCqqqpSRUWFtmzZoqefflrJZFLz589XW1vPP4Ncd911qqur6z7dddddvbpoAMDAZ/pj8ZNPPtnj6zVr1qiwsFDV1dWaPXt29/eHDBmi4mL35yAAAJ89p/QcUFNTkySpoKCgx/d/85vfaMSIEZo6dapWrlyp9vb2E/ZIJBJqbm7ucQIADH4n/Sq4dDqtm2++WRdeeKGmTv3LJ3teddVVGjt2rEpLS7Vz5059//vfV01NjR5++OHj9qmsrNTtt99+sssAAAxQJz2AKioqtGvXLj333HM9vn/99dd3/3vatGkqKSnR3LlztXfvXk2YMOFjfVauXKkVK1Z0f93c3KzRo0ef7LIAAAPESQ2g5cuX6/HHH9emTZs0atSoT6wtKyuTJO3Zs+e4AygWiykWs30WPABg4DMNoCAIdNNNN2n9+vXauHGjxo0b96n/Z8eOHZKkkpKSk1ogAGBwMg2giooKrV27Vo8++qhyc3NVX18vSYrH48rOztbevXu1du1a/e3f/q2GDx+unTt36pZbbtHs2bM1ffr0PjkAAMDAZBpAq1evlvT+m03/2n333adrrrlG0WhUzzzzjO6++261tbVp9OjRWrJkiX74wx/22oIBAIOD+U9wn2T06NGqqqo6pQV96KtXf1uxLLestOHD3V+08P+u+rlpHS0tJ34J+UelEntsvY82ONcWZOeaeoc/d5ZzbSI2zNR7zJgyU31XVpFzbXOb7WX4+9/Y7Vz74pYtpt7H2t3z3b797W+bes9fMN9UH810z+yKxtyz3SRJobRzaSrtEPD1161D7vlho0pGmHqPHFnw6UUfOLTXlpEWpC35a1Io5P6OFkummiSl0u77kxGxPa0fjbpfV8xZcA7IggMAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeHHSnwfU184ru0hDhuY41e7Y/rpz34zoENM68kvHONcePbTf1Pvg0cPOtW2d7rEwkpTV4p4+XjA809S7KWGrjzQlnWtra18z9d619QXn2pbWVlPvbyxb5lz7xYsuMPVubW0x1cfz8pxrw+G++72yK+QWsfKhSIZ7/ZgzCk29hxe4R0gFsq3bmJYjyf0/ZGbabj+WtUQitsihZJf7bdMWxeNWyyMgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBf9NguuozOlcEaXU+1ru99y7tt4LG1aR168yLk2MzPb1Lup7oBz7bvNTabe+fXvOteOmZxr6h2JuO3Lh17ZWe1c++qObabeqXb3y+Xb3/6Wqff/ddml7uuwhofZroZKJt0zu6xBZplR92yylHHdlgMtLMg3dZ589lnOtc8/bctfS6Zs13FjRF6f9c4zZAZKUntbu3NtstOSG+e27zwCAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB40W+jeJ565nllRrOcaqvf2OPcNxwvMa3j2Hu1zrUZ4Yip96gJk51rDzW8Y+o9Yrj7cWZGbOveu7fGVP/GTvd4nfcO7jP1/vubKpxrr1i61NTbEscSSqdMvYcOtcU2ZWa431SzYlFT70jY/ffQSMgW8xMODJE2xsuw/AvnOtc+feYYU+/dr+4y1VsuQ+vv/dFYjnNtoiNh6t3V5b4/6bR7rBJRPACAfo0BBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwot9mwbV1ZSgz7La84jOnOvc9eGC/aR1HDh10rk0cbTL1Hlk01Lm24Izppt6dgXu+2+s1r5l6Nx+y5bU1vut+GS6+4jJT70svd68PQqbWimXFnGttWWBSdizTVB8JuS8+w7iWkKm3LTcwFHK/i0mlDblxkqZOcc9S/MfvrjD1/tld/2aq3/v6q861ufFhpt7NbUnn2pAhr02SwobriuV6IrnV8ggIAOCFaQCtXr1a06dPV15envLy8lReXq4nnnii+/yOjg5VVFRo+PDhysnJ0ZIlS9TQ0NDriwYADHymATRq1Cjdeeedqq6u1rZt23TxxRfr0ksv1SuvvCJJuuWWW/TYY4/poYceUlVVlQ4ePKjLL7+8TxYOABjYTM8BXXLJJT2+/td//VetXr1aW7Zs0ahRo3Tvvfdq7dq1uvjiiyVJ9913n84++2xt2bJFF1xwQe+tGgAw4J30c0CpVErr1q1TW1ubysvLVV1drWQyqXnz5nXXTJ48WWPGjNHmzZtP2CeRSKi5ubnHCQAw+JkH0Msvv6ycnBzFYjHdcMMNWr9+vaZMmaL6+npFo1Hl5+f3qC8qKlJ9ff0J+1VWVioej3efRo8ebT4IAMDAYx5AkyZN0o4dO7R161bdeOONWrZsmV591f0liB+1cuVKNTU1dZ/277e9TBoAMDCZ3wcUjUY1ceJESdLMmTP10ksv6ec//7mWLl2qzs5ONTY29ngU1NDQoOLi4hP2i8ViisXc328BABgcTvl9QOl0WolEQjNnzlRmZqY2bNjQfV5NTY327dun8vLyU/0xAIBBxvQIaOXKlVq0aJHGjBmjlpYWrV27Vhs3btRTTz2leDyua6+9VitWrFBBQYHy8vJ00003qby8nFfAAQA+xjSADh06pG984xuqq6tTPB7X9OnT9dRTT+krX/mKJOlnP/uZwuGwlixZokQioQULFuhXv/rVSS1s+ue/oKxst6ia32/8s3PfRIct7iOvcIxz7fDx02y983Kca7OiUVPvppZG59oDb7pffpJ07F1bFM+iBV9xrr36W9ebeo8aVepcm+pyjzSRpEjEPXbG+mdkYyqQwoYYlLQxjiWRSDjXZmbYoniihssle6j77UGSOlKBc+1bb9ueWz58+LCpPn+Ye7zOUONxNra851wbDtwvE0nq6nK/P7TcHgLH3CvTALr33ns/8fysrCytWrVKq1atsrQFAHwGkQUHAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwwpyG3deCD6IkEsfanP9PV+cx59p0V6dtQSn3+pSxd1fSPQKlK2SL2EgZeqdTtniiILBFvSST7pdLe1urqXdLi/sHGKYNsSOSFDZEj3R2ul/eUn+L4nHfn8wM2++s0U73KJ5wxBY31drS4lyb6Ogw9bZehjLUp9IpU2vL7S0wRvHY6t2vgx+u+dP6hwLrivvYgQMH+FA6ABgE9u/fr1GjRp3w/H43gNLptA4ePKjc3FyF/uq3vubmZo0ePVr79+9XXl6exxX2LY5z8PgsHKPEcQ42vXGcQRCopaVFpaWlCodP/Ki53/0JLhwOf+LEzMvLG9Sb/yGOc/D4LByjxHEONqd6nPF4/FNreBECAMALBhAAwIsBM4BisZhuu+028wd/DTQc5+DxWThGieMcbE7ncfa7FyEAAD4bBswjIADA4MIAAgB4wQACAHjBAAIAeDFgBtCqVat05plnKisrS2VlZXrxxRd9L6lX/fjHP1YoFOpxmjx5su9lnZJNmzbpkksuUWlpqUKhkB555JEe5wdBoFtvvVUlJSXKzs7WvHnztHv3bj+LPQWfdpzXXHPNx/Z24cKFfhZ7kiorK3X++ecrNzdXhYWFWrx4sWpqanrUdHR0qKKiQsOHD1dOTo6WLFmihoYGTys+OS7HOWfOnI/t5w033OBpxSdn9erVmj59evebTcvLy/XEE090n3+69nJADKDf/va3WrFihW677Tb96U9/0owZM7RgwQIdOnTI99J61TnnnKO6urru03PPPed7Saekra1NM2bM0KpVq457/l133aVf/OIXuueee7R161YNHTpUCxYsUIcxONK3TztOSVq4cGGPvX3ggQdO4wpPXVVVlSoqKrRlyxY9/fTTSiaTmj9/vtra/hIafMstt+ixxx7TQw89pKqqKh08eFCXX365x1XbuRynJF133XU99vOuu+7ytOKTM2rUKN15552qrq7Wtm3bdPHFF+vSSy/VK6+8Iuk07mUwAMyaNSuoqKjo/jqVSgWlpaVBZWWlx1X1rttuuy2YMWOG72X0GUnB+vXru79Op9NBcXFx8JOf/KT7e42NjUEsFgseeOABDyvsHR89ziAIgmXLlgWXXnqpl/X0lUOHDgWSgqqqqiAI3t+7zMzM4KGHHuquee211wJJwebNm30t85R99DiDIAj+5m/+JviHf/gHf4vqI8OGDQv+4z/+47TuZb9/BNTZ2anq6mrNmzev+3vhcFjz5s3T5s2bPa6s9+3evVulpaUaP368rr76au3bt8/3kvpMbW2t6uvre+xrPB5XWVnZoNtXSdq4caMKCws1adIk3XjjjTpy5IjvJZ2SpqYmSVJBQYEkqbq6Wslkssd+Tp48WWPGjBnQ+/nR4/zQb37zG40YMUJTp07VypUr1d7e7mN5vSKVSmndunVqa2tTeXn5ad3LfhdG+lHvvvuuUqmUioqKeny/qKhIr7/+uqdV9b6ysjKtWbNGkyZNUl1dnW6//XZ96Utf0q5du5Sbm+t7eb2uvr5eko67rx+eN1gsXLhQl19+ucaNG6e9e/fqn/7pn7Ro0SJt3rxZEcNnDvUX6XRaN998sy688EJNnTpV0vv7GY1GlZ+f36N2IO/n8Y5Tkq666iqNHTtWpaWl2rlzp77//e+rpqZGDz/8sMfV2r388ssqLy9XR0eHcnJytH79ek2ZMkU7duw4bXvZ7wfQZ8WiRYu6/z19+nSVlZVp7NixevDBB3Xttdd6XBlO1ZVXXtn972nTpmn69OmaMGGCNm7cqLlz53pc2cmpqKjQrl27BvxzlJ/mRMd5/fXXd/972rRpKikp0dy5c7V3715NmDDhdC/zpE2aNEk7duxQU1OTfve732nZsmWqqqo6rWvo93+CGzFihCKRyMdegdHQ0KDi4mJPq+p7+fn5Ouuss7Rnzx7fS+kTH+7dZ21fJWn8+PEaMWLEgNzb5cuX6/HHH9cf/vCHHh+bUlxcrM7OTjU2NvaoH6j7eaLjPJ6ysjJJGnD7GY1GNXHiRM2cOVOVlZWaMWOGfv7zn5/Wvez3AygajWrmzJnasGFD9/fS6bQ2bNig8vJyjyvrW62trdq7d69KSkp8L6VPjBs3TsXFxT32tbm5WVu3bh3U+yq9/6m/R44cGVB7GwSBli9frvXr1+vZZ5/VuHHjepw/c+ZMZWZm9tjPmpoa7du3b0Dt56cd5/Hs2LFDkgbUfh5POp1WIpE4vXvZqy9p6CPr1q0LYrFYsGbNmuDVV18Nrr/++iA/Pz+or6/3vbRe84//+I/Bxo0bg9ra2uD5558P5s2bF4wYMSI4dOiQ76WdtJaWlmD79u3B9u3bA0nBT3/602D79u3B22+/HQRBENx5551Bfn5+8OijjwY7d+4MLr300mDcuHHBsWPHPK/c5pOOs6WlJfjOd74TbN68OaitrQ2eeeaZ4Lzzzgs+97nPBR0dHb6X7uzGG28M4vF4sHHjxqCurq771N7e3l1zww03BGPGjAmeffbZYNu2bUF5eXlQXl7ucdV2n3ace/bsCe64445g27ZtQW1tbfDoo48G48ePD2bPnu155TY/+MEPgqqqqqC2tjbYuXNn8IMf/CAIhULB73//+yAITt9eDogBFARB8Mtf/jIYM2ZMEI1Gg1mzZgVbtmzxvaRetXTp0qCkpCSIRqPBGWecESxdujTYs2eP72Wdkj/84Q+BpI+dli1bFgTB+y/F/tGPfhQUFRUFsVgsmDt3blBTU+N30Sfhk46zvb09mD9/fjBy5MggMzMzGDt2bHDdddcNuF+ejnd8koL77ruvu+bYsWPB3//93wfDhg0LhgwZElx22WVBXV2dv0WfhE87zn379gWzZ88OCgoKglgsFkycODH47ne/GzQ1NflduNG3vvWtYOzYsUE0Gg1GjhwZzJ07t3v4BMHp20s+jgEA4EW/fw4IADA4MYAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXvwfMc0wCPFlbVMAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[20000])\n",
        "print(y_train[20000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7tyQbuCygUt",
        "outputId": "ce92429e-2f20-4fb2-8527-6de746ac1118"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FXZTRIMAqhI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "x_train_gray = np.sum(x_train/3, axis=3, keepdims = True)\n",
        "x_test_gray = np.sum(x_test/3, axis=3, keepdims = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jegXV6ai1q9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L70j_5v_hzSZ"
      },
      "outputs": [],
      "source": [
        "x_train_gray /= 255\n",
        "x_test_gray /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3Hcz1a8i7O_",
        "outputId": "d566d187-8d8a-494c-bf39-e95209e8cd14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[0.24052288],\n",
              "         [0.1751634 ],\n",
              "         [0.18431373],\n",
              "         ...,\n",
              "         [0.52026144],\n",
              "         [0.49542484],\n",
              "         [0.49019608]],\n",
              "\n",
              "        [[0.07320261],\n",
              "         [0.        ],\n",
              "         [0.03398693],\n",
              "         ...,\n",
              "         [0.34771242],\n",
              "         [0.32941176],\n",
              "         [0.34771242]],\n",
              "\n",
              "        [[0.09150327],\n",
              "         [0.03006536],\n",
              "         [0.10980392],\n",
              "         ...,\n",
              "         [0.32941176],\n",
              "         [0.33202614],\n",
              "         [0.29281046]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.61960784],\n",
              "         [0.50718954],\n",
              "         [0.50326797],\n",
              "         ...,\n",
              "         [0.4745098 ],\n",
              "         [0.12287582],\n",
              "         [0.13986928]],\n",
              "\n",
              "        [[0.54248366],\n",
              "         [0.44183007],\n",
              "         [0.47058824],\n",
              "         ...,\n",
              "         [0.55686275],\n",
              "         [0.25228758],\n",
              "         [0.22222222]],\n",
              "\n",
              "        [[0.57124183],\n",
              "         [0.51111111],\n",
              "         [0.53333333],\n",
              "         ...,\n",
              "         [0.70588235],\n",
              "         [0.46143791],\n",
              "         [0.3751634 ]]],\n",
              "\n",
              "\n",
              "       [[[0.67712418],\n",
              "         [0.52156863],\n",
              "         [0.39738562],\n",
              "         ...,\n",
              "         [0.33594771],\n",
              "         [0.32418301],\n",
              "         [0.30065359]],\n",
              "\n",
              "        [[0.6130719 ],\n",
              "         [0.59084967],\n",
              "         [0.48104575],\n",
              "         ...,\n",
              "         [0.35686275],\n",
              "         [0.28627451],\n",
              "         [0.26797386]],\n",
              "\n",
              "        [[0.6       ],\n",
              "         [0.56732026],\n",
              "         [0.44705882],\n",
              "         ...,\n",
              "         [0.29411765],\n",
              "         [0.25228758],\n",
              "         [0.2496732 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.66405229],\n",
              "         [0.61437908],\n",
              "         [0.63267974],\n",
              "         ...,\n",
              "         [0.14640523],\n",
              "         [0.22352941],\n",
              "         [0.34901961]],\n",
              "\n",
              "        [[0.58431373],\n",
              "         [0.57254902],\n",
              "         [0.60392157],\n",
              "         ...,\n",
              "         [0.38169935],\n",
              "         [0.46666667],\n",
              "         [0.50065359]],\n",
              "\n",
              "        [[0.56339869],\n",
              "         [0.55947712],\n",
              "         [0.59084967],\n",
              "         ...,\n",
              "         [0.54248366],\n",
              "         [0.54771242],\n",
              "         [0.54901961]]],\n",
              "\n",
              "\n",
              "       [[[1.        ],\n",
              "         [0.99215686],\n",
              "         [0.99215686],\n",
              "         ...,\n",
              "         [0.99215686],\n",
              "         [0.99215686],\n",
              "         [0.99215686]],\n",
              "\n",
              "        [[1.        ],\n",
              "         [1.        ],\n",
              "         [1.        ],\n",
              "         ...,\n",
              "         [1.        ],\n",
              "         [1.        ],\n",
              "         [1.        ]],\n",
              "\n",
              "        [[1.        ],\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         ...,\n",
              "         [0.99607843],\n",
              "         [0.99607843],\n",
              "         [0.99607843]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.45098039],\n",
              "         [0.44444444],\n",
              "         [0.42222222],\n",
              "         ...,\n",
              "         [0.30457516],\n",
              "         [0.30196078],\n",
              "         [0.30196078]],\n",
              "\n",
              "        [[0.44313725],\n",
              "         [0.41699346],\n",
              "         [0.39607843],\n",
              "         ...,\n",
              "         [0.28235294],\n",
              "         [0.28888889],\n",
              "         [0.31895425]],\n",
              "\n",
              "        [[0.42352941],\n",
              "         [0.39607843],\n",
              "         [0.38039216],\n",
              "         ...,\n",
              "         [0.32156863],\n",
              "         [0.32287582],\n",
              "         [0.32679739]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.58562092],\n",
              "         [0.59477124],\n",
              "         [0.6       ],\n",
              "         ...,\n",
              "         [0.64705882],\n",
              "         [0.55294118],\n",
              "         [0.55686275]],\n",
              "\n",
              "        [[0.61830065],\n",
              "         [0.6248366 ],\n",
              "         [0.61830065],\n",
              "         ...,\n",
              "         [0.70326797],\n",
              "         [0.68496732],\n",
              "         [0.5751634 ]],\n",
              "\n",
              "        [[0.69542484],\n",
              "         [0.66013072],\n",
              "         [0.66143791],\n",
              "         ...,\n",
              "         [0.76993464],\n",
              "         [0.52418301],\n",
              "         [0.30065359]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.29934641],\n",
              "         [0.24052288],\n",
              "         [0.26405229],\n",
              "         ...,\n",
              "         [0.15816993],\n",
              "         [0.14117647],\n",
              "         [0.16993464]],\n",
              "\n",
              "        [[0.26666667],\n",
              "         [0.27581699],\n",
              "         [0.3124183 ],\n",
              "         ...,\n",
              "         [0.18823529],\n",
              "         [0.1372549 ],\n",
              "         [0.08104575]],\n",
              "\n",
              "        [[0.22614379],\n",
              "         [0.26143791],\n",
              "         [0.30196078],\n",
              "         ...,\n",
              "         [0.20392157],\n",
              "         [0.16993464],\n",
              "         [0.12156863]]],\n",
              "\n",
              "\n",
              "       [[[0.83660131],\n",
              "         [0.82352941],\n",
              "         [0.81960784],\n",
              "         ...,\n",
              "         [0.77647059],\n",
              "         [0.76862745],\n",
              "         [0.7620915 ]],\n",
              "\n",
              "        [[0.84052288],\n",
              "         [0.82875817],\n",
              "         [0.8248366 ],\n",
              "         ...,\n",
              "         [0.76470588],\n",
              "         [0.75816993],\n",
              "         [0.74901961]],\n",
              "\n",
              "        [[0.87712418],\n",
              "         [0.86405229],\n",
              "         [0.86013072],\n",
              "         ...,\n",
              "         [0.7620915 ],\n",
              "         [0.75555556],\n",
              "         [0.75163399]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.76732026],\n",
              "         [0.74901961],\n",
              "         [0.74771242],\n",
              "         ...,\n",
              "         [0.51503268],\n",
              "         [0.61437908],\n",
              "         [0.63006536]],\n",
              "\n",
              "        [[0.72941176],\n",
              "         [0.69150327],\n",
              "         [0.65228758],\n",
              "         ...,\n",
              "         [0.66535948],\n",
              "         [0.65359477],\n",
              "         [0.65098039]],\n",
              "\n",
              "        [[0.73202614],\n",
              "         [0.69542484],\n",
              "         [0.6496732 ],\n",
              "         ...,\n",
              "         [0.71633987],\n",
              "         [0.72679739],\n",
              "         [0.72679739]]],\n",
              "\n",
              "\n",
              "       [[[0.91111111],\n",
              "         [0.94117647],\n",
              "         [0.9372549 ],\n",
              "         ...,\n",
              "         [0.8745098 ],\n",
              "         [0.88627451],\n",
              "         [0.88627451]],\n",
              "\n",
              "        [[0.87843137],\n",
              "         [0.9503268 ],\n",
              "         [0.93202614],\n",
              "         ...,\n",
              "         [0.89150327],\n",
              "         [0.90588235],\n",
              "         [0.8379085 ]],\n",
              "\n",
              "        [[0.82352941],\n",
              "         [0.92156863],\n",
              "         [0.9254902 ],\n",
              "         ...,\n",
              "         [0.87843137],\n",
              "         [0.87712418],\n",
              "         [0.81045752]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.55947712],\n",
              "         [0.5254902 ],\n",
              "         [0.49542484],\n",
              "         ...,\n",
              "         [0.86797386],\n",
              "         [0.89281046],\n",
              "         [0.94117647]],\n",
              "\n",
              "        [[0.51633987],\n",
              "         [0.49281046],\n",
              "         [0.47189542],\n",
              "         ...,\n",
              "         [0.70457516],\n",
              "         [0.78562092],\n",
              "         [0.82352941]],\n",
              "\n",
              "        [[0.46405229],\n",
              "         [0.4496732 ],\n",
              "         [0.45359477],\n",
              "         ...,\n",
              "         [0.69150327],\n",
              "         [0.64052288],\n",
              "         [0.63660131]]]])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train_gray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Wi7Oug6Jmtk",
        "outputId": "683c52ad-f34d-4c9e-f527-e7ee551131da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_60 (Conv2D)          (None, 28, 28, 6)         156       \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_61 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_62 (Conv2D)          (None, 1, 1, 120)         48120     \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 120)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 61,706\n",
            "Trainable params: 61,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(6, (5,5), activation = 'tanh', input_shape= (32,32,1)))\n",
        "\n",
        "model.add(layers.MaxPooling2D(strides=2))\n",
        "\n",
        "model.add(layers.Conv2D(16, (5,5), activation = 'tanh'))\n",
        "\n",
        "model.add(layers.MaxPooling2D(strides=2))\n",
        "\n",
        "model.add(layers.Conv2D(120,(5,5), activation='tanh'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(84, activation='tanh'))\n",
        "\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyO9ypjCKJg-"
      },
      "outputs": [],
      "source": [
        "# \n",
        "\n",
        "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "#     initial_learning_rate=1e-2,\n",
        "#     decay_steps=10000,\n",
        "#     decay_rate=0.96)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JThmro7lvn5w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKyvMOxVddxS",
        "outputId": "0e2e00f8-650f-43ec-a6a3-3ff625df2ef7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "250/250 [==============================] - 13s 48ms/step - loss: 1.9652 - accuracy: 0.2860\n",
            "Epoch 2/25\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 1.5159 - accuracy: 0.4595\n",
            "Epoch 3/25\n",
            "250/250 [==============================] - 13s 50ms/step - loss: 1.3664 - accuracy: 0.5187\n",
            "Epoch 4/25\n",
            "250/250 [==============================] - 13s 50ms/step - loss: 1.2895 - accuracy: 0.5482\n",
            "Epoch 5/25\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 1.2120 - accuracy: 0.5742\n",
            "Epoch 6/25\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 1.1957 - accuracy: 0.5811\n",
            "Epoch 7/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 1.1604 - accuracy: 0.5939\n",
            "Epoch 8/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 1.1392 - accuracy: 0.6024\n",
            "Epoch 9/25\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 1.1388 - accuracy: 0.6024\n",
            "Epoch 10/25\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 1.1188 - accuracy: 0.6081\n",
            "Epoch 11/25\n",
            "250/250 [==============================] - 13s 50ms/step - loss: 1.0993 - accuracy: 0.6166\n",
            "Epoch 12/25\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 1.1021 - accuracy: 0.6160\n",
            "Epoch 13/25\n",
            "250/250 [==============================] - 11s 46ms/step - loss: 1.0796 - accuracy: 0.6234\n",
            "Epoch 14/25\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 1.0984 - accuracy: 0.6174\n",
            "Epoch 15/25\n",
            "250/250 [==============================] - 12s 50ms/step - loss: 1.1073 - accuracy: 0.6144\n",
            "Epoch 16/25\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 1.1021 - accuracy: 0.6181\n",
            "Epoch 17/25\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 1.0769 - accuracy: 0.6240\n",
            "Epoch 18/25\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 1.1009 - accuracy: 0.6153\n",
            "Epoch 19/25\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 1.0938 - accuracy: 0.6186\n",
            "Epoch 20/25\n",
            "250/250 [==============================] - 13s 50ms/step - loss: 1.1019 - accuracy: 0.6167\n",
            "Epoch 21/25\n",
            "250/250 [==============================] - 13s 52ms/step - loss: 1.0923 - accuracy: 0.6201\n",
            "Epoch 22/25\n",
            "250/250 [==============================] - 13s 52ms/step - loss: 1.0949 - accuracy: 0.6208\n",
            "Epoch 23/25\n",
            "250/250 [==============================] - 13s 50ms/step - loss: 1.0824 - accuracy: 0.6224\n",
            "Epoch 24/25\n",
            "250/250 [==============================] - 13s 51ms/step - loss: 1.1115 - accuracy: 0.6115\n",
            "Epoch 25/25\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 1.0883 - accuracy: 0.6198\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.3704 - accuracy: 0.5403\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.0261 - accuracy: 0.6431\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.9768 - accuracy: 0.6601\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.9524 - accuracy: 0.6663\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.9299 - accuracy: 0.6741\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.9133 - accuracy: 0.6791\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.8840 - accuracy: 0.6907\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.8734 - accuracy: 0.6949\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.8756 - accuracy: 0.6939\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.8784 - accuracy: 0.6929\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.8478 - accuracy: 0.7030\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.8454 - accuracy: 0.7050\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8526 - accuracy: 0.7001\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8399 - accuracy: 0.7050\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8292 - accuracy: 0.7092\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.8183 - accuracy: 0.7137\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.8297 - accuracy: 0.7083\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.8204 - accuracy: 0.7138\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.8199 - accuracy: 0.7153\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.8155 - accuracy: 0.7128\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.8250 - accuracy: 0.7101\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7982 - accuracy: 0.7195\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.8080 - accuracy: 0.7187\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7973 - accuracy: 0.7188\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.7854 - accuracy: 0.7242\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7893 - accuracy: 0.7236\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.4367 - accuracy: 0.5511\n",
            "Epoch 1/25\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 0.8060 - accuracy: 0.7180\n",
            "Epoch 2/25\n",
            "72/72 [==============================] - 8s 110ms/step - loss: 0.7078 - accuracy: 0.7529\n",
            "Epoch 3/25\n",
            "72/72 [==============================] - 9s 123ms/step - loss: 0.6981 - accuracy: 0.7557\n",
            "Epoch 4/25\n",
            "72/72 [==============================] - 9s 122ms/step - loss: 0.7199 - accuracy: 0.7466\n",
            "Epoch 5/25\n",
            "72/72 [==============================] - 9s 119ms/step - loss: 0.6835 - accuracy: 0.7597\n",
            "Epoch 6/25\n",
            "72/72 [==============================] - 9s 120ms/step - loss: 0.6551 - accuracy: 0.7705\n",
            "Epoch 7/25\n",
            "72/72 [==============================] - 9s 123ms/step - loss: 0.6767 - accuracy: 0.7615\n",
            "Epoch 8/25\n",
            "72/72 [==============================] - 9s 125ms/step - loss: 0.6992 - accuracy: 0.7530\n",
            "Epoch 9/25\n",
            "72/72 [==============================] - 9s 125ms/step - loss: 0.6675 - accuracy: 0.7656\n",
            "Epoch 10/25\n",
            "72/72 [==============================] - 10s 135ms/step - loss: 0.6605 - accuracy: 0.7698\n",
            "Epoch 11/25\n",
            "72/72 [==============================] - 9s 126ms/step - loss: 0.6394 - accuracy: 0.7739\n",
            "Epoch 12/25\n",
            "72/72 [==============================] - 9s 126ms/step - loss: 0.6341 - accuracy: 0.7758\n",
            "Epoch 13/25\n",
            "72/72 [==============================] - 9s 127ms/step - loss: 0.6120 - accuracy: 0.7834\n",
            "Epoch 14/25\n",
            "72/72 [==============================] - 9s 125ms/step - loss: 0.6379 - accuracy: 0.7756\n",
            "Epoch 15/25\n",
            "72/72 [==============================] - 9s 131ms/step - loss: 0.6200 - accuracy: 0.7805\n",
            "Epoch 16/25\n",
            "72/72 [==============================] - 9s 121ms/step - loss: 0.6488 - accuracy: 0.7731\n",
            "Epoch 17/25\n",
            "72/72 [==============================] - 8s 117ms/step - loss: 0.6261 - accuracy: 0.7807\n",
            "Epoch 18/25\n",
            "72/72 [==============================] - 9s 119ms/step - loss: 0.6437 - accuracy: 0.7726\n",
            "Epoch 19/25\n",
            "72/72 [==============================] - 8s 115ms/step - loss: 0.6168 - accuracy: 0.7816\n",
            "Epoch 20/25\n",
            "72/72 [==============================] - 9s 121ms/step - loss: 0.6155 - accuracy: 0.7823\n",
            "Epoch 21/25\n",
            "72/72 [==============================] - 9s 123ms/step - loss: 0.6361 - accuracy: 0.7754\n",
            "Epoch 22/25\n",
            "72/72 [==============================] - 9s 121ms/step - loss: 0.6493 - accuracy: 0.7697\n",
            "Epoch 23/25\n",
            "72/72 [==============================] - 9s 124ms/step - loss: 0.6164 - accuracy: 0.7829\n",
            "Epoch 24/25\n",
            "72/72 [==============================] - 9s 124ms/step - loss: 0.6172 - accuracy: 0.7834\n",
            "Epoch 25/25\n",
            "72/72 [==============================] - 9s 126ms/step - loss: 0.6077 - accuracy: 0.7851\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.6447 - accuracy: 0.5529\n",
            "Epoch 1/25\n",
            "59/59 [==============================] - 8s 125ms/step - loss: 0.6270 - accuracy: 0.7785\n",
            "Epoch 2/25\n",
            "59/59 [==============================] - 9s 147ms/step - loss: 0.5643 - accuracy: 0.8019\n",
            "Epoch 3/25\n",
            "59/59 [==============================] - 9s 151ms/step - loss: 0.5480 - accuracy: 0.8079\n",
            "Epoch 4/25\n",
            "59/59 [==============================] - 9s 152ms/step - loss: 0.5349 - accuracy: 0.8116\n",
            "Epoch 5/25\n",
            "59/59 [==============================] - 9s 147ms/step - loss: 0.5410 - accuracy: 0.8085\n",
            "Epoch 6/25\n",
            "59/59 [==============================] - 9s 144ms/step - loss: 0.5174 - accuracy: 0.8175\n",
            "Epoch 7/25\n",
            "59/59 [==============================] - 9s 146ms/step - loss: 0.5019 - accuracy: 0.8220\n",
            "Epoch 8/25\n",
            "59/59 [==============================] - 8s 141ms/step - loss: 0.5045 - accuracy: 0.8224\n",
            "Epoch 9/25\n",
            "59/59 [==============================] - 9s 149ms/step - loss: 0.4980 - accuracy: 0.8251\n",
            "Epoch 10/25\n",
            "59/59 [==============================] - 8s 139ms/step - loss: 0.4865 - accuracy: 0.8303\n",
            "Epoch 11/25\n",
            "59/59 [==============================] - 8s 136ms/step - loss: 0.5009 - accuracy: 0.8247\n",
            "Epoch 12/25\n",
            "59/59 [==============================] - 8s 133ms/step - loss: 0.4898 - accuracy: 0.8272\n",
            "Epoch 13/25\n",
            "59/59 [==============================] - 8s 135ms/step - loss: 0.4904 - accuracy: 0.8261\n",
            "Epoch 14/25\n",
            "59/59 [==============================] - 8s 136ms/step - loss: 0.5428 - accuracy: 0.8072\n",
            "Epoch 15/25\n",
            "59/59 [==============================] - 8s 136ms/step - loss: 0.5064 - accuracy: 0.8215\n",
            "Epoch 16/25\n",
            "59/59 [==============================] - 8s 140ms/step - loss: 0.4973 - accuracy: 0.8260\n",
            "Epoch 17/25\n",
            "59/59 [==============================] - 8s 142ms/step - loss: 0.5071 - accuracy: 0.8225\n",
            "Epoch 18/25\n",
            "59/59 [==============================] - 9s 156ms/step - loss: 0.4736 - accuracy: 0.8338\n",
            "Epoch 19/25\n",
            "59/59 [==============================] - 9s 147ms/step - loss: 0.4593 - accuracy: 0.8381\n",
            "Epoch 20/25\n",
            "59/59 [==============================] - 9s 145ms/step - loss: 0.4867 - accuracy: 0.8287\n",
            "Epoch 21/25\n",
            "59/59 [==============================] - 9s 149ms/step - loss: 0.4896 - accuracy: 0.8268\n",
            "Epoch 22/25\n",
            "59/59 [==============================] - 9s 152ms/step - loss: 0.4793 - accuracy: 0.8306\n",
            "Epoch 23/25\n",
            "59/59 [==============================] - 9s 148ms/step - loss: 0.4419 - accuracy: 0.8446\n",
            "Epoch 24/25\n",
            "59/59 [==============================] - 9s 145ms/step - loss: 0.4555 - accuracy: 0.8390\n",
            "Epoch 25/25\n",
            "59/59 [==============================] - 9s 147ms/step - loss: 0.4907 - accuracy: 0.8275\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 1.9340 - accuracy: 0.5435\n",
            "Epoch 1/25\n",
            "250/250 [==============================] - 13s 49ms/step - loss: 2.7685 - accuracy: 0.1047\n",
            "Epoch 2/25\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 2.6012 - accuracy: 0.1023\n",
            "Epoch 3/25\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 2.5735 - accuracy: 0.1007\n",
            "Epoch 4/25\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 2.5433 - accuracy: 0.1005\n",
            "Epoch 5/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.5192 - accuracy: 0.1001\n",
            "Epoch 6/25\n",
            "250/250 [==============================] - 11s 43ms/step - loss: 2.6630 - accuracy: 0.0989\n",
            "Epoch 7/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.6007 - accuracy: 0.0997\n",
            "Epoch 8/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.5826 - accuracy: 0.0983\n",
            "Epoch 9/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.5375 - accuracy: 0.1002\n",
            "Epoch 10/25\n",
            "250/250 [==============================] - 11s 46ms/step - loss: 2.5198 - accuracy: 0.1004\n",
            "Epoch 11/25\n",
            "250/250 [==============================] - 11s 46ms/step - loss: 2.5676 - accuracy: 0.0999\n",
            "Epoch 12/25\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 2.5675 - accuracy: 0.0983\n",
            "Epoch 13/25\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 2.5795 - accuracy: 0.1003\n",
            "Epoch 14/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.5303 - accuracy: 0.1004\n",
            "Epoch 15/25\n",
            "250/250 [==============================] - 11s 46ms/step - loss: 2.6613 - accuracy: 0.0998\n",
            "Epoch 16/25\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 2.5317 - accuracy: 0.1020\n",
            "Epoch 17/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.6442 - accuracy: 0.1012\n",
            "Epoch 18/25\n",
            "250/250 [==============================] - 11s 46ms/step - loss: 2.5447 - accuracy: 0.0991\n",
            "Epoch 19/25\n",
            "250/250 [==============================] - 12s 46ms/step - loss: 2.7831 - accuracy: 0.1000\n",
            "Epoch 20/25\n",
            "250/250 [==============================] - 12s 50ms/step - loss: 2.5378 - accuracy: 0.1023\n",
            "Epoch 21/25\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 2.5427 - accuracy: 0.1000\n",
            "Epoch 22/25\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 2.6157 - accuracy: 0.0977\n",
            "Epoch 23/25\n",
            "250/250 [==============================] - 13s 50ms/step - loss: 2.5207 - accuracy: 0.0999\n",
            "Epoch 24/25\n",
            "250/250 [==============================] - 12s 50ms/step - loss: 2.4997 - accuracy: 0.1029\n",
            "Epoch 25/25\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 2.7003 - accuracy: 0.1001\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 2.4270 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 9s 82ms/step - loss: 3.4735 - accuracy: 0.1006\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.3844 - accuracy: 0.0989\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.4207 - accuracy: 0.0965\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 2.4037 - accuracy: 0.1001\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.4281 - accuracy: 0.0983\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.6660 - accuracy: 0.1018\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 3.7121 - accuracy: 0.0989\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3785 - accuracy: 0.1014\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 2.3864 - accuracy: 0.1010\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 2.3916 - accuracy: 0.1005\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 2.4329 - accuracy: 0.0986\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 2.3999 - accuracy: 0.0996\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 2.4740 - accuracy: 0.0999\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 2.5036 - accuracy: 0.0968\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 2.8224 - accuracy: 0.1014\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 2.5344 - accuracy: 0.0996\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 2.5067 - accuracy: 0.1002\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 3.0749 - accuracy: 0.1008\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 4.9478 - accuracy: 0.0985\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 3.0364 - accuracy: 0.0995\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 2.3677 - accuracy: 0.0988\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 2.3721 - accuracy: 0.1006\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 2.3760 - accuracy: 0.0982\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 2.3809 - accuracy: 0.0979\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 2.3649 - accuracy: 0.1006\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 2.3416 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 3.6730 - accuracy: 0.1016\n",
            "Epoch 2/25\n",
            "72/72 [==============================] - 9s 126ms/step - loss: 2.3399 - accuracy: 0.1025\n",
            "Epoch 3/25\n",
            "72/72 [==============================] - 10s 133ms/step - loss: 2.3452 - accuracy: 0.1002\n",
            "Epoch 4/25\n",
            "72/72 [==============================] - 9s 119ms/step - loss: 2.3601 - accuracy: 0.0986\n",
            "Epoch 5/25\n",
            "72/72 [==============================] - 9s 121ms/step - loss: 2.4855 - accuracy: 0.0986\n",
            "Epoch 6/25\n",
            "72/72 [==============================] - 9s 120ms/step - loss: 2.6487 - accuracy: 0.0984\n",
            "Epoch 7/25\n",
            "72/72 [==============================] - 9s 119ms/step - loss: 2.3928 - accuracy: 0.0976\n",
            "Epoch 8/25\n",
            "72/72 [==============================] - 9s 118ms/step - loss: 2.3730 - accuracy: 0.1018\n",
            "Epoch 9/25\n",
            "72/72 [==============================] - 9s 119ms/step - loss: 2.3755 - accuracy: 0.1011\n",
            "Epoch 10/25\n",
            "72/72 [==============================] - 9s 119ms/step - loss: 2.4042 - accuracy: 0.1015\n",
            "Epoch 11/25\n",
            "72/72 [==============================] - 8s 117ms/step - loss: 2.7225 - accuracy: 0.0987\n",
            "Epoch 12/25\n",
            "72/72 [==============================] - 8s 117ms/step - loss: 2.7378 - accuracy: 0.1024\n",
            "Epoch 13/25\n",
            "72/72 [==============================] - 8s 117ms/step - loss: 2.4022 - accuracy: 0.1004\n",
            "Epoch 14/25\n",
            "72/72 [==============================] - 9s 127ms/step - loss: 2.3972 - accuracy: 0.0996\n",
            "Epoch 15/25\n",
            "72/72 [==============================] - 9s 125ms/step - loss: 2.3971 - accuracy: 0.1019\n",
            "Epoch 16/25\n",
            "72/72 [==============================] - 9s 121ms/step - loss: 2.4911 - accuracy: 0.1005\n",
            "Epoch 17/25\n",
            "72/72 [==============================] - 9s 122ms/step - loss: 2.9132 - accuracy: 0.0990\n",
            "Epoch 18/25\n",
            "72/72 [==============================] - 9s 122ms/step - loss: 3.8136 - accuracy: 0.0982\n",
            "Epoch 19/25\n",
            "72/72 [==============================] - 9s 121ms/step - loss: 3.2488 - accuracy: 0.0991\n",
            "Epoch 20/25\n",
            "72/72 [==============================] - 9s 119ms/step - loss: 2.4396 - accuracy: 0.0991\n",
            "Epoch 21/25\n",
            "72/72 [==============================] - 9s 120ms/step - loss: 2.3603 - accuracy: 0.0997\n",
            "Epoch 22/25\n",
            "72/72 [==============================] - 9s 120ms/step - loss: 2.3926 - accuracy: 0.0999\n",
            "Epoch 23/25\n",
            "72/72 [==============================] - 8s 114ms/step - loss: 2.3749 - accuracy: 0.1007\n",
            "Epoch 24/25\n",
            "72/72 [==============================] - 9s 123ms/step - loss: 2.3650 - accuracy: 0.0984\n",
            "Epoch 25/25\n",
            "72/72 [==============================] - 8s 117ms/step - loss: 2.3725 - accuracy: 0.0995\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 2.4055 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "59/59 [==============================] - 8s 119ms/step - loss: 4.5581 - accuracy: 0.1005\n",
            "Epoch 2/25\n",
            "59/59 [==============================] - 8s 138ms/step - loss: 2.3415 - accuracy: 0.0986\n",
            "Epoch 3/25\n",
            "59/59 [==============================] - 8s 140ms/step - loss: 2.3435 - accuracy: 0.0989\n",
            "Epoch 4/25\n",
            "59/59 [==============================] - 8s 142ms/step - loss: 2.3477 - accuracy: 0.1009\n",
            "Epoch 5/25\n",
            "59/59 [==============================] - 8s 141ms/step - loss: 2.3461 - accuracy: 0.0996\n",
            "Epoch 6/25\n",
            "59/59 [==============================] - 8s 141ms/step - loss: 2.3516 - accuracy: 0.1005\n",
            "Epoch 7/25\n",
            "59/59 [==============================] - 8s 141ms/step - loss: 2.3894 - accuracy: 0.0983\n",
            "Epoch 8/25\n",
            "59/59 [==============================] - 8s 141ms/step - loss: 2.3788 - accuracy: 0.0996\n",
            "Epoch 9/25\n",
            "59/59 [==============================] - 9s 144ms/step - loss: 2.4194 - accuracy: 0.0993\n",
            "Epoch 10/25\n",
            "59/59 [==============================] - 8s 144ms/step - loss: 2.3770 - accuracy: 0.1008\n",
            "Epoch 11/25\n",
            "59/59 [==============================] - 9s 145ms/step - loss: 2.4557 - accuracy: 0.1003\n",
            "Epoch 12/25\n",
            "59/59 [==============================] - 8s 142ms/step - loss: 2.4132 - accuracy: 0.1008\n",
            "Epoch 13/25\n",
            "59/59 [==============================] - 8s 139ms/step - loss: 2.3747 - accuracy: 0.1000\n",
            "Epoch 14/25\n",
            "59/59 [==============================] - 8s 136ms/step - loss: 2.3961 - accuracy: 0.1014\n",
            "Epoch 15/25\n",
            "59/59 [==============================] - 8s 140ms/step - loss: 2.4474 - accuracy: 0.0989\n",
            "Epoch 16/25\n",
            "59/59 [==============================] - 8s 138ms/step - loss: 2.4079 - accuracy: 0.1029\n",
            "Epoch 17/25\n",
            "59/59 [==============================] - 8s 140ms/step - loss: 2.6196 - accuracy: 0.0993\n",
            "Epoch 18/25\n",
            "59/59 [==============================] - 8s 135ms/step - loss: 7.8939 - accuracy: 0.1004\n",
            "Epoch 19/25\n",
            "59/59 [==============================] - 8s 140ms/step - loss: 3.6738 - accuracy: 0.0990\n",
            "Epoch 20/25\n",
            "59/59 [==============================] - 8s 141ms/step - loss: 2.3422 - accuracy: 0.0999\n",
            "Epoch 21/25\n",
            "59/59 [==============================] - 9s 154ms/step - loss: 2.3530 - accuracy: 0.1003\n",
            "Epoch 22/25\n",
            "59/59 [==============================] - 8s 137ms/step - loss: 2.3554 - accuracy: 0.1001\n",
            "Epoch 23/25\n",
            "59/59 [==============================] - 8s 140ms/step - loss: 2.3530 - accuracy: 0.1004\n",
            "Epoch 24/25\n",
            "59/59 [==============================] - 9s 144ms/step - loss: 2.3440 - accuracy: 0.1012\n",
            "Epoch 25/25\n",
            "59/59 [==============================] - 9s 145ms/step - loss: 2.3472 - accuracy: 0.0989\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 2.3138 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "250/250 [==============================] - 13s 48ms/step - loss: 6.6181 - accuracy: 0.0996\n",
            "Epoch 2/25\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 6.6288 - accuracy: 0.1031\n",
            "Epoch 3/25\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 3.2634 - accuracy: 0.0997\n",
            "Epoch 4/25\n",
            "250/250 [==============================] - 11s 43ms/step - loss: 7.3757 - accuracy: 0.1022\n",
            "Epoch 5/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 7.9440 - accuracy: 0.1000\n",
            "Epoch 6/25\n",
            "250/250 [==============================] - 11s 46ms/step - loss: 4.2646 - accuracy: 0.0980\n",
            "Epoch 7/25\n",
            "250/250 [==============================] - 11s 43ms/step - loss: 4.3027 - accuracy: 0.1011\n",
            "Epoch 8/25\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 8.4167 - accuracy: 0.1011\n",
            "Epoch 9/25\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 7.2961 - accuracy: 0.0996\n",
            "Epoch 10/25\n",
            "250/250 [==============================] - 12s 46ms/step - loss: 5.9085 - accuracy: 0.1004\n",
            "Epoch 11/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.6931 - accuracy: 0.1018\n",
            "Epoch 12/25\n",
            "250/250 [==============================] - 14s 56ms/step - loss: 7.1468 - accuracy: 0.0980\n",
            "Epoch 13/25\n",
            "250/250 [==============================] - 10s 40ms/step - loss: 5.8089 - accuracy: 0.0997\n",
            "Epoch 14/25\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 3.4854 - accuracy: 0.1021\n",
            "Epoch 15/25\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 9.5874 - accuracy: 0.0998\n",
            "Epoch 16/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 4.8728 - accuracy: 0.1014\n",
            "Epoch 17/25\n",
            "250/250 [==============================] - 11s 46ms/step - loss: 6.3580 - accuracy: 0.0985\n",
            "Epoch 18/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 7.3207 - accuracy: 0.1015\n",
            "Epoch 19/25\n",
            "250/250 [==============================] - 12s 46ms/step - loss: 2.7095 - accuracy: 0.0999\n",
            "Epoch 20/25\n",
            "250/250 [==============================] - 13s 50ms/step - loss: 6.4501 - accuracy: 0.1017\n",
            "Epoch 21/25\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 7.4884 - accuracy: 0.0990\n",
            "Epoch 22/25\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 8.0445 - accuracy: 0.0988\n",
            "Epoch 23/25\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 3.0846 - accuracy: 0.0998\n",
            "Epoch 24/25\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 2.9102 - accuracy: 0.0989\n",
            "Epoch 25/25\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 9.3805 - accuracy: 0.0980\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 7.5627 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 11.6976 - accuracy: 0.0970\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 2.4698 - accuracy: 0.0974\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 8.0413 - accuracy: 0.1002\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 10.1634 - accuracy: 0.0999\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 4.3823 - accuracy: 0.0986\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 2.3924 - accuracy: 0.1001\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 2.4618 - accuracy: 0.1013\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 4.8505 - accuracy: 0.1019\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 12.1017 - accuracy: 0.1007\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 9.1925 - accuracy: 0.0980\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 8.7888 - accuracy: 0.0989\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 7.2312 - accuracy: 0.1015\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 3.4728 - accuracy: 0.0977\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 2.3662 - accuracy: 0.0991\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 2.3869 - accuracy: 0.0997\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 2.4061 - accuracy: 0.1002\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 2.4325 - accuracy: 0.0994\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 2.6783 - accuracy: 0.1021\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 12.0197 - accuracy: 0.0993\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 11.1809 - accuracy: 0.0993\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 11.0352 - accuracy: 0.1001\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 9.5057 - accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 8.0576 - accuracy: 0.0988\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 5.9930 - accuracy: 0.0999\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 2.4021 - accuracy: 0.1008\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 2.3352 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "72/72 [==============================] - 10s 125ms/step - loss: 12.3763 - accuracy: 0.1020\n",
            "Epoch 2/25\n",
            "72/72 [==============================] - 9s 122ms/step - loss: 2.6217 - accuracy: 0.0997\n",
            "Epoch 3/25\n",
            "72/72 [==============================] - 9s 130ms/step - loss: 2.3769 - accuracy: 0.1014\n",
            "Epoch 4/25\n",
            "72/72 [==============================] - 9s 126ms/step - loss: 3.3592 - accuracy: 0.0996\n",
            "Epoch 5/25\n",
            "72/72 [==============================] - 10s 132ms/step - loss: 13.5331 - accuracy: 0.0985\n",
            "Epoch 6/25\n",
            "72/72 [==============================] - 10s 133ms/step - loss: 10.3473 - accuracy: 0.1008\n",
            "Epoch 7/25\n",
            "72/72 [==============================] - 10s 138ms/step - loss: 3.8796 - accuracy: 0.0984\n",
            "Epoch 8/25\n",
            "72/72 [==============================] - 9s 129ms/step - loss: 2.5710 - accuracy: 0.1008\n",
            "Epoch 9/25\n",
            "72/72 [==============================] - 9s 131ms/step - loss: 2.3763 - accuracy: 0.1010\n",
            "Epoch 10/25\n",
            "72/72 [==============================] - 9s 122ms/step - loss: 2.4288 - accuracy: 0.0994\n",
            "Epoch 11/25\n",
            "72/72 [==============================] - 9s 121ms/step - loss: 7.0236 - accuracy: 0.1012\n",
            "Epoch 12/25\n",
            "72/72 [==============================] - 9s 118ms/step - loss: 16.5015 - accuracy: 0.1002\n",
            "Epoch 13/25\n",
            "72/72 [==============================] - 9s 120ms/step - loss: 10.9917 - accuracy: 0.0977\n",
            "Epoch 14/25\n",
            "72/72 [==============================] - 9s 123ms/step - loss: 8.4321 - accuracy: 0.1005\n",
            "Epoch 15/25\n",
            "72/72 [==============================] - 9s 120ms/step - loss: 5.0171 - accuracy: 0.1008\n",
            "Epoch 16/25\n",
            "72/72 [==============================] - 9s 119ms/step - loss: 2.9920 - accuracy: 0.1000\n",
            "Epoch 17/25\n",
            "72/72 [==============================] - 9s 122ms/step - loss: 2.3859 - accuracy: 0.1034\n",
            "Epoch 18/25\n",
            "72/72 [==============================] - 9s 123ms/step - loss: 2.3815 - accuracy: 0.0996\n",
            "Epoch 19/25\n",
            "72/72 [==============================] - 9s 118ms/step - loss: 2.3682 - accuracy: 0.1007\n",
            "Epoch 20/25\n",
            "72/72 [==============================] - 9s 121ms/step - loss: 2.3953 - accuracy: 0.0990\n",
            "Epoch 21/25\n",
            "72/72 [==============================] - 9s 123ms/step - loss: 2.5730 - accuracy: 0.0999\n",
            "Epoch 22/25\n",
            "72/72 [==============================] - 9s 121ms/step - loss: 5.4811 - accuracy: 0.0990\n",
            "Epoch 23/25\n",
            "72/72 [==============================] - 9s 120ms/step - loss: 17.4957 - accuracy: 0.1014\n",
            "Epoch 24/25\n",
            "72/72 [==============================] - 9s 122ms/step - loss: 11.6963 - accuracy: 0.0988\n",
            "Epoch 25/25\n",
            "72/72 [==============================] - 9s 120ms/step - loss: 12.0269 - accuracy: 0.0993\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 15.9585 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "59/59 [==============================] - 8s 120ms/step - loss: 17.1406 - accuracy: 0.1008\n",
            "Epoch 2/25\n",
            "59/59 [==============================] - 9s 146ms/step - loss: 5.0262 - accuracy: 0.0994\n",
            "Epoch 3/25\n",
            "59/59 [==============================] - 9s 144ms/step - loss: 2.5253 - accuracy: 0.1009\n",
            "Epoch 4/25\n",
            "59/59 [==============================] - 9s 149ms/step - loss: 2.3680 - accuracy: 0.1033\n",
            "Epoch 5/25\n",
            "59/59 [==============================] - 8s 139ms/step - loss: 2.3601 - accuracy: 0.0985\n",
            "Epoch 6/25\n",
            "59/59 [==============================] - 9s 145ms/step - loss: 3.5556 - accuracy: 0.0999\n",
            "Epoch 7/25\n",
            "59/59 [==============================] - 8s 138ms/step - loss: 10.5789 - accuracy: 0.0984\n",
            "Epoch 8/25\n",
            "59/59 [==============================] - 8s 139ms/step - loss: 11.2275 - accuracy: 0.1013\n",
            "Epoch 9/25\n",
            "59/59 [==============================] - 8s 141ms/step - loss: 9.5939 - accuracy: 0.0997\n",
            "Epoch 10/25\n",
            "59/59 [==============================] - 8s 140ms/step - loss: 9.8316 - accuracy: 0.0994\n",
            "Epoch 11/25\n",
            "59/59 [==============================] - 8s 142ms/step - loss: 7.3028 - accuracy: 0.0944\n",
            "Epoch 12/25\n",
            "59/59 [==============================] - 8s 140ms/step - loss: 4.8477 - accuracy: 0.0991\n",
            "Epoch 13/25\n",
            "59/59 [==============================] - 8s 143ms/step - loss: 5.4645 - accuracy: 0.1009\n",
            "Epoch 14/25\n",
            "59/59 [==============================] - 8s 142ms/step - loss: 5.7041 - accuracy: 0.1000\n",
            "Epoch 15/25\n",
            "59/59 [==============================] - 8s 141ms/step - loss: 3.6488 - accuracy: 0.1004\n",
            "Epoch 16/25\n",
            "59/59 [==============================] - 8s 142ms/step - loss: 2.3579 - accuracy: 0.0975\n",
            "Epoch 17/25\n",
            "59/59 [==============================] - 8s 144ms/step - loss: 2.3461 - accuracy: 0.1009\n",
            "Epoch 18/25\n",
            "59/59 [==============================] - 9s 158ms/step - loss: 2.3572 - accuracy: 0.1023\n",
            "Epoch 19/25\n",
            "59/59 [==============================] - 9s 145ms/step - loss: 2.3575 - accuracy: 0.0982\n",
            "Epoch 20/25\n",
            "59/59 [==============================] - 8s 138ms/step - loss: 2.3395 - accuracy: 0.0993\n",
            "Epoch 21/25\n",
            "59/59 [==============================] - 9s 145ms/step - loss: 2.3568 - accuracy: 0.1000\n",
            "Epoch 22/25\n",
            "59/59 [==============================] - 8s 143ms/step - loss: 2.3578 - accuracy: 0.1000\n",
            "Epoch 23/25\n",
            "59/59 [==============================] - 8s 142ms/step - loss: 2.3804 - accuracy: 0.0989\n",
            "Epoch 24/25\n",
            "59/59 [==============================] - 9s 144ms/step - loss: 2.4029 - accuracy: 0.0998\n",
            "Epoch 25/25\n",
            "59/59 [==============================] - 11s 191ms/step - loss: 2.7771 - accuracy: 0.0995\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 5.2979 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 20.8635 - accuracy: 0.0998\n",
            "Epoch 2/25\n",
            "250/250 [==============================] - 12s 46ms/step - loss: 21.4217 - accuracy: 0.1009\n",
            "Epoch 3/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 15.3436 - accuracy: 0.1004\n",
            "Epoch 4/25\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 18.9806 - accuracy: 0.0979\n",
            "Epoch 5/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 17.3404 - accuracy: 0.0997\n",
            "Epoch 6/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 17.0777 - accuracy: 0.1033\n",
            "Epoch 7/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 19.5624 - accuracy: 0.1001\n",
            "Epoch 8/25\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 17.4845 - accuracy: 0.0975\n",
            "Epoch 9/25\n",
            "250/250 [==============================] - 11s 42ms/step - loss: 18.4222 - accuracy: 0.0994\n",
            "Epoch 10/25\n",
            "250/250 [==============================] - 11s 46ms/step - loss: 19.7326 - accuracy: 0.0989\n",
            "Epoch 11/25\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 18.9598 - accuracy: 0.0991\n",
            "Epoch 12/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 17.1827 - accuracy: 0.1004\n",
            "Epoch 13/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 18.1122 - accuracy: 0.1017\n",
            "Epoch 14/25\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 17.2959 - accuracy: 0.0983\n",
            "Epoch 15/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 16.5355 - accuracy: 0.0989\n",
            "Epoch 16/25\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 18.5118 - accuracy: 0.0989\n",
            "Epoch 17/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 16.7287 - accuracy: 0.0995\n",
            "Epoch 18/25\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 17.8869 - accuracy: 0.0986\n",
            "Epoch 19/25\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 16.6900 - accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 16.8421 - accuracy: 0.0992\n",
            "Epoch 21/25\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 17.8552 - accuracy: 0.0983\n",
            "Epoch 22/25\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 18.4976 - accuracy: 0.1009\n",
            "Epoch 23/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 17.7018 - accuracy: 0.1004\n",
            "Epoch 24/25\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 17.1000 - accuracy: 0.1007\n",
            "Epoch 25/25\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 16.9545 - accuracy: 0.1000\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 15.3078 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 9s 81ms/step - loss: 27.8626 - accuracy: 0.1008\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 13.0811 - accuracy: 0.1001\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 15.2165 - accuracy: 0.0982\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 16.4193 - accuracy: 0.0990\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 20.6119 - accuracy: 0.1001\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 15.5728 - accuracy: 0.1001\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 16.3797 - accuracy: 0.1015\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 15.4184 - accuracy: 0.0989\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 14.5379 - accuracy: 0.1008\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 15.2595 - accuracy: 0.0996\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 15.3577 - accuracy: 0.1027\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 15.6010 - accuracy: 0.0993\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 19.5557 - accuracy: 0.1003\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 16.2711 - accuracy: 0.1018\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 17.8969 - accuracy: 0.1013\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 16.9799 - accuracy: 0.0997\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 14.2119 - accuracy: 0.0999\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 16.1679 - accuracy: 0.1006\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 19.1831 - accuracy: 0.1014\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 15.7907 - accuracy: 0.1010\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 16.1319 - accuracy: 0.0996\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 17.4497 - accuracy: 0.0992\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 16.3587 - accuracy: 0.0999\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 14.9898 - accuracy: 0.1016\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 14.3753 - accuracy: 0.0987\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 20.1115 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "72/72 [==============================] - 9s 117ms/step - loss: 41.0237 - accuracy: 0.0998\n",
            "Epoch 2/25\n",
            "72/72 [==============================] - 9s 132ms/step - loss: 16.2239 - accuracy: 0.1024\n",
            "Epoch 3/25\n",
            "72/72 [==============================] - 9s 124ms/step - loss: 18.4801 - accuracy: 0.1002\n",
            "Epoch 4/25\n",
            "72/72 [==============================] - 9s 122ms/step - loss: 22.6277 - accuracy: 0.1007\n",
            "Epoch 5/25\n",
            "72/72 [==============================] - 9s 121ms/step - loss: 16.3486 - accuracy: 0.1005\n",
            "Epoch 6/25\n",
            "72/72 [==============================] - 9s 120ms/step - loss: 16.1242 - accuracy: 0.0991\n",
            "Epoch 7/25\n",
            "72/72 [==============================] - 9s 121ms/step - loss: 17.6864 - accuracy: 0.0994\n",
            "Epoch 8/25\n",
            "72/72 [==============================] - 9s 121ms/step - loss: 15.8825 - accuracy: 0.0984\n",
            "Epoch 9/25\n",
            "72/72 [==============================] - 9s 121ms/step - loss: 13.3140 - accuracy: 0.0967\n",
            "Epoch 10/25\n",
            "72/72 [==============================] - 9s 127ms/step - loss: 16.8589 - accuracy: 0.1007\n",
            "Epoch 11/25\n",
            "72/72 [==============================] - 9s 124ms/step - loss: 17.8025 - accuracy: 0.1006\n",
            "Epoch 12/25\n",
            "72/72 [==============================] - 9s 131ms/step - loss: 18.4609 - accuracy: 0.0987\n",
            "Epoch 13/25\n",
            "72/72 [==============================] - 9s 130ms/step - loss: 16.5029 - accuracy: 0.0998\n",
            "Epoch 14/25\n",
            "72/72 [==============================] - 9s 123ms/step - loss: 15.3864 - accuracy: 0.1002\n",
            "Epoch 15/25\n",
            "72/72 [==============================] - 9s 120ms/step - loss: 19.3563 - accuracy: 0.1004\n",
            "Epoch 16/25\n",
            "72/72 [==============================] - 9s 127ms/step - loss: 18.5993 - accuracy: 0.1002\n",
            "Epoch 17/25\n",
            "72/72 [==============================] - 9s 119ms/step - loss: 15.5599 - accuracy: 0.1007\n",
            "Epoch 18/25\n",
            "72/72 [==============================] - 9s 124ms/step - loss: 17.1335 - accuracy: 0.1011\n",
            "Epoch 19/25\n",
            "72/72 [==============================] - 9s 122ms/step - loss: 13.7405 - accuracy: 0.1016\n",
            "Epoch 20/25\n",
            "72/72 [==============================] - 9s 122ms/step - loss: 14.3351 - accuracy: 0.1009\n",
            "Epoch 21/25\n",
            "72/72 [==============================] - 9s 123ms/step - loss: 15.8442 - accuracy: 0.1006\n",
            "Epoch 22/25\n",
            "72/72 [==============================] - 9s 121ms/step - loss: 16.8275 - accuracy: 0.1000\n",
            "Epoch 23/25\n",
            "72/72 [==============================] - 9s 121ms/step - loss: 18.3410 - accuracy: 0.1010\n",
            "Epoch 24/25\n",
            "72/72 [==============================] - 9s 120ms/step - loss: 20.0705 - accuracy: 0.0977\n",
            "Epoch 25/25\n",
            "72/72 [==============================] - 9s 120ms/step - loss: 13.4414 - accuracy: 0.1013\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 16.7041 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "59/59 [==============================] - 8s 117ms/step - loss: 46.4873 - accuracy: 0.1006\n",
            "Epoch 2/25\n",
            "59/59 [==============================] - 8s 143ms/step - loss: 17.0382 - accuracy: 0.0992\n",
            "Epoch 3/25\n",
            "59/59 [==============================] - 8s 141ms/step - loss: 16.8315 - accuracy: 0.0990\n",
            "Epoch 4/25\n",
            "59/59 [==============================] - 8s 142ms/step - loss: 17.3674 - accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "59/59 [==============================] - 8s 139ms/step - loss: 16.0077 - accuracy: 0.1000\n",
            "Epoch 6/25\n",
            "59/59 [==============================] - 8s 140ms/step - loss: 18.6068 - accuracy: 0.1011\n",
            "Epoch 7/25\n",
            "59/59 [==============================] - 9s 145ms/step - loss: 18.3420 - accuracy: 0.0992\n",
            "Epoch 8/25\n",
            "59/59 [==============================] - 9s 146ms/step - loss: 19.3609 - accuracy: 0.1021\n",
            "Epoch 9/25\n",
            "59/59 [==============================] - 8s 142ms/step - loss: 17.2132 - accuracy: 0.1004\n",
            "Epoch 10/25\n",
            "59/59 [==============================] - 10s 161ms/step - loss: 15.4245 - accuracy: 0.0999\n",
            "Epoch 11/25\n",
            "59/59 [==============================] - 9s 157ms/step - loss: 15.4415 - accuracy: 0.0988\n",
            "Epoch 12/25\n",
            "59/59 [==============================] - 8s 141ms/step - loss: 18.6255 - accuracy: 0.0987\n",
            "Epoch 13/25\n",
            "59/59 [==============================] - 8s 141ms/step - loss: 20.2922 - accuracy: 0.1016\n",
            "Epoch 14/25\n",
            "59/59 [==============================] - 8s 142ms/step - loss: 17.3862 - accuracy: 0.1021\n",
            "Epoch 15/25\n",
            "59/59 [==============================] - 8s 143ms/step - loss: 16.3852 - accuracy: 0.1008\n",
            "Epoch 16/25\n",
            "59/59 [==============================] - 8s 141ms/step - loss: 17.1857 - accuracy: 0.1005\n",
            "Epoch 17/25\n",
            "59/59 [==============================] - 8s 144ms/step - loss: 22.1678 - accuracy: 0.1014\n",
            "Epoch 18/25\n",
            "59/59 [==============================] - 8s 143ms/step - loss: 15.7246 - accuracy: 0.0994\n",
            "Epoch 19/25\n",
            "59/59 [==============================] - 8s 141ms/step - loss: 17.9097 - accuracy: 0.1013\n",
            "Epoch 20/25\n",
            "59/59 [==============================] - 9s 146ms/step - loss: 16.3057 - accuracy: 0.1009\n",
            "Epoch 21/25\n",
            "59/59 [==============================] - 8s 143ms/step - loss: 19.2041 - accuracy: 0.1009\n",
            "Epoch 22/25\n",
            "59/59 [==============================] - 9s 147ms/step - loss: 16.9369 - accuracy: 0.0980\n",
            "Epoch 23/25\n",
            "59/59 [==============================] - 8s 143ms/step - loss: 22.3574 - accuracy: 0.0992\n",
            "Epoch 24/25\n",
            "59/59 [==============================] - 8s 140ms/step - loss: 17.5144 - accuracy: 0.0989\n",
            "Epoch 25/25\n",
            "59/59 [==============================] - 9s 145ms/step - loss: 15.9188 - accuracy: 0.0972\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 11.8674 - accuracy: 0.1000\n"
          ]
        }
      ],
      "source": [
        "scores = []\n",
        "params = []\n",
        "for i in [0.01,0.1,0.25,0.5]:\n",
        "  for j in [200,500,700,850]:\n",
        "  # lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "  #   initial_learning_rate=1e-2,\n",
        "  #   decay_steps=10000,\n",
        "  #   decay_rate=0.96)\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=i), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(x_train_gray, y_train, epochs=25, batch_size=j, verbose=1)\n",
        "    score = model.evaluate(x_test_gray,y_test)\n",
        "    scores.append(score)\n",
        "    params.append((i,j,scores,'Adam'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCBU8GF1-43P",
        "outputId": "3ad0ff01-2d82-42d6-8ebf-08715930971c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 3.9606 - accuracy: 0.0999\n",
            "Epoch 2/75\n",
            "250/250 [==============================] - 12s 46ms/step - loss: 2.3038 - accuracy: 0.0984\n",
            "Epoch 3/75\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.3037 - accuracy: 0.0983\n",
            "Epoch 4/75\n",
            "250/250 [==============================] - 12s 46ms/step - loss: 2.3037 - accuracy: 0.0993\n",
            "Epoch 5/75\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.3037 - accuracy: 0.1002\n",
            "Epoch 6/75\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.3036 - accuracy: 0.1009\n",
            "Epoch 7/75\n",
            "250/250 [==============================] - 12s 46ms/step - loss: 2.3037 - accuracy: 0.0984\n",
            "Epoch 8/75\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 2.3037 - accuracy: 0.0986\n",
            "Epoch 9/75\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.3036 - accuracy: 0.0997\n",
            "Epoch 10/75\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.3037 - accuracy: 0.1002\n",
            "Epoch 11/75\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.3036 - accuracy: 0.1010\n",
            "Epoch 12/75\n",
            "250/250 [==============================] - 12s 46ms/step - loss: 2.3036 - accuracy: 0.1002\n",
            "Epoch 13/75\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 2.3036 - accuracy: 0.1001\n",
            "Epoch 14/75\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 2.3036 - accuracy: 0.1002\n",
            "Epoch 15/75\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 2.3036 - accuracy: 0.1008\n",
            "Epoch 16/75\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.3037 - accuracy: 0.0991\n",
            "Epoch 17/75\n",
            "250/250 [==============================] - 12s 46ms/step - loss: 2.3037 - accuracy: 0.0982\n",
            "Epoch 18/75\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 2.3037 - accuracy: 0.0980\n",
            "Epoch 19/75\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 2.3037 - accuracy: 0.0981\n",
            "Epoch 20/75\n",
            "250/250 [==============================] - 13s 50ms/step - loss: 2.3038 - accuracy: 0.0971\n",
            "Epoch 21/75\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 2.3037 - accuracy: 0.0982\n",
            "Epoch 22/75\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 2.3039 - accuracy: 0.0997\n",
            "Epoch 23/75\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.3038 - accuracy: 0.0984\n",
            "Epoch 24/75\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.3035 - accuracy: 0.1014\n",
            "Epoch 25/75\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 2.3036 - accuracy: 0.1005\n",
            "Epoch 26/75\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 2.3036 - accuracy: 0.0992\n",
            "Epoch 27/75\n",
            "250/250 [==============================] - 12s 46ms/step - loss: 2.3037 - accuracy: 0.0985\n",
            "Epoch 28/75\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 2.3038 - accuracy: 0.1001\n",
            "Epoch 29/75\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 2.3038 - accuracy: 0.0976\n",
            "Epoch 30/75\n",
            "250/250 [==============================] - 11s 46ms/step - loss: 2.3036 - accuracy: 0.0987\n",
            "Epoch 31/75\n",
            "250/250 [==============================] - 11s 46ms/step - loss: 2.3038 - accuracy: 0.0985\n",
            "Epoch 32/75\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.3035 - accuracy: 0.1011\n",
            "Epoch 33/75\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.3036 - accuracy: 0.0986\n",
            "Epoch 34/75\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.3036 - accuracy: 0.0998\n",
            "Epoch 35/75\n",
            "250/250 [==============================] - 12s 46ms/step - loss: 2.3037 - accuracy: 0.1002\n",
            "Epoch 36/75\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 2.3037 - accuracy: 0.1006\n",
            "Epoch 37/75\n",
            "250/250 [==============================] - 13s 51ms/step - loss: 2.3037 - accuracy: 0.0963\n",
            "Epoch 38/75\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 2.3037 - accuracy: 0.0983\n",
            "Epoch 39/75\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 2.3036 - accuracy: 0.0984\n",
            "Epoch 40/75\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 2.3037 - accuracy: 0.0984\n",
            "Epoch 41/75\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 2.3035 - accuracy: 0.0993\n",
            "Epoch 42/75\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 2.3037 - accuracy: 0.0985\n",
            "Epoch 43/75\n",
            "250/250 [==============================] - 12s 46ms/step - loss: 2.3037 - accuracy: 0.0993\n",
            "Epoch 44/75\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.3037 - accuracy: 0.0986\n",
            "Epoch 45/75\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 2.3037 - accuracy: 0.0983\n",
            "Epoch 46/75\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.3036 - accuracy: 0.0982\n",
            "Epoch 47/75\n",
            "250/250 [==============================] - 12s 49ms/step - loss: 2.3039 - accuracy: 0.0975\n",
            "Epoch 48/75\n",
            "250/250 [==============================] - 10s 40ms/step - loss: 2.3035 - accuracy: 0.0999\n",
            "Epoch 49/75\n",
            "250/250 [==============================] - 10s 40ms/step - loss: 2.3038 - accuracy: 0.0994\n",
            "Epoch 50/75\n",
            "250/250 [==============================] - 10s 40ms/step - loss: 2.3037 - accuracy: 0.0998\n",
            "Epoch 51/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.3037 - accuracy: 0.0994\n",
            "Epoch 52/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 2.3037 - accuracy: 0.0996\n",
            "Epoch 53/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3038 - accuracy: 0.0978\n",
            "Epoch 54/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3038 - accuracy: 0.0973\n",
            "Epoch 55/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3036 - accuracy: 0.0977\n",
            "Epoch 56/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.3036 - accuracy: 0.1001\n",
            "Epoch 57/75\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 2.3037 - accuracy: 0.0983\n",
            "Epoch 58/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 2.3036 - accuracy: 0.1000\n",
            "Epoch 59/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 2.3035 - accuracy: 0.1005\n",
            "Epoch 60/75\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 2.3037 - accuracy: 0.0973\n",
            "Epoch 61/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3038 - accuracy: 0.0977\n",
            "Epoch 62/75\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 2.3036 - accuracy: 0.0996\n",
            "Epoch 63/75\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 2.3036 - accuracy: 0.0990\n",
            "Epoch 64/75\n",
            "250/250 [==============================] - 11s 43ms/step - loss: 2.3036 - accuracy: 0.1009\n",
            "Epoch 65/75\n",
            "250/250 [==============================] - 13s 50ms/step - loss: 2.3037 - accuracy: 0.1005\n",
            "Epoch 66/75\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 2.3037 - accuracy: 0.0996\n",
            "Epoch 67/75\n",
            "250/250 [==============================] - 11s 44ms/step - loss: 2.3036 - accuracy: 0.0985\n",
            "Epoch 68/75\n",
            "250/250 [==============================] - 12s 48ms/step - loss: 2.3036 - accuracy: 0.1011\n",
            "Epoch 69/75\n",
            "250/250 [==============================] - 13s 50ms/step - loss: 2.3036 - accuracy: 0.0980\n",
            "Epoch 70/75\n",
            "250/250 [==============================] - 12s 46ms/step - loss: 2.3037 - accuracy: 0.0993\n",
            "Epoch 71/75\n",
            "250/250 [==============================] - 13s 51ms/step - loss: 2.3037 - accuracy: 0.0999\n",
            "Epoch 72/75\n",
            "250/250 [==============================] - 13s 53ms/step - loss: 2.3038 - accuracy: 0.0986\n",
            "Epoch 73/75\n",
            "250/250 [==============================] - 13s 54ms/step - loss: 2.3036 - accuracy: 0.1020\n",
            "Epoch 74/75\n",
            "250/250 [==============================] - 14s 54ms/step - loss: 2.3036 - accuracy: 0.0995\n",
            "Epoch 75/75\n",
            "250/250 [==============================] - 14s 57ms/step - loss: 2.3036 - accuracy: 0.0998\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 2.3042 - accuracy: 0.1000\n",
            "Epoch 1/75\n",
            "100/100 [==============================] - 12s 113ms/step - loss: 2.3032 - accuracy: 0.0981\n",
            "Epoch 2/75\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 2.3031 - accuracy: 0.0972\n",
            "Epoch 3/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3030 - accuracy: 0.1013\n",
            "Epoch 4/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.3031 - accuracy: 0.0982\n",
            "Epoch 5/75\n",
            "100/100 [==============================] - 11s 115ms/step - loss: 2.3029 - accuracy: 0.0991\n",
            "Epoch 6/75\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 2.3032 - accuracy: 0.0980\n",
            "Epoch 7/75\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 2.3031 - accuracy: 0.0999\n",
            "Epoch 8/75\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 2.3031 - accuracy: 0.1013\n",
            "Epoch 9/75\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 2.3031 - accuracy: 0.0982\n",
            "Epoch 10/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.3031 - accuracy: 0.0997\n",
            "Epoch 11/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3031 - accuracy: 0.0995\n",
            "Epoch 12/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.3030 - accuracy: 0.1009\n",
            "Epoch 13/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3030 - accuracy: 0.1018\n",
            "Epoch 14/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3031 - accuracy: 0.0996\n",
            "Epoch 15/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3032 - accuracy: 0.0981\n",
            "Epoch 16/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3031 - accuracy: 0.0988\n",
            "Epoch 17/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3031 - accuracy: 0.1004\n",
            "Epoch 18/75\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 2.3031 - accuracy: 0.0983\n",
            "Epoch 19/75\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 2.3030 - accuracy: 0.0981\n",
            "Epoch 20/75\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 2.3031 - accuracy: 0.0981\n",
            "Epoch 21/75\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 2.3030 - accuracy: 0.0994\n",
            "Epoch 22/75\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 2.3030 - accuracy: 0.1012\n",
            "Epoch 23/75\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 2.3030 - accuracy: 0.1004\n",
            "Epoch 24/75\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 2.3031 - accuracy: 0.0980\n",
            "Epoch 25/75\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 2.3031 - accuracy: 0.0966\n",
            "Epoch 26/75\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 2.3030 - accuracy: 0.0967\n",
            "Epoch 27/75\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 2.3030 - accuracy: 0.0985\n",
            "Epoch 28/75\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 2.3031 - accuracy: 0.0977\n",
            "Epoch 29/75\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 2.3031 - accuracy: 0.0996\n",
            "Epoch 30/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3030 - accuracy: 0.0986\n",
            "Epoch 31/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3031 - accuracy: 0.0966\n",
            "Epoch 32/75\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 2.3031 - accuracy: 0.0990\n",
            "Epoch 33/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.3030 - accuracy: 0.1002\n",
            "Epoch 34/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.3031 - accuracy: 0.0980\n",
            "Epoch 35/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.3031 - accuracy: 0.0996\n",
            "Epoch 36/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3031 - accuracy: 0.0972\n",
            "Epoch 37/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.3031 - accuracy: 0.0997\n",
            "Epoch 38/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.3031 - accuracy: 0.0974\n",
            "Epoch 39/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.3031 - accuracy: 0.1011\n",
            "Epoch 40/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.3031 - accuracy: 0.0996\n",
            "Epoch 41/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.3031 - accuracy: 0.0979\n",
            "Epoch 42/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3031 - accuracy: 0.0992\n",
            "Epoch 43/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3031 - accuracy: 0.0997\n",
            "Epoch 44/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3031 - accuracy: 0.0964\n",
            "Epoch 45/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3031 - accuracy: 0.1004\n",
            "Epoch 46/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.3030 - accuracy: 0.1009\n",
            "Epoch 47/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.3030 - accuracy: 0.0990\n",
            "Epoch 48/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3030 - accuracy: 0.1000\n",
            "Epoch 49/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3032 - accuracy: 0.0981\n",
            "Epoch 50/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3031 - accuracy: 0.0992\n",
            "Epoch 51/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3029 - accuracy: 0.1007\n",
            "Epoch 52/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3030 - accuracy: 0.1012\n",
            "Epoch 53/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.3030 - accuracy: 0.0982\n",
            "Epoch 54/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3031 - accuracy: 0.0982\n",
            "Epoch 55/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3031 - accuracy: 0.1002\n",
            "Epoch 56/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3031 - accuracy: 0.0985\n",
            "Epoch 57/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3030 - accuracy: 0.1014\n",
            "Epoch 58/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.3031 - accuracy: 0.0986\n",
            "Epoch 59/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.3031 - accuracy: 0.0993\n",
            "Epoch 60/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3030 - accuracy: 0.1008\n",
            "Epoch 61/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.3031 - accuracy: 0.0990\n",
            "Epoch 62/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3030 - accuracy: 0.0983\n",
            "Epoch 63/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3029 - accuracy: 0.1019\n",
            "Epoch 64/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.3030 - accuracy: 0.0995\n",
            "Epoch 65/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.3031 - accuracy: 0.1005\n",
            "Epoch 66/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.3031 - accuracy: 0.0994\n",
            "Epoch 67/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.3030 - accuracy: 0.1000\n",
            "Epoch 68/75\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 2.3031 - accuracy: 0.0997\n",
            "Epoch 69/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3030 - accuracy: 0.1001\n",
            "Epoch 70/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.3031 - accuracy: 0.0998\n",
            "Epoch 71/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.3030 - accuracy: 0.1009\n",
            "Epoch 72/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3029 - accuracy: 0.1019\n",
            "Epoch 73/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.3031 - accuracy: 0.0993\n",
            "Epoch 74/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.3030 - accuracy: 0.0995\n",
            "Epoch 75/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.3031 - accuracy: 0.0974\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.3027 - accuracy: 0.1000\n",
            "Epoch 1/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3029 - accuracy: 0.0986\n",
            "Epoch 2/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3029 - accuracy: 0.1005\n",
            "Epoch 3/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3030 - accuracy: 0.0980\n",
            "Epoch 4/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3030 - accuracy: 0.0973\n",
            "Epoch 5/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3029 - accuracy: 0.1019\n",
            "Epoch 6/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3030 - accuracy: 0.0985\n",
            "Epoch 7/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3029 - accuracy: 0.1002\n",
            "Epoch 8/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3028 - accuracy: 0.0997\n",
            "Epoch 9/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3030 - accuracy: 0.0994\n",
            "Epoch 10/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.1002\n",
            "Epoch 11/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.0982\n",
            "Epoch 12/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.1001\n",
            "Epoch 13/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3029 - accuracy: 0.1002\n",
            "Epoch 14/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3029 - accuracy: 0.0989\n",
            "Epoch 15/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.0993\n",
            "Epoch 16/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3029 - accuracy: 0.0983\n",
            "Epoch 17/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3029 - accuracy: 0.0966\n",
            "Epoch 18/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.0986\n",
            "Epoch 19/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 2.3029 - accuracy: 0.1000\n",
            "Epoch 20/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3029 - accuracy: 0.0986\n",
            "Epoch 21/75\n",
            "72/72 [==============================] - 8s 111ms/step - loss: 2.3029 - accuracy: 0.0973\n",
            "Epoch 22/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 2.3029 - accuracy: 0.0992\n",
            "Epoch 23/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.0960\n",
            "Epoch 24/75\n",
            "72/72 [==============================] - 8s 113ms/step - loss: 2.3030 - accuracy: 0.0955\n",
            "Epoch 25/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3029 - accuracy: 0.1006\n",
            "Epoch 26/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3029 - accuracy: 0.0981\n",
            "Epoch 27/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3030 - accuracy: 0.0979\n",
            "Epoch 28/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.0979\n",
            "Epoch 29/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.0996\n",
            "Epoch 30/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3029 - accuracy: 0.0989\n",
            "Epoch 31/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3030 - accuracy: 0.0973\n",
            "Epoch 32/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3030 - accuracy: 0.0973\n",
            "Epoch 33/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3030 - accuracy: 0.0981\n",
            "Epoch 34/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3028 - accuracy: 0.1007\n",
            "Epoch 35/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 2.3031 - accuracy: 0.0976\n",
            "Epoch 36/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 2.3030 - accuracy: 0.0996\n",
            "Epoch 37/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3030 - accuracy: 0.0989\n",
            "Epoch 38/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3030 - accuracy: 0.0955\n",
            "Epoch 39/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.0977\n",
            "Epoch 40/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3029 - accuracy: 0.0981\n",
            "Epoch 41/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.0980\n",
            "Epoch 42/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3029 - accuracy: 0.0994\n",
            "Epoch 43/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3029 - accuracy: 0.1007\n",
            "Epoch 44/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.0977\n",
            "Epoch 45/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3029 - accuracy: 0.0995\n",
            "Epoch 46/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3029 - accuracy: 0.0997\n",
            "Epoch 47/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3029 - accuracy: 0.0986\n",
            "Epoch 48/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3028 - accuracy: 0.1008\n",
            "Epoch 49/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3029 - accuracy: 0.1001\n",
            "Epoch 50/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3030 - accuracy: 0.0994\n",
            "Epoch 51/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3030 - accuracy: 0.0983\n",
            "Epoch 52/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3030 - accuracy: 0.0989\n",
            "Epoch 53/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3029 - accuracy: 0.1004\n",
            "Epoch 54/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.0989\n",
            "Epoch 55/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.0995\n",
            "Epoch 56/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.1002\n",
            "Epoch 57/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.0973\n",
            "Epoch 58/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3030 - accuracy: 0.0991\n",
            "Epoch 59/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.0980\n",
            "Epoch 60/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3029 - accuracy: 0.0994\n",
            "Epoch 61/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3029 - accuracy: 0.1002\n",
            "Epoch 62/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.0991\n",
            "Epoch 63/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3029 - accuracy: 0.0994\n",
            "Epoch 64/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3029 - accuracy: 0.0992\n",
            "Epoch 65/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 2.3030 - accuracy: 0.0976\n",
            "Epoch 66/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 2.3029 - accuracy: 0.1012\n",
            "Epoch 67/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3029 - accuracy: 0.1002\n",
            "Epoch 68/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 2.3030 - accuracy: 0.0998\n",
            "Epoch 69/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3029 - accuracy: 0.0977\n",
            "Epoch 70/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 2.3030 - accuracy: 0.0990\n",
            "Epoch 71/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3029 - accuracy: 0.0987\n",
            "Epoch 72/75\n",
            "72/72 [==============================] - 8s 111ms/step - loss: 2.3029 - accuracy: 0.0982\n",
            "Epoch 73/75\n",
            "72/72 [==============================] - 8s 110ms/step - loss: 2.3029 - accuracy: 0.1002\n",
            "Epoch 74/75\n",
            "72/72 [==============================] - 8s 112ms/step - loss: 2.3030 - accuracy: 0.0970\n",
            "Epoch 75/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3030 - accuracy: 0.0974\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.3027 - accuracy: 0.1000\n",
            "Epoch 1/75\n",
            "59/59 [==============================] - 8s 129ms/step - loss: 2.3028 - accuracy: 0.1008\n",
            "Epoch 2/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3028 - accuracy: 0.1000\n",
            "Epoch 3/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.3029 - accuracy: 0.0967\n",
            "Epoch 4/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.3029 - accuracy: 0.1002\n",
            "Epoch 5/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.3029 - accuracy: 0.0993\n",
            "Epoch 6/75\n",
            "59/59 [==============================] - 8s 127ms/step - loss: 2.3029 - accuracy: 0.0977\n",
            "Epoch 7/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 2.3029 - accuracy: 0.0955\n",
            "Epoch 8/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.3029 - accuracy: 0.0967\n",
            "Epoch 9/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.3029 - accuracy: 0.0985\n",
            "Epoch 10/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.3028 - accuracy: 0.1008\n",
            "Epoch 11/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 2.3029 - accuracy: 0.0966\n",
            "Epoch 12/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3029 - accuracy: 0.0996\n",
            "Epoch 13/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.3028 - accuracy: 0.0982\n",
            "Epoch 14/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3029 - accuracy: 0.0990\n",
            "Epoch 15/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 2.3030 - accuracy: 0.0983\n",
            "Epoch 16/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3028 - accuracy: 0.1006\n",
            "Epoch 17/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3029 - accuracy: 0.0978\n",
            "Epoch 18/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.3029 - accuracy: 0.0990\n",
            "Epoch 19/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.3029 - accuracy: 0.0990\n",
            "Epoch 20/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.3029 - accuracy: 0.0995\n",
            "Epoch 21/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3028 - accuracy: 0.0984\n",
            "Epoch 22/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3029 - accuracy: 0.1011\n",
            "Epoch 23/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 2.3029 - accuracy: 0.0980\n",
            "Epoch 24/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3029 - accuracy: 0.0982\n",
            "Epoch 25/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3029 - accuracy: 0.0988\n",
            "Epoch 26/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3029 - accuracy: 0.0979\n",
            "Epoch 27/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.3029 - accuracy: 0.0982\n",
            "Epoch 28/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 2.3029 - accuracy: 0.0979\n",
            "Epoch 29/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.3029 - accuracy: 0.0984\n",
            "Epoch 30/75\n",
            "59/59 [==============================] - 8s 131ms/step - loss: 2.3029 - accuracy: 0.0985\n",
            "Epoch 31/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 2.3029 - accuracy: 0.0988\n",
            "Epoch 32/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3029 - accuracy: 0.0976\n",
            "Epoch 33/75\n",
            "59/59 [==============================] - 8s 133ms/step - loss: 2.3028 - accuracy: 0.1002\n",
            "Epoch 34/75\n",
            "59/59 [==============================] - 8s 130ms/step - loss: 2.3028 - accuracy: 0.1002\n",
            "Epoch 35/75\n",
            "59/59 [==============================] - 8s 131ms/step - loss: 2.3029 - accuracy: 0.0992\n",
            "Epoch 36/75\n",
            "59/59 [==============================] - 8s 133ms/step - loss: 2.3029 - accuracy: 0.0975\n",
            "Epoch 37/75\n",
            "59/59 [==============================] - 8s 130ms/step - loss: 2.3029 - accuracy: 0.0982\n",
            "Epoch 38/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.3028 - accuracy: 0.1005\n",
            "Epoch 39/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.3029 - accuracy: 0.0980\n",
            "Epoch 40/75\n",
            "59/59 [==============================] - 7s 121ms/step - loss: 2.3029 - accuracy: 0.0983\n",
            "Epoch 41/75\n",
            "59/59 [==============================] - 7s 122ms/step - loss: 2.3029 - accuracy: 0.0992\n",
            "Epoch 42/75\n",
            "59/59 [==============================] - 7s 122ms/step - loss: 2.3029 - accuracy: 0.0981\n",
            "Epoch 43/75\n",
            "59/59 [==============================] - 7s 121ms/step - loss: 2.3029 - accuracy: 0.0984\n",
            "Epoch 44/75\n",
            "59/59 [==============================] - 7s 121ms/step - loss: 2.3029 - accuracy: 0.1006\n",
            "Epoch 45/75\n",
            "59/59 [==============================] - 7s 120ms/step - loss: 2.3029 - accuracy: 0.0978\n",
            "Epoch 46/75\n",
            "59/59 [==============================] - 7s 121ms/step - loss: 2.3029 - accuracy: 0.0980\n",
            "Epoch 47/75\n",
            "59/59 [==============================] - 7s 122ms/step - loss: 2.3028 - accuracy: 0.0984\n",
            "Epoch 48/75\n",
            "59/59 [==============================] - 7s 121ms/step - loss: 2.3029 - accuracy: 0.0987\n",
            "Epoch 49/75\n",
            "59/59 [==============================] - 7s 123ms/step - loss: 2.3029 - accuracy: 0.0978\n",
            "Epoch 50/75\n",
            "59/59 [==============================] - 7s 122ms/step - loss: 2.3028 - accuracy: 0.1000\n",
            "Epoch 51/75\n",
            "59/59 [==============================] - 7s 120ms/step - loss: 2.3029 - accuracy: 0.0995\n",
            "Epoch 52/75\n",
            "59/59 [==============================] - 7s 121ms/step - loss: 2.3028 - accuracy: 0.0997\n",
            "Epoch 53/75\n",
            "59/59 [==============================] - 7s 120ms/step - loss: 2.3029 - accuracy: 0.0972\n",
            "Epoch 54/75\n",
            "59/59 [==============================] - 7s 121ms/step - loss: 2.3029 - accuracy: 0.1005\n",
            "Epoch 55/75\n",
            "59/59 [==============================] - 7s 122ms/step - loss: 2.3029 - accuracy: 0.0999\n",
            "Epoch 56/75\n",
            "59/59 [==============================] - 7s 121ms/step - loss: 2.3029 - accuracy: 0.0985\n",
            "Epoch 57/75\n",
            "59/59 [==============================] - 7s 121ms/step - loss: 2.3029 - accuracy: 0.0981\n",
            "Epoch 58/75\n",
            "59/59 [==============================] - 7s 120ms/step - loss: 2.3029 - accuracy: 0.0964\n",
            "Epoch 59/75\n",
            "59/59 [==============================] - 7s 121ms/step - loss: 2.3029 - accuracy: 0.0989\n",
            "Epoch 60/75\n",
            "59/59 [==============================] - 7s 121ms/step - loss: 2.3029 - accuracy: 0.0982\n",
            "Epoch 61/75\n",
            "59/59 [==============================] - 7s 122ms/step - loss: 2.3029 - accuracy: 0.0991\n",
            "Epoch 62/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.3030 - accuracy: 0.0957\n",
            "Epoch 63/75\n",
            "59/59 [==============================] - 7s 121ms/step - loss: 2.3029 - accuracy: 0.0963\n",
            "Epoch 64/75\n",
            "59/59 [==============================] - 7s 121ms/step - loss: 2.3029 - accuracy: 0.0983\n",
            "Epoch 65/75\n",
            "59/59 [==============================] - 7s 122ms/step - loss: 2.3029 - accuracy: 0.1003\n",
            "Epoch 66/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3028 - accuracy: 0.0992\n",
            "Epoch 67/75\n",
            "59/59 [==============================] - 7s 123ms/step - loss: 2.3028 - accuracy: 0.0998\n",
            "Epoch 68/75\n",
            "59/59 [==============================] - 7s 121ms/step - loss: 2.3029 - accuracy: 0.0992\n",
            "Epoch 69/75\n",
            "59/59 [==============================] - 7s 121ms/step - loss: 2.3029 - accuracy: 0.0973\n",
            "Epoch 70/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.3029 - accuracy: 0.0970\n",
            "Epoch 71/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3029 - accuracy: 0.0990\n",
            "Epoch 72/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 2.3029 - accuracy: 0.0979\n",
            "Epoch 73/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.3029 - accuracy: 0.0998\n",
            "Epoch 74/75\n",
            "59/59 [==============================] - 8s 132ms/step - loss: 2.3029 - accuracy: 0.1002\n",
            "Epoch 75/75\n",
            "59/59 [==============================] - 7s 123ms/step - loss: 2.3029 - accuracy: 0.0980\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.3028 - accuracy: 0.1000\n",
            "Epoch 1/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3202 - accuracy: 0.1004\n",
            "Epoch 2/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3197 - accuracy: 0.1020\n",
            "Epoch 3/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3201 - accuracy: 0.1009\n",
            "Epoch 4/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3189 - accuracy: 0.0987\n",
            "Epoch 5/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3188 - accuracy: 0.1014\n",
            "Epoch 6/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3201 - accuracy: 0.0992\n",
            "Epoch 7/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3209 - accuracy: 0.1007\n",
            "Epoch 8/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3212 - accuracy: 0.0990\n",
            "Epoch 9/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3197 - accuracy: 0.1017\n",
            "Epoch 10/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3180 - accuracy: 0.1007\n",
            "Epoch 11/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3203 - accuracy: 0.0995\n",
            "Epoch 12/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3202 - accuracy: 0.1013\n",
            "Epoch 13/75\n",
            "250/250 [==============================] - 11s 43ms/step - loss: 2.3182 - accuracy: 0.1000\n",
            "Epoch 14/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 2.3195 - accuracy: 0.0988\n",
            "Epoch 15/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3182 - accuracy: 0.1011\n",
            "Epoch 16/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3185 - accuracy: 0.1011\n",
            "Epoch 17/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3196 - accuracy: 0.0989\n",
            "Epoch 18/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.3198 - accuracy: 0.0999\n",
            "Epoch 19/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3210 - accuracy: 0.0991\n",
            "Epoch 20/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3185 - accuracy: 0.1021\n",
            "Epoch 21/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3212 - accuracy: 0.0982\n",
            "Epoch 22/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.3199 - accuracy: 0.0999\n",
            "Epoch 23/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3204 - accuracy: 0.0980\n",
            "Epoch 24/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3178 - accuracy: 0.0990\n",
            "Epoch 25/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3212 - accuracy: 0.0979\n",
            "Epoch 26/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3204 - accuracy: 0.0972\n",
            "Epoch 27/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3189 - accuracy: 0.1012\n",
            "Epoch 28/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3188 - accuracy: 0.1003\n",
            "Epoch 29/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 2.3198 - accuracy: 0.1011\n",
            "Epoch 30/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3195 - accuracy: 0.0998\n",
            "Epoch 31/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3177 - accuracy: 0.1031\n",
            "Epoch 32/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3199 - accuracy: 0.1001\n",
            "Epoch 33/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3190 - accuracy: 0.1004\n",
            "Epoch 34/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.3188 - accuracy: 0.0992\n",
            "Epoch 35/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3192 - accuracy: 0.0996\n",
            "Epoch 36/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.3192 - accuracy: 0.0979\n",
            "Epoch 37/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3188 - accuracy: 0.1026\n",
            "Epoch 38/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3200 - accuracy: 0.1006\n",
            "Epoch 39/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3186 - accuracy: 0.0996\n",
            "Epoch 40/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3209 - accuracy: 0.0972\n",
            "Epoch 41/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3201 - accuracy: 0.0980\n",
            "Epoch 42/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3186 - accuracy: 0.0998\n",
            "Epoch 43/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3196 - accuracy: 0.0995\n",
            "Epoch 44/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3216 - accuracy: 0.0968\n",
            "Epoch 45/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3198 - accuracy: 0.1002\n",
            "Epoch 46/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3200 - accuracy: 0.1014\n",
            "Epoch 47/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3183 - accuracy: 0.0998\n",
            "Epoch 48/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3194 - accuracy: 0.1013\n",
            "Epoch 49/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3203 - accuracy: 0.0991\n",
            "Epoch 50/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3198 - accuracy: 0.1018\n",
            "Epoch 51/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3181 - accuracy: 0.0993\n",
            "Epoch 52/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3200 - accuracy: 0.0987\n",
            "Epoch 53/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3183 - accuracy: 0.1009\n",
            "Epoch 54/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3178 - accuracy: 0.1012\n",
            "Epoch 55/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3193 - accuracy: 0.0995\n",
            "Epoch 56/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3201 - accuracy: 0.1009\n",
            "Epoch 57/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3196 - accuracy: 0.1010\n",
            "Epoch 58/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3192 - accuracy: 0.1014\n",
            "Epoch 59/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3194 - accuracy: 0.0987\n",
            "Epoch 60/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.3189 - accuracy: 0.1020\n",
            "Epoch 61/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3199 - accuracy: 0.0984\n",
            "Epoch 62/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.3195 - accuracy: 0.1004\n",
            "Epoch 63/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.3210 - accuracy: 0.1010\n",
            "Epoch 64/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3188 - accuracy: 0.0997\n",
            "Epoch 65/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.3199 - accuracy: 0.1001\n",
            "Epoch 66/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.3188 - accuracy: 0.1011\n",
            "Epoch 67/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3195 - accuracy: 0.0998\n",
            "Epoch 68/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3198 - accuracy: 0.0996\n",
            "Epoch 69/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3191 - accuracy: 0.0997\n",
            "Epoch 70/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3201 - accuracy: 0.0973\n",
            "Epoch 71/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3196 - accuracy: 0.0990\n",
            "Epoch 72/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.3214 - accuracy: 0.0989\n",
            "Epoch 73/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.3182 - accuracy: 0.0995\n",
            "Epoch 74/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.3203 - accuracy: 0.1018\n",
            "Epoch 75/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 2.3199 - accuracy: 0.0996\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.3186 - accuracy: 0.1000\n",
            "Epoch 1/75\n",
            "100/100 [==============================] - 9s 82ms/step - loss: 2.3093 - accuracy: 0.1000\n",
            "Epoch 2/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.3089 - accuracy: 0.1032\n",
            "Epoch 3/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.3091 - accuracy: 0.0988\n",
            "Epoch 4/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.3096 - accuracy: 0.1010\n",
            "Epoch 5/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3087 - accuracy: 0.0997\n",
            "Epoch 6/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3101 - accuracy: 0.0995\n",
            "Epoch 7/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3089 - accuracy: 0.1018\n",
            "Epoch 8/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3098 - accuracy: 0.0984\n",
            "Epoch 9/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3091 - accuracy: 0.0994\n",
            "Epoch 10/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.3101 - accuracy: 0.0989\n",
            "Epoch 11/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3095 - accuracy: 0.1006\n",
            "Epoch 12/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3096 - accuracy: 0.0977\n",
            "Epoch 13/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3084 - accuracy: 0.0998\n",
            "Epoch 14/75\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 2.3095 - accuracy: 0.1005\n",
            "Epoch 15/75\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 2.3093 - accuracy: 0.1006\n",
            "Epoch 16/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3095 - accuracy: 0.0995\n",
            "Epoch 17/75\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 2.3098 - accuracy: 0.0989\n",
            "Epoch 18/75\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 2.3083 - accuracy: 0.0998\n",
            "Epoch 19/75\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 2.3092 - accuracy: 0.0976\n",
            "Epoch 20/75\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 2.3100 - accuracy: 0.0979\n",
            "Epoch 21/75\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 2.3093 - accuracy: 0.0992\n",
            "Epoch 22/75\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 2.3085 - accuracy: 0.1023\n",
            "Epoch 23/75\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 2.3085 - accuracy: 0.1024\n",
            "Epoch 24/75\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 2.3090 - accuracy: 0.0996\n",
            "Epoch 25/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3085 - accuracy: 0.0979\n",
            "Epoch 26/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.3088 - accuracy: 0.0990\n",
            "Epoch 27/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3083 - accuracy: 0.1020\n",
            "Epoch 28/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3088 - accuracy: 0.0991\n",
            "Epoch 29/75\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 2.3098 - accuracy: 0.1001\n",
            "Epoch 30/75\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 2.3107 - accuracy: 0.0983\n",
            "Epoch 31/75\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 2.3103 - accuracy: 0.0991\n",
            "Epoch 32/75\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 2.3097 - accuracy: 0.1015\n",
            "Epoch 33/75\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 2.3090 - accuracy: 0.1026\n",
            "Epoch 34/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3094 - accuracy: 0.0992\n",
            "Epoch 35/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.3097 - accuracy: 0.0985\n",
            "Epoch 36/75\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 2.3091 - accuracy: 0.1007\n",
            "Epoch 37/75\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 2.3095 - accuracy: 0.0977\n",
            "Epoch 38/75\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 2.3093 - accuracy: 0.1008\n",
            "Epoch 39/75\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 2.3091 - accuracy: 0.1021\n",
            "Epoch 40/75\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 2.3095 - accuracy: 0.0992\n",
            "Epoch 41/75\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 2.3100 - accuracy: 0.1003\n",
            "Epoch 42/75\n",
            "100/100 [==============================] - 12s 116ms/step - loss: 2.3090 - accuracy: 0.0991\n",
            "Epoch 43/75\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 2.3100 - accuracy: 0.0974\n",
            "Epoch 44/75\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 2.3097 - accuracy: 0.0996\n",
            "Epoch 45/75\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 2.3098 - accuracy: 0.1008\n",
            "Epoch 46/75\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 2.3101 - accuracy: 0.1004\n",
            "Epoch 47/75\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 2.3104 - accuracy: 0.0986\n",
            "Epoch 48/75\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 2.3098 - accuracy: 0.1005\n",
            "Epoch 49/75\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 2.3095 - accuracy: 0.0981\n",
            "Epoch 50/75\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 2.3094 - accuracy: 0.0987\n",
            "Epoch 51/75\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 2.3096 - accuracy: 0.1004\n",
            "Epoch 52/75\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 2.3092 - accuracy: 0.0992\n",
            "Epoch 53/75\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 2.3088 - accuracy: 0.1009\n",
            "Epoch 54/75\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 2.3097 - accuracy: 0.0981\n",
            "Epoch 55/75\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 2.3093 - accuracy: 0.0987\n",
            "Epoch 56/75\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 2.3088 - accuracy: 0.0988\n",
            "Epoch 57/75\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 2.3095 - accuracy: 0.0981\n",
            "Epoch 58/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3101 - accuracy: 0.0996\n",
            "Epoch 59/75\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 2.3104 - accuracy: 0.1009\n",
            "Epoch 60/75\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 2.3094 - accuracy: 0.0984\n",
            "Epoch 61/75\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 2.3092 - accuracy: 0.0972\n",
            "Epoch 62/75\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 2.3093 - accuracy: 0.1000\n",
            "Epoch 63/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.3095 - accuracy: 0.1014\n",
            "Epoch 64/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.3102 - accuracy: 0.0976\n",
            "Epoch 65/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.3093 - accuracy: 0.1003\n",
            "Epoch 66/75\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 2.3093 - accuracy: 0.0994\n",
            "Epoch 67/75\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 2.3102 - accuracy: 0.0998\n",
            "Epoch 68/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.3093 - accuracy: 0.0991\n",
            "Epoch 69/75\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 2.3097 - accuracy: 0.0983\n",
            "Epoch 70/75\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 2.3095 - accuracy: 0.0999\n",
            "Epoch 71/75\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 2.3096 - accuracy: 0.1001\n",
            "Epoch 72/75\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 2.3092 - accuracy: 0.1002\n",
            "Epoch 73/75\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 2.3089 - accuracy: 0.0984\n",
            "Epoch 74/75\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 2.3096 - accuracy: 0.1006\n",
            "Epoch 75/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.3098 - accuracy: 0.0998\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.3054 - accuracy: 0.1000\n",
            "Epoch 1/75\n",
            "72/72 [==============================] - 9s 119ms/step - loss: 2.3064 - accuracy: 0.0996\n",
            "Epoch 2/75\n",
            "72/72 [==============================] - 8s 116ms/step - loss: 2.3079 - accuracy: 0.0999\n",
            "Epoch 3/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 2.3074 - accuracy: 0.0990\n",
            "Epoch 4/75\n",
            "72/72 [==============================] - 8s 110ms/step - loss: 2.3076 - accuracy: 0.0982\n",
            "Epoch 5/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 2.3073 - accuracy: 0.1004\n",
            "Epoch 6/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 2.3078 - accuracy: 0.0991\n",
            "Epoch 7/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 2.3071 - accuracy: 0.0990\n",
            "Epoch 8/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3083 - accuracy: 0.0987\n",
            "Epoch 9/75\n",
            "72/72 [==============================] - 8s 110ms/step - loss: 2.3078 - accuracy: 0.0996\n",
            "Epoch 10/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 2.3080 - accuracy: 0.0976\n",
            "Epoch 11/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3076 - accuracy: 0.1005\n",
            "Epoch 12/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3082 - accuracy: 0.0982\n",
            "Epoch 13/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 2.3075 - accuracy: 0.0993\n",
            "Epoch 14/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3075 - accuracy: 0.0980\n",
            "Epoch 15/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3076 - accuracy: 0.1008\n",
            "Epoch 16/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3074 - accuracy: 0.1002\n",
            "Epoch 17/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 2.3067 - accuracy: 0.1001\n",
            "Epoch 18/75\n",
            "72/72 [==============================] - 8s 110ms/step - loss: 2.3076 - accuracy: 0.1000\n",
            "Epoch 19/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3073 - accuracy: 0.1001\n",
            "Epoch 20/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3074 - accuracy: 0.1004\n",
            "Epoch 21/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3074 - accuracy: 0.1013\n",
            "Epoch 22/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3081 - accuracy: 0.0963\n",
            "Epoch 23/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3069 - accuracy: 0.1002\n",
            "Epoch 24/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3065 - accuracy: 0.1030\n",
            "Epoch 25/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3077 - accuracy: 0.0995\n",
            "Epoch 26/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3082 - accuracy: 0.0985\n",
            "Epoch 27/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3076 - accuracy: 0.1013\n",
            "Epoch 28/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3066 - accuracy: 0.1002\n",
            "Epoch 29/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3080 - accuracy: 0.1012\n",
            "Epoch 30/75\n",
            "72/72 [==============================] - 8s 104ms/step - loss: 2.3074 - accuracy: 0.1012\n",
            "Epoch 31/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3075 - accuracy: 0.0975\n",
            "Epoch 32/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3081 - accuracy: 0.1002\n",
            "Epoch 33/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3073 - accuracy: 0.1005\n",
            "Epoch 34/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3076 - accuracy: 0.0980\n",
            "Epoch 35/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3074 - accuracy: 0.0998\n",
            "Epoch 36/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3077 - accuracy: 0.0998\n",
            "Epoch 37/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3079 - accuracy: 0.1002\n",
            "Epoch 38/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3070 - accuracy: 0.0997\n",
            "Epoch 39/75\n",
            "72/72 [==============================] - 8s 110ms/step - loss: 2.3073 - accuracy: 0.0995\n",
            "Epoch 40/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 2.3069 - accuracy: 0.1006\n",
            "Epoch 41/75\n",
            "72/72 [==============================] - 8s 110ms/step - loss: 2.3070 - accuracy: 0.1033\n",
            "Epoch 42/75\n",
            "72/72 [==============================] - 8s 112ms/step - loss: 2.3081 - accuracy: 0.0987\n",
            "Epoch 43/75\n",
            "72/72 [==============================] - 9s 123ms/step - loss: 2.3075 - accuracy: 0.0987\n",
            "Epoch 44/75\n",
            "72/72 [==============================] - 8s 112ms/step - loss: 2.3078 - accuracy: 0.0992\n",
            "Epoch 45/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 2.3083 - accuracy: 0.0981\n",
            "Epoch 46/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3074 - accuracy: 0.1012\n",
            "Epoch 47/75\n",
            "72/72 [==============================] - 8s 110ms/step - loss: 2.3072 - accuracy: 0.0993\n",
            "Epoch 48/75\n",
            "72/72 [==============================] - 8s 112ms/step - loss: 2.3071 - accuracy: 0.1013\n",
            "Epoch 49/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 2.3078 - accuracy: 0.1007\n",
            "Epoch 50/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 2.3078 - accuracy: 0.0991\n",
            "Epoch 51/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 2.3071 - accuracy: 0.1013\n",
            "Epoch 52/75\n",
            "72/72 [==============================] - 8s 111ms/step - loss: 2.3081 - accuracy: 0.1012\n",
            "Epoch 53/75\n",
            "72/72 [==============================] - 8s 112ms/step - loss: 2.3079 - accuracy: 0.0992\n",
            "Epoch 54/75\n",
            "72/72 [==============================] - 8s 111ms/step - loss: 2.3067 - accuracy: 0.1030\n",
            "Epoch 55/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 2.3077 - accuracy: 0.0998\n",
            "Epoch 56/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3085 - accuracy: 0.1012\n",
            "Epoch 57/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3075 - accuracy: 0.1016\n",
            "Epoch 58/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3077 - accuracy: 0.0991\n",
            "Epoch 59/75\n",
            "72/72 [==============================] - 8s 104ms/step - loss: 2.3074 - accuracy: 0.0989\n",
            "Epoch 60/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3074 - accuracy: 0.1012\n",
            "Epoch 61/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3076 - accuracy: 0.0994\n",
            "Epoch 62/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3069 - accuracy: 0.0991\n",
            "Epoch 63/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3079 - accuracy: 0.0992\n",
            "Epoch 64/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3072 - accuracy: 0.1004\n",
            "Epoch 65/75\n",
            "72/72 [==============================] - 8s 104ms/step - loss: 2.3074 - accuracy: 0.0973\n",
            "Epoch 66/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3077 - accuracy: 0.0999\n",
            "Epoch 67/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3069 - accuracy: 0.1018\n",
            "Epoch 68/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3069 - accuracy: 0.1008\n",
            "Epoch 69/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3076 - accuracy: 0.0983\n",
            "Epoch 70/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3071 - accuracy: 0.1008\n",
            "Epoch 71/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.3074 - accuracy: 0.0979\n",
            "Epoch 72/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.3074 - accuracy: 0.0974\n",
            "Epoch 73/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3074 - accuracy: 0.0978\n",
            "Epoch 74/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3074 - accuracy: 0.1008\n",
            "Epoch 75/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.3079 - accuracy: 0.1006\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 2.3122 - accuracy: 0.1000\n",
            "Epoch 1/75\n",
            "59/59 [==============================] - 8s 124ms/step - loss: 2.3068 - accuracy: 0.0995\n",
            "Epoch 2/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.3060 - accuracy: 0.0993\n",
            "Epoch 3/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.3071 - accuracy: 0.0990\n",
            "Epoch 4/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.3077 - accuracy: 0.0998\n",
            "Epoch 5/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 2.3064 - accuracy: 0.0988\n",
            "Epoch 6/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 2.3064 - accuracy: 0.0990\n",
            "Epoch 7/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.3064 - accuracy: 0.1001\n",
            "Epoch 8/75\n",
            "59/59 [==============================] - 8s 129ms/step - loss: 2.3068 - accuracy: 0.0998\n",
            "Epoch 9/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.3068 - accuracy: 0.0995\n",
            "Epoch 10/75\n",
            "59/59 [==============================] - 7s 122ms/step - loss: 2.3072 - accuracy: 0.0992\n",
            "Epoch 11/75\n",
            "59/59 [==============================] - 8s 133ms/step - loss: 2.3067 - accuracy: 0.0984\n",
            "Epoch 12/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 2.3072 - accuracy: 0.0995\n",
            "Epoch 13/75\n",
            "59/59 [==============================] - 8s 138ms/step - loss: 2.3071 - accuracy: 0.0983\n",
            "Epoch 14/75\n",
            "59/59 [==============================] - 20s 338ms/step - loss: 2.3078 - accuracy: 0.0982\n",
            "Epoch 15/75\n",
            "59/59 [==============================] - 24s 414ms/step - loss: 2.3067 - accuracy: 0.0999\n",
            "Epoch 16/75\n",
            "59/59 [==============================] - 24s 407ms/step - loss: 2.3064 - accuracy: 0.0992\n",
            "Epoch 17/75\n",
            "59/59 [==============================] - 25s 426ms/step - loss: 2.3067 - accuracy: 0.0987\n",
            "Epoch 18/75\n",
            "59/59 [==============================] - 27s 449ms/step - loss: 2.3062 - accuracy: 0.1002\n",
            "Epoch 19/75\n",
            "59/59 [==============================] - 27s 454ms/step - loss: 2.3074 - accuracy: 0.0986\n",
            "Epoch 20/75\n",
            "59/59 [==============================] - 12s 203ms/step - loss: 2.3063 - accuracy: 0.1018\n",
            "Epoch 21/75\n",
            "59/59 [==============================] - 4s 69ms/step - loss: 2.3068 - accuracy: 0.0992\n",
            "Epoch 22/75\n",
            "59/59 [==============================] - 4s 69ms/step - loss: 2.3068 - accuracy: 0.0971\n",
            "Epoch 23/75\n",
            "59/59 [==============================] - 5s 80ms/step - loss: 2.3068 - accuracy: 0.1015\n",
            "Epoch 24/75\n",
            "59/59 [==============================] - 7s 111ms/step - loss: 2.3069 - accuracy: 0.0975\n",
            "Epoch 25/75\n",
            "59/59 [==============================] - 6s 110ms/step - loss: 2.3068 - accuracy: 0.0993\n",
            "Epoch 26/75\n",
            "59/59 [==============================] - 7s 122ms/step - loss: 2.3061 - accuracy: 0.1001\n",
            "Epoch 27/75\n",
            "59/59 [==============================] - 6s 109ms/step - loss: 2.3067 - accuracy: 0.1004\n",
            "Epoch 28/75\n",
            "59/59 [==============================] - 7s 111ms/step - loss: 2.3066 - accuracy: 0.0983\n",
            "Epoch 29/75\n",
            "59/59 [==============================] - 6s 109ms/step - loss: 2.3065 - accuracy: 0.1009\n",
            "Epoch 30/75\n",
            "59/59 [==============================] - 7s 112ms/step - loss: 2.3064 - accuracy: 0.0998\n",
            "Epoch 31/75\n",
            "59/59 [==============================] - 7s 113ms/step - loss: 2.3069 - accuracy: 0.0976\n",
            "Epoch 32/75\n",
            "59/59 [==============================] - 7s 113ms/step - loss: 2.3068 - accuracy: 0.0988\n",
            "Epoch 33/75\n",
            "59/59 [==============================] - 7s 114ms/step - loss: 2.3073 - accuracy: 0.0997\n",
            "Epoch 34/75\n",
            "59/59 [==============================] - 7s 114ms/step - loss: 2.3070 - accuracy: 0.1005\n",
            "Epoch 35/75\n",
            "59/59 [==============================] - 7s 117ms/step - loss: 2.3064 - accuracy: 0.1004\n",
            "Epoch 36/75\n",
            "59/59 [==============================] - 7s 116ms/step - loss: 2.3067 - accuracy: 0.1010\n",
            "Epoch 37/75\n",
            "59/59 [==============================] - 7s 120ms/step - loss: 2.3069 - accuracy: 0.0989\n",
            "Epoch 38/75\n",
            "59/59 [==============================] - 7s 119ms/step - loss: 2.3060 - accuracy: 0.1003\n",
            "Epoch 39/75\n",
            "59/59 [==============================] - 7s 121ms/step - loss: 2.3063 - accuracy: 0.0986\n",
            "Epoch 40/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3066 - accuracy: 0.1004\n",
            "Epoch 41/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3072 - accuracy: 0.0986\n",
            "Epoch 42/75\n",
            "59/59 [==============================] - 8s 129ms/step - loss: 2.3060 - accuracy: 0.1008\n",
            "Epoch 43/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.3068 - accuracy: 0.0985\n",
            "Epoch 44/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3065 - accuracy: 0.0980\n",
            "Epoch 45/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 2.3065 - accuracy: 0.0980\n",
            "Epoch 46/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 2.3063 - accuracy: 0.0994\n",
            "Epoch 47/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 2.3065 - accuracy: 0.1001\n",
            "Epoch 48/75\n",
            "59/59 [==============================] - 8s 127ms/step - loss: 2.3060 - accuracy: 0.1017\n",
            "Epoch 49/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3068 - accuracy: 0.0988\n",
            "Epoch 50/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3070 - accuracy: 0.1005\n",
            "Epoch 51/75\n",
            "59/59 [==============================] - 8s 130ms/step - loss: 2.3062 - accuracy: 0.1008\n",
            "Epoch 52/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 2.3074 - accuracy: 0.1003\n",
            "Epoch 53/75\n",
            "59/59 [==============================] - 8s 142ms/step - loss: 2.3073 - accuracy: 0.0994\n",
            "Epoch 54/75\n",
            "59/59 [==============================] - 8s 129ms/step - loss: 2.3068 - accuracy: 0.1006\n",
            "Epoch 55/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 2.3075 - accuracy: 0.0992\n",
            "Epoch 56/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 2.3066 - accuracy: 0.1002\n",
            "Epoch 57/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 2.3063 - accuracy: 0.0992\n",
            "Epoch 58/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 2.3066 - accuracy: 0.1004\n",
            "Epoch 59/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 2.3069 - accuracy: 0.0999\n",
            "Epoch 60/75\n",
            "59/59 [==============================] - 8s 129ms/step - loss: 2.3078 - accuracy: 0.0966\n",
            "Epoch 61/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 2.3066 - accuracy: 0.1007\n",
            "Epoch 62/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3067 - accuracy: 0.0981\n",
            "Epoch 63/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3067 - accuracy: 0.0992\n",
            "Epoch 64/75\n",
            "59/59 [==============================] - 8s 127ms/step - loss: 2.3062 - accuracy: 0.1001\n",
            "Epoch 65/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 2.3065 - accuracy: 0.1011\n",
            "Epoch 66/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 2.3061 - accuracy: 0.1007\n",
            "Epoch 67/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 2.3067 - accuracy: 0.1011\n",
            "Epoch 68/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.3068 - accuracy: 0.0982\n",
            "Epoch 69/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.3068 - accuracy: 0.0997\n",
            "Epoch 70/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.3069 - accuracy: 0.0991\n",
            "Epoch 71/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.3067 - accuracy: 0.0975\n",
            "Epoch 72/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 2.3064 - accuracy: 0.0994\n",
            "Epoch 73/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 2.3063 - accuracy: 0.0999\n",
            "Epoch 74/75\n",
            "59/59 [==============================] - 8s 133ms/step - loss: 2.3062 - accuracy: 0.1010\n",
            "Epoch 75/75\n",
            "59/59 [==============================] - 8s 127ms/step - loss: 2.3073 - accuracy: 0.0995\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.3070 - accuracy: 0.1000\n",
            "Epoch 1/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.5719 - accuracy: 0.1024\n",
            "Epoch 2/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 2.6247 - accuracy: 0.1021\n",
            "Epoch 3/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 2.6264 - accuracy: 0.0992\n",
            "Epoch 4/75\n",
            "250/250 [==============================] - 10s 40ms/step - loss: 2.6485 - accuracy: 0.0978\n",
            "Epoch 5/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 2.6179 - accuracy: 0.1011\n",
            "Epoch 6/75\n",
            "250/250 [==============================] - 10s 40ms/step - loss: 2.6248 - accuracy: 0.1000\n",
            "Epoch 7/75\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 2.6110 - accuracy: 0.1000\n",
            "Epoch 8/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.6082 - accuracy: 0.1001\n",
            "Epoch 9/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6201 - accuracy: 0.0994\n",
            "Epoch 10/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.6515 - accuracy: 0.0999\n",
            "Epoch 11/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6113 - accuracy: 0.0985\n",
            "Epoch 12/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.6214 - accuracy: 0.1004\n",
            "Epoch 13/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.5895 - accuracy: 0.0997\n",
            "Epoch 14/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6049 - accuracy: 0.0991\n",
            "Epoch 15/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6297 - accuracy: 0.0988\n",
            "Epoch 16/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6074 - accuracy: 0.0979\n",
            "Epoch 17/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6074 - accuracy: 0.1004\n",
            "Epoch 18/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6111 - accuracy: 0.0983\n",
            "Epoch 19/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6309 - accuracy: 0.1012\n",
            "Epoch 20/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6214 - accuracy: 0.1011\n",
            "Epoch 21/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6179 - accuracy: 0.1008\n",
            "Epoch 22/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6067 - accuracy: 0.0985\n",
            "Epoch 23/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6065 - accuracy: 0.0992\n",
            "Epoch 24/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.5929 - accuracy: 0.1004\n",
            "Epoch 25/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6188 - accuracy: 0.0982\n",
            "Epoch 26/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6272 - accuracy: 0.1008\n",
            "Epoch 27/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6347 - accuracy: 0.1015\n",
            "Epoch 28/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6199 - accuracy: 0.1022\n",
            "Epoch 29/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.6270 - accuracy: 0.0988\n",
            "Epoch 30/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.6301 - accuracy: 0.0980\n",
            "Epoch 31/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 2.6154 - accuracy: 0.1013\n",
            "Epoch 32/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.6487 - accuracy: 0.0955\n",
            "Epoch 33/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6010 - accuracy: 0.1024\n",
            "Epoch 34/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6471 - accuracy: 0.0993\n",
            "Epoch 35/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.6305 - accuracy: 0.1006\n",
            "Epoch 36/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6370 - accuracy: 0.1019\n",
            "Epoch 37/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.5854 - accuracy: 0.0993\n",
            "Epoch 38/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.6223 - accuracy: 0.1008\n",
            "Epoch 39/75\n",
            "250/250 [==============================] - 10s 40ms/step - loss: 2.6157 - accuracy: 0.1003\n",
            "Epoch 40/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6513 - accuracy: 0.0984\n",
            "Epoch 41/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6317 - accuracy: 0.0995\n",
            "Epoch 42/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.6385 - accuracy: 0.0978\n",
            "Epoch 43/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6044 - accuracy: 0.1006\n",
            "Epoch 44/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6240 - accuracy: 0.1026\n",
            "Epoch 45/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6288 - accuracy: 0.1020\n",
            "Epoch 46/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6351 - accuracy: 0.0988\n",
            "Epoch 47/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6066 - accuracy: 0.1016\n",
            "Epoch 48/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6037 - accuracy: 0.0998\n",
            "Epoch 49/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6196 - accuracy: 0.1019\n",
            "Epoch 50/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6077 - accuracy: 0.1010\n",
            "Epoch 51/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.6152 - accuracy: 0.1002\n",
            "Epoch 52/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6666 - accuracy: 0.0995\n",
            "Epoch 53/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6031 - accuracy: 0.1003\n",
            "Epoch 54/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6253 - accuracy: 0.0997\n",
            "Epoch 55/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6113 - accuracy: 0.1008\n",
            "Epoch 56/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6290 - accuracy: 0.0989\n",
            "Epoch 57/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6405 - accuracy: 0.0990\n",
            "Epoch 58/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6379 - accuracy: 0.0983\n",
            "Epoch 59/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6345 - accuracy: 0.0996\n",
            "Epoch 60/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.5978 - accuracy: 0.1009\n",
            "Epoch 61/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.6087 - accuracy: 0.0977\n",
            "Epoch 62/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.6279 - accuracy: 0.1007\n",
            "Epoch 63/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6349 - accuracy: 0.0983\n",
            "Epoch 64/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6131 - accuracy: 0.1015\n",
            "Epoch 65/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6039 - accuracy: 0.0987\n",
            "Epoch 66/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6314 - accuracy: 0.0996\n",
            "Epoch 67/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6160 - accuracy: 0.1027\n",
            "Epoch 68/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.5959 - accuracy: 0.1008\n",
            "Epoch 69/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.5961 - accuracy: 0.1016\n",
            "Epoch 70/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6226 - accuracy: 0.0989\n",
            "Epoch 71/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 2.6329 - accuracy: 0.0995\n",
            "Epoch 72/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.6552 - accuracy: 0.1005\n",
            "Epoch 73/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.5892 - accuracy: 0.1007\n",
            "Epoch 74/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 2.6240 - accuracy: 0.1007\n",
            "Epoch 75/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 2.6292 - accuracy: 0.1020\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.4179 - accuracy: 0.1000\n",
            "Epoch 1/75\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 2.4383 - accuracy: 0.1004\n",
            "Epoch 2/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.4674 - accuracy: 0.1013\n",
            "Epoch 3/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.4572 - accuracy: 0.0990\n",
            "Epoch 4/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.4402 - accuracy: 0.0994\n",
            "Epoch 5/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.4465 - accuracy: 0.0996\n",
            "Epoch 6/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4440 - accuracy: 0.1005\n",
            "Epoch 7/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.4302 - accuracy: 0.1016\n",
            "Epoch 8/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4615 - accuracy: 0.1014\n",
            "Epoch 9/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4342 - accuracy: 0.1007\n",
            "Epoch 10/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4486 - accuracy: 0.1021\n",
            "Epoch 11/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.4441 - accuracy: 0.1001\n",
            "Epoch 12/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4747 - accuracy: 0.0995\n",
            "Epoch 13/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.4731 - accuracy: 0.0993\n",
            "Epoch 14/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4484 - accuracy: 0.0998\n",
            "Epoch 15/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4652 - accuracy: 0.0982\n",
            "Epoch 16/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4506 - accuracy: 0.1003\n",
            "Epoch 17/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4548 - accuracy: 0.1000\n",
            "Epoch 18/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4587 - accuracy: 0.0989\n",
            "Epoch 19/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4559 - accuracy: 0.0993\n",
            "Epoch 20/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.4509 - accuracy: 0.0998\n",
            "Epoch 21/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4590 - accuracy: 0.0992\n",
            "Epoch 22/75\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 2.4528 - accuracy: 0.0998\n",
            "Epoch 23/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.4569 - accuracy: 0.1008\n",
            "Epoch 24/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4456 - accuracy: 0.1003\n",
            "Epoch 25/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.4706 - accuracy: 0.0995\n",
            "Epoch 26/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4604 - accuracy: 0.0993\n",
            "Epoch 27/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4453 - accuracy: 0.0990\n",
            "Epoch 28/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4588 - accuracy: 0.1003\n",
            "Epoch 29/75\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 2.4807 - accuracy: 0.0999\n",
            "Epoch 30/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 2.4496 - accuracy: 0.1001\n",
            "Epoch 31/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4371 - accuracy: 0.0999\n",
            "Epoch 32/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4625 - accuracy: 0.1005\n",
            "Epoch 33/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.4463 - accuracy: 0.1009\n",
            "Epoch 34/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.4635 - accuracy: 0.0978\n",
            "Epoch 35/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4644 - accuracy: 0.0988\n",
            "Epoch 36/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4426 - accuracy: 0.0978\n",
            "Epoch 37/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4539 - accuracy: 0.1004\n",
            "Epoch 38/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.4518 - accuracy: 0.1007\n",
            "Epoch 39/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4663 - accuracy: 0.0990\n",
            "Epoch 40/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.4521 - accuracy: 0.1005\n",
            "Epoch 41/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4609 - accuracy: 0.1004\n",
            "Epoch 42/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4463 - accuracy: 0.0992\n",
            "Epoch 43/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.4478 - accuracy: 0.1011\n",
            "Epoch 44/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4307 - accuracy: 0.1005\n",
            "Epoch 45/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.4455 - accuracy: 0.0982\n",
            "Epoch 46/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.4782 - accuracy: 0.0992\n",
            "Epoch 47/75\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 2.4604 - accuracy: 0.0999\n",
            "Epoch 48/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 2.4702 - accuracy: 0.0995\n",
            "Epoch 49/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.4393 - accuracy: 0.1003\n",
            "Epoch 50/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4645 - accuracy: 0.0995\n",
            "Epoch 51/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4392 - accuracy: 0.0978\n",
            "Epoch 52/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4486 - accuracy: 0.1006\n",
            "Epoch 53/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4800 - accuracy: 0.1021\n",
            "Epoch 54/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4516 - accuracy: 0.0998\n",
            "Epoch 55/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.4698 - accuracy: 0.0989\n",
            "Epoch 56/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.4554 - accuracy: 0.0980\n",
            "Epoch 57/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.4528 - accuracy: 0.1004\n",
            "Epoch 58/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4746 - accuracy: 0.0992\n",
            "Epoch 59/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4412 - accuracy: 0.1000\n",
            "Epoch 60/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.4988 - accuracy: 0.0972\n",
            "Epoch 61/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.4704 - accuracy: 0.1009\n",
            "Epoch 62/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4456 - accuracy: 0.1008\n",
            "Epoch 63/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.4483 - accuracy: 0.1011\n",
            "Epoch 64/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4556 - accuracy: 0.0984\n",
            "Epoch 65/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4476 - accuracy: 0.1003\n",
            "Epoch 66/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.4727 - accuracy: 0.0982\n",
            "Epoch 67/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.4572 - accuracy: 0.0975\n",
            "Epoch 68/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.4446 - accuracy: 0.0997\n",
            "Epoch 69/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 2.4565 - accuracy: 0.1020\n",
            "Epoch 70/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4520 - accuracy: 0.0994\n",
            "Epoch 71/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4528 - accuracy: 0.0996\n",
            "Epoch 72/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4556 - accuracy: 0.0999\n",
            "Epoch 73/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4701 - accuracy: 0.1005\n",
            "Epoch 74/75\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 2.4565 - accuracy: 0.1003\n",
            "Epoch 75/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 2.4279 - accuracy: 0.1014\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.4090 - accuracy: 0.1000\n",
            "Epoch 1/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4306 - accuracy: 0.0977\n",
            "Epoch 2/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4471 - accuracy: 0.0983\n",
            "Epoch 3/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4275 - accuracy: 0.0994\n",
            "Epoch 4/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4660 - accuracy: 0.0977\n",
            "Epoch 5/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4215 - accuracy: 0.1013\n",
            "Epoch 6/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4203 - accuracy: 0.0993\n",
            "Epoch 7/75\n",
            "72/72 [==============================] - 8s 111ms/step - loss: 2.4353 - accuracy: 0.0974\n",
            "Epoch 8/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4290 - accuracy: 0.0994\n",
            "Epoch 9/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4144 - accuracy: 0.1006\n",
            "Epoch 10/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4452 - accuracy: 0.0984\n",
            "Epoch 11/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4320 - accuracy: 0.1014\n",
            "Epoch 12/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4228 - accuracy: 0.0996\n",
            "Epoch 13/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4349 - accuracy: 0.1000\n",
            "Epoch 14/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4166 - accuracy: 0.1027\n",
            "Epoch 15/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.4388 - accuracy: 0.1021\n",
            "Epoch 16/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4107 - accuracy: 0.0998\n",
            "Epoch 17/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4193 - accuracy: 0.1015\n",
            "Epoch 18/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4180 - accuracy: 0.0982\n",
            "Epoch 19/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4284 - accuracy: 0.0987\n",
            "Epoch 20/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4232 - accuracy: 0.0994\n",
            "Epoch 21/75\n",
            "72/72 [==============================] - 8s 104ms/step - loss: 2.4147 - accuracy: 0.1005\n",
            "Epoch 22/75\n",
            "72/72 [==============================] - 7s 104ms/step - loss: 2.4166 - accuracy: 0.1005\n",
            "Epoch 23/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4446 - accuracy: 0.0988\n",
            "Epoch 24/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4145 - accuracy: 0.1001\n",
            "Epoch 25/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4288 - accuracy: 0.1004\n",
            "Epoch 26/75\n",
            "72/72 [==============================] - 7s 104ms/step - loss: 2.4202 - accuracy: 0.0993\n",
            "Epoch 27/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4610 - accuracy: 0.0993\n",
            "Epoch 28/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4364 - accuracy: 0.1001\n",
            "Epoch 29/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4115 - accuracy: 0.0997\n",
            "Epoch 30/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4106 - accuracy: 0.1006\n",
            "Epoch 31/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4267 - accuracy: 0.0998\n",
            "Epoch 32/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4260 - accuracy: 0.1006\n",
            "Epoch 33/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4201 - accuracy: 0.0986\n",
            "Epoch 34/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4283 - accuracy: 0.0992\n",
            "Epoch 35/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.4285 - accuracy: 0.0982\n",
            "Epoch 36/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.4383 - accuracy: 0.0997\n",
            "Epoch 37/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4411 - accuracy: 0.0960\n",
            "Epoch 38/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4380 - accuracy: 0.0974\n",
            "Epoch 39/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4329 - accuracy: 0.0982\n",
            "Epoch 40/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4259 - accuracy: 0.0993\n",
            "Epoch 41/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4346 - accuracy: 0.1013\n",
            "Epoch 42/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4368 - accuracy: 0.1009\n",
            "Epoch 43/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4169 - accuracy: 0.1005\n",
            "Epoch 44/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4223 - accuracy: 0.1007\n",
            "Epoch 45/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4495 - accuracy: 0.0980\n",
            "Epoch 46/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4272 - accuracy: 0.0992\n",
            "Epoch 47/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4290 - accuracy: 0.0986\n",
            "Epoch 48/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 2.4259 - accuracy: 0.1014\n",
            "Epoch 49/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 2.4320 - accuracy: 0.0986\n",
            "Epoch 50/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4361 - accuracy: 0.0967\n",
            "Epoch 51/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4171 - accuracy: 0.1004\n",
            "Epoch 52/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4294 - accuracy: 0.1003\n",
            "Epoch 53/75\n",
            "72/72 [==============================] - 7s 104ms/step - loss: 2.4198 - accuracy: 0.0997\n",
            "Epoch 54/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4381 - accuracy: 0.0989\n",
            "Epoch 55/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4207 - accuracy: 0.1018\n",
            "Epoch 56/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.4133 - accuracy: 0.1001\n",
            "Epoch 57/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4320 - accuracy: 0.0987\n",
            "Epoch 58/75\n",
            "72/72 [==============================] - 8s 104ms/step - loss: 2.4360 - accuracy: 0.1027\n",
            "Epoch 59/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4319 - accuracy: 0.0984\n",
            "Epoch 60/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4134 - accuracy: 0.1013\n",
            "Epoch 61/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 2.4428 - accuracy: 0.0993\n",
            "Epoch 62/75\n",
            "72/72 [==============================] - 8s 111ms/step - loss: 2.4130 - accuracy: 0.1006\n",
            "Epoch 63/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4291 - accuracy: 0.0999\n",
            "Epoch 64/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4255 - accuracy: 0.0991\n",
            "Epoch 65/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.4188 - accuracy: 0.0973\n",
            "Epoch 66/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4120 - accuracy: 0.0989\n",
            "Epoch 67/75\n",
            "72/72 [==============================] - 8s 113ms/step - loss: 2.4286 - accuracy: 0.1009\n",
            "Epoch 68/75\n",
            "72/72 [==============================] - 8s 116ms/step - loss: 2.4089 - accuracy: 0.1017\n",
            "Epoch 69/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 2.4249 - accuracy: 0.1005\n",
            "Epoch 70/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 2.4378 - accuracy: 0.1003\n",
            "Epoch 71/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 2.4395 - accuracy: 0.0967\n",
            "Epoch 72/75\n",
            "72/72 [==============================] - 8s 105ms/step - loss: 2.4252 - accuracy: 0.0983\n",
            "Epoch 73/75\n",
            "72/72 [==============================] - 7s 104ms/step - loss: 2.4356 - accuracy: 0.1008\n",
            "Epoch 74/75\n",
            "72/72 [==============================] - 8s 110ms/step - loss: 2.4332 - accuracy: 0.0985\n",
            "Epoch 75/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 2.4216 - accuracy: 0.1015\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.5489 - accuracy: 0.1000\n",
            "Epoch 1/75\n",
            "59/59 [==============================] - 7s 122ms/step - loss: 2.4237 - accuracy: 0.0996\n",
            "Epoch 2/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4120 - accuracy: 0.1019\n",
            "Epoch 3/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4198 - accuracy: 0.0990\n",
            "Epoch 4/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4243 - accuracy: 0.0978\n",
            "Epoch 5/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4175 - accuracy: 0.0994\n",
            "Epoch 6/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4100 - accuracy: 0.0987\n",
            "Epoch 7/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4163 - accuracy: 0.1026\n",
            "Epoch 8/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4232 - accuracy: 0.0997\n",
            "Epoch 9/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.3931 - accuracy: 0.1000\n",
            "Epoch 10/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4286 - accuracy: 0.0975\n",
            "Epoch 11/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4173 - accuracy: 0.0966\n",
            "Epoch 12/75\n",
            "59/59 [==============================] - 7s 123ms/step - loss: 2.4264 - accuracy: 0.0997\n",
            "Epoch 13/75\n",
            "59/59 [==============================] - 8s 132ms/step - loss: 2.4066 - accuracy: 0.1022\n",
            "Epoch 14/75\n",
            "59/59 [==============================] - 8s 136ms/step - loss: 2.4080 - accuracy: 0.0999\n",
            "Epoch 15/75\n",
            "59/59 [==============================] - 8s 144ms/step - loss: 2.4143 - accuracy: 0.1006\n",
            "Epoch 16/75\n",
            "59/59 [==============================] - 8s 132ms/step - loss: 2.4000 - accuracy: 0.1001\n",
            "Epoch 17/75\n",
            "59/59 [==============================] - 7s 123ms/step - loss: 2.4178 - accuracy: 0.0976\n",
            "Epoch 18/75\n",
            "59/59 [==============================] - 7s 123ms/step - loss: 2.4197 - accuracy: 0.0969\n",
            "Epoch 19/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4113 - accuracy: 0.1004\n",
            "Epoch 20/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4226 - accuracy: 0.1019\n",
            "Epoch 21/75\n",
            "59/59 [==============================] - 7s 123ms/step - loss: 2.4182 - accuracy: 0.0986\n",
            "Epoch 22/75\n",
            "59/59 [==============================] - 7s 123ms/step - loss: 2.4087 - accuracy: 0.1010\n",
            "Epoch 23/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.4170 - accuracy: 0.0978\n",
            "Epoch 24/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4123 - accuracy: 0.0989\n",
            "Epoch 25/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.3962 - accuracy: 0.0999\n",
            "Epoch 26/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4034 - accuracy: 0.0978\n",
            "Epoch 27/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4060 - accuracy: 0.0995\n",
            "Epoch 28/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.4216 - accuracy: 0.0992\n",
            "Epoch 29/75\n",
            "59/59 [==============================] - 7s 123ms/step - loss: 2.4290 - accuracy: 0.0995\n",
            "Epoch 30/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4087 - accuracy: 0.0996\n",
            "Epoch 31/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4371 - accuracy: 0.0983\n",
            "Epoch 32/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4037 - accuracy: 0.1016\n",
            "Epoch 33/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4169 - accuracy: 0.0985\n",
            "Epoch 34/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4215 - accuracy: 0.0971\n",
            "Epoch 35/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4151 - accuracy: 0.0985\n",
            "Epoch 36/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4312 - accuracy: 0.0979\n",
            "Epoch 37/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4145 - accuracy: 0.1006\n",
            "Epoch 38/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4232 - accuracy: 0.1005\n",
            "Epoch 39/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4156 - accuracy: 0.0998\n",
            "Epoch 40/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4256 - accuracy: 0.1000\n",
            "Epoch 41/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.3957 - accuracy: 0.1013\n",
            "Epoch 42/75\n",
            "59/59 [==============================] - 8s 129ms/step - loss: 2.4289 - accuracy: 0.0997\n",
            "Epoch 43/75\n",
            "59/59 [==============================] - 8s 130ms/step - loss: 2.4021 - accuracy: 0.0992\n",
            "Epoch 44/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4220 - accuracy: 0.1003\n",
            "Epoch 45/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4037 - accuracy: 0.0991\n",
            "Epoch 46/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4336 - accuracy: 0.1001\n",
            "Epoch 47/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4066 - accuracy: 0.1002\n",
            "Epoch 48/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4007 - accuracy: 0.1017\n",
            "Epoch 49/75\n",
            "59/59 [==============================] - 7s 123ms/step - loss: 2.4420 - accuracy: 0.0964\n",
            "Epoch 50/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4061 - accuracy: 0.1004\n",
            "Epoch 51/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 2.4126 - accuracy: 0.1003\n",
            "Epoch 52/75\n",
            "59/59 [==============================] - 7s 123ms/step - loss: 2.4107 - accuracy: 0.0975\n",
            "Epoch 53/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4375 - accuracy: 0.0975\n",
            "Epoch 54/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4219 - accuracy: 0.1003\n",
            "Epoch 55/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4111 - accuracy: 0.0990\n",
            "Epoch 56/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4031 - accuracy: 0.1032\n",
            "Epoch 57/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4060 - accuracy: 0.1003\n",
            "Epoch 58/75\n",
            "59/59 [==============================] - 7s 123ms/step - loss: 2.4170 - accuracy: 0.0988\n",
            "Epoch 59/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.3979 - accuracy: 0.0999\n",
            "Epoch 60/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4035 - accuracy: 0.1028\n",
            "Epoch 61/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4021 - accuracy: 0.1017\n",
            "Epoch 62/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4234 - accuracy: 0.1010\n",
            "Epoch 63/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4142 - accuracy: 0.0995\n",
            "Epoch 64/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4144 - accuracy: 0.0997\n",
            "Epoch 65/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4059 - accuracy: 0.0994\n",
            "Epoch 66/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4139 - accuracy: 0.1000\n",
            "Epoch 67/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4033 - accuracy: 0.1018\n",
            "Epoch 68/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4130 - accuracy: 0.0992\n",
            "Epoch 69/75\n",
            "59/59 [==============================] - 7s 122ms/step - loss: 2.4148 - accuracy: 0.0967\n",
            "Epoch 70/75\n",
            "59/59 [==============================] - 7s 123ms/step - loss: 2.4084 - accuracy: 0.0992\n",
            "Epoch 71/75\n",
            "59/59 [==============================] - 7s 121ms/step - loss: 2.4114 - accuracy: 0.0980\n",
            "Epoch 72/75\n",
            "59/59 [==============================] - 7s 123ms/step - loss: 2.4040 - accuracy: 0.0999\n",
            "Epoch 73/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 2.4113 - accuracy: 0.1005\n",
            "Epoch 74/75\n",
            "59/59 [==============================] - 7s 123ms/step - loss: 2.4031 - accuracy: 0.0996\n",
            "Epoch 75/75\n",
            "59/59 [==============================] - 7s 124ms/step - loss: 2.4191 - accuracy: 0.1017\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 2.4895 - accuracy: 0.1000\n",
            "Epoch 1/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 10.0390 - accuracy: 0.0982\n",
            "Epoch 2/75\n",
            "250/250 [==============================] - 10s 40ms/step - loss: 9.9483 - accuracy: 0.0993\n",
            "Epoch 3/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 9.7589 - accuracy: 0.0993\n",
            "Epoch 4/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 10.2995 - accuracy: 0.0990\n",
            "Epoch 5/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.5060 - accuracy: 0.1003\n",
            "Epoch 6/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 10.0828 - accuracy: 0.1003\n",
            "Epoch 7/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 9.6621 - accuracy: 0.0982\n",
            "Epoch 8/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 9.5167 - accuracy: 0.1001\n",
            "Epoch 9/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 9.3431 - accuracy: 0.0992\n",
            "Epoch 10/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 9.3012 - accuracy: 0.1008\n",
            "Epoch 11/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 10.0382 - accuracy: 0.0999\n",
            "Epoch 12/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.4492 - accuracy: 0.1019\n",
            "Epoch 13/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 10.1290 - accuracy: 0.0990\n",
            "Epoch 14/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 9.0519 - accuracy: 0.0994\n",
            "Epoch 15/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 9.5758 - accuracy: 0.0982\n",
            "Epoch 16/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 9.8496 - accuracy: 0.1008\n",
            "Epoch 17/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 10.2652 - accuracy: 0.1002\n",
            "Epoch 18/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 9.5855 - accuracy: 0.1000\n",
            "Epoch 19/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 10.2585 - accuracy: 0.1005\n",
            "Epoch 20/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 10.1942 - accuracy: 0.0991\n",
            "Epoch 21/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 10.2014 - accuracy: 0.1004\n",
            "Epoch 22/75\n",
            "250/250 [==============================] - 11s 45ms/step - loss: 9.5149 - accuracy: 0.1005\n",
            "Epoch 23/75\n",
            "250/250 [==============================] - 11s 46ms/step - loss: 9.4642 - accuracy: 0.0995\n",
            "Epoch 24/75\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 9.7510 - accuracy: 0.1014\n",
            "Epoch 25/75\n",
            "250/250 [==============================] - 10s 40ms/step - loss: 9.5380 - accuracy: 0.0986\n",
            "Epoch 26/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.1480 - accuracy: 0.1015\n",
            "Epoch 27/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 9.5181 - accuracy: 0.0998\n",
            "Epoch 28/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 9.8916 - accuracy: 0.0991\n",
            "Epoch 29/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 9.7921 - accuracy: 0.0989\n",
            "Epoch 30/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 10.3296 - accuracy: 0.0999\n",
            "Epoch 31/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 9.7780 - accuracy: 0.0993\n",
            "Epoch 32/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 9.6282 - accuracy: 0.1023\n",
            "Epoch 33/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 9.5482 - accuracy: 0.1001\n",
            "Epoch 34/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.6320 - accuracy: 0.1006\n",
            "Epoch 35/75\n",
            "250/250 [==============================] - 10s 40ms/step - loss: 10.2893 - accuracy: 0.1019\n",
            "Epoch 36/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 9.3493 - accuracy: 0.1005\n",
            "Epoch 37/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 9.7264 - accuracy: 0.1017\n",
            "Epoch 38/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.8879 - accuracy: 0.0991\n",
            "Epoch 39/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.7368 - accuracy: 0.0978\n",
            "Epoch 40/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 9.5298 - accuracy: 0.1001\n",
            "Epoch 41/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.6701 - accuracy: 0.0982\n",
            "Epoch 42/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 9.5006 - accuracy: 0.1008\n",
            "Epoch 43/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 9.5203 - accuracy: 0.0996\n",
            "Epoch 44/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 9.6972 - accuracy: 0.1007\n",
            "Epoch 45/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.2063 - accuracy: 0.1006\n",
            "Epoch 46/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 9.5782 - accuracy: 0.1022\n",
            "Epoch 47/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 9.2252 - accuracy: 0.1010\n",
            "Epoch 48/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.5215 - accuracy: 0.0984\n",
            "Epoch 49/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 9.5396 - accuracy: 0.1003\n",
            "Epoch 50/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 9.7334 - accuracy: 0.1018\n",
            "Epoch 51/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.3613 - accuracy: 0.0999\n",
            "Epoch 52/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 9.9960 - accuracy: 0.0997\n",
            "Epoch 53/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 9.4959 - accuracy: 0.1013\n",
            "Epoch 54/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.1371 - accuracy: 0.1025\n",
            "Epoch 55/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.4854 - accuracy: 0.1007\n",
            "Epoch 56/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.8270 - accuracy: 0.0986\n",
            "Epoch 57/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.7747 - accuracy: 0.0998\n",
            "Epoch 58/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 10.4577 - accuracy: 0.0976\n",
            "Epoch 59/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.6024 - accuracy: 0.1010\n",
            "Epoch 60/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.9257 - accuracy: 0.0998\n",
            "Epoch 61/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.7885 - accuracy: 0.0992\n",
            "Epoch 62/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 9.5466 - accuracy: 0.1001\n",
            "Epoch 63/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 10.1777 - accuracy: 0.1018\n",
            "Epoch 64/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 9.6442 - accuracy: 0.0994\n",
            "Epoch 65/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 9.8689 - accuracy: 0.1001\n",
            "Epoch 66/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.9401 - accuracy: 0.1013\n",
            "Epoch 67/75\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 10.1873 - accuracy: 0.0978\n",
            "Epoch 68/75\n",
            "250/250 [==============================] - 10s 40ms/step - loss: 9.8489 - accuracy: 0.0995\n",
            "Epoch 69/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 10.0266 - accuracy: 0.1016\n",
            "Epoch 70/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 10.1814 - accuracy: 0.0998\n",
            "Epoch 71/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.8340 - accuracy: 0.1008\n",
            "Epoch 72/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 9.7339 - accuracy: 0.1019\n",
            "Epoch 73/75\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 9.7491 - accuracy: 0.0990\n",
            "Epoch 74/75\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 9.9268 - accuracy: 0.1016\n",
            "Epoch 75/75\n",
            "250/250 [==============================] - 10s 38ms/step - loss: 9.6485 - accuracy: 0.1001\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 9.1491 - accuracy: 0.1000\n",
            "Epoch 1/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 7.9037 - accuracy: 0.0985\n",
            "Epoch 2/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 6.9020 - accuracy: 0.1013\n",
            "Epoch 3/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 7.8521 - accuracy: 0.1009\n",
            "Epoch 4/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.3275 - accuracy: 0.0959\n",
            "Epoch 5/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 8.2147 - accuracy: 0.1003\n",
            "Epoch 6/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 8.3680 - accuracy: 0.0981\n",
            "Epoch 7/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.5900 - accuracy: 0.1012\n",
            "Epoch 8/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.0658 - accuracy: 0.0995\n",
            "Epoch 9/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.6861 - accuracy: 0.1006\n",
            "Epoch 10/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.0293 - accuracy: 0.1024\n",
            "Epoch 11/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 7.9335 - accuracy: 0.1002\n",
            "Epoch 12/75\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 8.5408 - accuracy: 0.1014\n",
            "Epoch 13/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 7.8678 - accuracy: 0.1026\n",
            "Epoch 14/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 7.7161 - accuracy: 0.1002\n",
            "Epoch 15/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 7.7396 - accuracy: 0.1019\n",
            "Epoch 16/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 8.6361 - accuracy: 0.1011\n",
            "Epoch 17/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 8.6476 - accuracy: 0.0983\n",
            "Epoch 18/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.0675 - accuracy: 0.0980\n",
            "Epoch 19/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.6992 - accuracy: 0.0985\n",
            "Epoch 20/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 7.9544 - accuracy: 0.1003\n",
            "Epoch 21/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.0162 - accuracy: 0.1000\n",
            "Epoch 22/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 8.0991 - accuracy: 0.0998\n",
            "Epoch 23/75\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 7.7163 - accuracy: 0.0979\n",
            "Epoch 24/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.1608 - accuracy: 0.1004\n",
            "Epoch 25/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.5962 - accuracy: 0.0990\n",
            "Epoch 26/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.3091 - accuracy: 0.1018\n",
            "Epoch 27/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 7.9348 - accuracy: 0.1004\n",
            "Epoch 28/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.4407 - accuracy: 0.1005\n",
            "Epoch 29/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.4184 - accuracy: 0.0977\n",
            "Epoch 30/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 7.8893 - accuracy: 0.0992\n",
            "Epoch 31/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.2371 - accuracy: 0.1025\n",
            "Epoch 32/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.9456 - accuracy: 0.0989\n",
            "Epoch 33/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.3953 - accuracy: 0.0986\n",
            "Epoch 34/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.4376 - accuracy: 0.0986\n",
            "Epoch 35/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.5204 - accuracy: 0.1005\n",
            "Epoch 36/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.1297 - accuracy: 0.1008\n",
            "Epoch 37/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.5430 - accuracy: 0.0994\n",
            "Epoch 38/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 7.8091 - accuracy: 0.0999\n",
            "Epoch 39/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.5674 - accuracy: 0.0986\n",
            "Epoch 40/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.2632 - accuracy: 0.0991\n",
            "Epoch 41/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.5739 - accuracy: 0.0995\n",
            "Epoch 42/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 9.0007 - accuracy: 0.0989\n",
            "Epoch 43/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.0333 - accuracy: 0.1027\n",
            "Epoch 44/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 7.4542 - accuracy: 0.1017\n",
            "Epoch 45/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 7.8361 - accuracy: 0.1002\n",
            "Epoch 46/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 8.0152 - accuracy: 0.1003\n",
            "Epoch 47/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.7425 - accuracy: 0.0995\n",
            "Epoch 48/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 7.7559 - accuracy: 0.1003\n",
            "Epoch 49/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 9.4353 - accuracy: 0.1000\n",
            "Epoch 50/75\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 8.6832 - accuracy: 0.0979\n",
            "Epoch 51/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.4023 - accuracy: 0.0999\n",
            "Epoch 52/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.3134 - accuracy: 0.1014\n",
            "Epoch 53/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.3348 - accuracy: 0.1001\n",
            "Epoch 54/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 7.8274 - accuracy: 0.0987\n",
            "Epoch 55/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.1449 - accuracy: 0.0993\n",
            "Epoch 56/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.2201 - accuracy: 0.1001\n",
            "Epoch 57/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.3854 - accuracy: 0.0989\n",
            "Epoch 58/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 7.8774 - accuracy: 0.1004\n",
            "Epoch 59/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.2087 - accuracy: 0.0985\n",
            "Epoch 60/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.0005 - accuracy: 0.1004\n",
            "Epoch 61/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 7.8646 - accuracy: 0.1009\n",
            "Epoch 62/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.3720 - accuracy: 0.0979\n",
            "Epoch 63/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.6718 - accuracy: 0.0996\n",
            "Epoch 64/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.5055 - accuracy: 0.0999\n",
            "Epoch 65/75\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 8.7225 - accuracy: 0.0993\n",
            "Epoch 66/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.8364 - accuracy: 0.0963\n",
            "Epoch 67/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 7.7185 - accuracy: 0.0999\n",
            "Epoch 68/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.7458 - accuracy: 0.1007\n",
            "Epoch 69/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 7.5574 - accuracy: 0.1004\n",
            "Epoch 70/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.6085 - accuracy: 0.0985\n",
            "Epoch 71/75\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 8.6215 - accuracy: 0.1007\n",
            "Epoch 72/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 7.8349 - accuracy: 0.0980\n",
            "Epoch 73/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.5203 - accuracy: 0.1002\n",
            "Epoch 74/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 8.1821 - accuracy: 0.1006\n",
            "Epoch 75/75\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 7.6690 - accuracy: 0.0981\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 8.8054 - accuracy: 0.1000\n",
            "Epoch 1/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 8.4074 - accuracy: 0.0998\n",
            "Epoch 2/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 7.8444 - accuracy: 0.0997\n",
            "Epoch 3/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 7.3164 - accuracy: 0.0994\n",
            "Epoch 4/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 7.7237 - accuracy: 0.1007\n",
            "Epoch 5/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 7.1916 - accuracy: 0.1017\n",
            "Epoch 6/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 7.5246 - accuracy: 0.1008\n",
            "Epoch 7/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 8.2746 - accuracy: 0.1015\n",
            "Epoch 8/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 7.6367 - accuracy: 0.1023\n",
            "Epoch 9/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 7.3317 - accuracy: 0.0997\n",
            "Epoch 10/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 7.3355 - accuracy: 0.1010\n",
            "Epoch 11/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 8.4802 - accuracy: 0.1022\n",
            "Epoch 12/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 7.7703 - accuracy: 0.1021\n",
            "Epoch 13/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 8.5870 - accuracy: 0.0992\n",
            "Epoch 14/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 7.4376 - accuracy: 0.1003\n",
            "Epoch 15/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 7.5992 - accuracy: 0.0998\n",
            "Epoch 16/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 7.6149 - accuracy: 0.0992\n",
            "Epoch 17/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 7.9106 - accuracy: 0.1027\n",
            "Epoch 18/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 7.8653 - accuracy: 0.0994\n",
            "Epoch 19/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 7.4990 - accuracy: 0.0983\n",
            "Epoch 20/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 7.2827 - accuracy: 0.0993\n",
            "Epoch 21/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 8.4463 - accuracy: 0.0996\n",
            "Epoch 22/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 7.6357 - accuracy: 0.1031\n",
            "Epoch 23/75\n",
            "72/72 [==============================] - 8s 106ms/step - loss: 7.7436 - accuracy: 0.1017\n",
            "Epoch 24/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 8.3396 - accuracy: 0.1000\n",
            "Epoch 25/75\n",
            "72/72 [==============================] - 8s 111ms/step - loss: 8.1589 - accuracy: 0.1027\n",
            "Epoch 26/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 7.6456 - accuracy: 0.0988\n",
            "Epoch 27/75\n",
            "72/72 [==============================] - 8s 110ms/step - loss: 7.9316 - accuracy: 0.1027\n",
            "Epoch 28/75\n",
            "72/72 [==============================] - 8s 113ms/step - loss: 7.4891 - accuracy: 0.0994\n",
            "Epoch 29/75\n",
            "72/72 [==============================] - 8s 113ms/step - loss: 7.9232 - accuracy: 0.1020\n",
            "Epoch 30/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 7.6470 - accuracy: 0.0987\n",
            "Epoch 31/75\n",
            "72/72 [==============================] - 8s 113ms/step - loss: 7.9671 - accuracy: 0.0993\n",
            "Epoch 32/75\n",
            "72/72 [==============================] - 8s 111ms/step - loss: 7.3091 - accuracy: 0.1018\n",
            "Epoch 33/75\n",
            "72/72 [==============================] - 8s 111ms/step - loss: 7.8807 - accuracy: 0.0996\n",
            "Epoch 34/75\n",
            "72/72 [==============================] - 8s 111ms/step - loss: 8.7060 - accuracy: 0.0995\n",
            "Epoch 35/75\n",
            "72/72 [==============================] - 8s 111ms/step - loss: 8.0886 - accuracy: 0.0981\n",
            "Epoch 36/75\n",
            "72/72 [==============================] - 8s 111ms/step - loss: 8.6852 - accuracy: 0.0999\n",
            "Epoch 37/75\n",
            "72/72 [==============================] - 8s 113ms/step - loss: 7.5298 - accuracy: 0.1008\n",
            "Epoch 38/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 7.6913 - accuracy: 0.1001\n",
            "Epoch 39/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 7.4417 - accuracy: 0.1004\n",
            "Epoch 40/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 7.7706 - accuracy: 0.1003\n",
            "Epoch 41/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 6.9574 - accuracy: 0.0987\n",
            "Epoch 42/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 8.9600 - accuracy: 0.0985\n",
            "Epoch 43/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 8.4725 - accuracy: 0.0993\n",
            "Epoch 44/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 7.8706 - accuracy: 0.1032\n",
            "Epoch 45/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 7.9909 - accuracy: 0.0992\n",
            "Epoch 46/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 7.7954 - accuracy: 0.1005\n",
            "Epoch 47/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 7.2740 - accuracy: 0.1007\n",
            "Epoch 48/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 8.1591 - accuracy: 0.0996\n",
            "Epoch 49/75\n",
            "72/72 [==============================] - 8s 113ms/step - loss: 7.6302 - accuracy: 0.1013\n",
            "Epoch 50/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 8.4732 - accuracy: 0.1007\n",
            "Epoch 51/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 7.7559 - accuracy: 0.0989\n",
            "Epoch 52/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 7.8852 - accuracy: 0.1003\n",
            "Epoch 53/75\n",
            "72/72 [==============================] - 8s 107ms/step - loss: 7.8570 - accuracy: 0.1020\n",
            "Epoch 54/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 7.2937 - accuracy: 0.1003\n",
            "Epoch 55/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 8.0615 - accuracy: 0.1003\n",
            "Epoch 56/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 7.6852 - accuracy: 0.0970\n",
            "Epoch 57/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 8.5523 - accuracy: 0.0986\n",
            "Epoch 58/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 8.1239 - accuracy: 0.0987\n",
            "Epoch 59/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 7.9702 - accuracy: 0.1011\n",
            "Epoch 60/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 8.3303 - accuracy: 0.0965\n",
            "Epoch 61/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 8.1885 - accuracy: 0.0993\n",
            "Epoch 62/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 7.7256 - accuracy: 0.1014\n",
            "Epoch 63/75\n",
            "72/72 [==============================] - 8s 110ms/step - loss: 7.4171 - accuracy: 0.0995\n",
            "Epoch 64/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 7.6470 - accuracy: 0.1000\n",
            "Epoch 65/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 8.6027 - accuracy: 0.1000\n",
            "Epoch 66/75\n",
            "72/72 [==============================] - 8s 111ms/step - loss: 8.7554 - accuracy: 0.1004\n",
            "Epoch 67/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 8.5396 - accuracy: 0.1015\n",
            "Epoch 68/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 8.8226 - accuracy: 0.0980\n",
            "Epoch 69/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 7.4864 - accuracy: 0.1004\n",
            "Epoch 70/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 8.2505 - accuracy: 0.1000\n",
            "Epoch 71/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 8.1031 - accuracy: 0.1017\n",
            "Epoch 72/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 7.8442 - accuracy: 0.0991\n",
            "Epoch 73/75\n",
            "72/72 [==============================] - 8s 109ms/step - loss: 7.6883 - accuracy: 0.0988\n",
            "Epoch 74/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 7.8757 - accuracy: 0.1023\n",
            "Epoch 75/75\n",
            "72/72 [==============================] - 8s 108ms/step - loss: 7.5911 - accuracy: 0.1004\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 6.8600 - accuracy: 0.1000\n",
            "Epoch 1/75\n",
            "59/59 [==============================] - 8s 125ms/step - loss: 8.2641 - accuracy: 0.1015\n",
            "Epoch 2/75\n",
            "59/59 [==============================] - 8s 127ms/step - loss: 7.8523 - accuracy: 0.0986\n",
            "Epoch 3/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 8.1218 - accuracy: 0.0994\n",
            "Epoch 4/75\n",
            "59/59 [==============================] - 8s 127ms/step - loss: 6.8760 - accuracy: 0.1027\n",
            "Epoch 5/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 7.6245 - accuracy: 0.1016\n",
            "Epoch 6/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 8.5028 - accuracy: 0.1007\n",
            "Epoch 7/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 8.0421 - accuracy: 0.0998\n",
            "Epoch 8/75\n",
            "59/59 [==============================] - 8s 127ms/step - loss: 7.5428 - accuracy: 0.0993\n",
            "Epoch 9/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 7.5533 - accuracy: 0.0970\n",
            "Epoch 10/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 8.0772 - accuracy: 0.0999\n",
            "Epoch 11/75\n",
            "59/59 [==============================] - 8s 129ms/step - loss: 7.9907 - accuracy: 0.0989\n",
            "Epoch 12/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 8.5909 - accuracy: 0.0998\n",
            "Epoch 13/75\n",
            "59/59 [==============================] - 8s 131ms/step - loss: 7.5119 - accuracy: 0.1002\n",
            "Epoch 14/75\n",
            "59/59 [==============================] - 8s 131ms/step - loss: 7.5825 - accuracy: 0.0992\n",
            "Epoch 15/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 8.2987 - accuracy: 0.1017\n",
            "Epoch 16/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 7.4780 - accuracy: 0.0984\n",
            "Epoch 17/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 7.4903 - accuracy: 0.1006\n",
            "Epoch 18/75\n",
            "59/59 [==============================] - 8s 135ms/step - loss: 8.4493 - accuracy: 0.0998\n",
            "Epoch 19/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 8.1106 - accuracy: 0.1006\n",
            "Epoch 20/75\n",
            "59/59 [==============================] - 8s 135ms/step - loss: 7.4794 - accuracy: 0.1017\n",
            "Epoch 21/75\n",
            "59/59 [==============================] - 8s 134ms/step - loss: 7.2436 - accuracy: 0.0986\n",
            "Epoch 22/75\n",
            "59/59 [==============================] - 8s 130ms/step - loss: 8.0107 - accuracy: 0.0984\n",
            "Epoch 23/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 7.8798 - accuracy: 0.0985\n",
            "Epoch 24/75\n",
            "59/59 [==============================] - 8s 129ms/step - loss: 7.7404 - accuracy: 0.1008\n",
            "Epoch 25/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 7.7369 - accuracy: 0.0989\n",
            "Epoch 26/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 7.7811 - accuracy: 0.0995\n",
            "Epoch 27/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 7.1003 - accuracy: 0.0989\n",
            "Epoch 28/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 8.0142 - accuracy: 0.0978\n",
            "Epoch 29/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 7.4467 - accuracy: 0.1017\n",
            "Epoch 30/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 8.4334 - accuracy: 0.1038\n",
            "Epoch 31/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 8.0179 - accuracy: 0.0965\n",
            "Epoch 32/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 8.0635 - accuracy: 0.0993\n",
            "Epoch 33/75\n",
            "59/59 [==============================] - 8s 127ms/step - loss: 7.7530 - accuracy: 0.0986\n",
            "Epoch 34/75\n",
            "59/59 [==============================] - 8s 129ms/step - loss: 7.4603 - accuracy: 0.1015\n",
            "Epoch 35/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 7.5335 - accuracy: 0.1007\n",
            "Epoch 36/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 8.4090 - accuracy: 0.1007\n",
            "Epoch 37/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 7.6756 - accuracy: 0.1010\n",
            "Epoch 38/75\n",
            "59/59 [==============================] - 8s 129ms/step - loss: 8.6403 - accuracy: 0.0994\n",
            "Epoch 39/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 7.4111 - accuracy: 0.1008\n",
            "Epoch 40/75\n",
            "59/59 [==============================] - 8s 127ms/step - loss: 8.3607 - accuracy: 0.1009\n",
            "Epoch 41/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 7.6891 - accuracy: 0.1019\n",
            "Epoch 42/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 7.5905 - accuracy: 0.1005\n",
            "Epoch 43/75\n",
            "59/59 [==============================] - 8s 130ms/step - loss: 7.2895 - accuracy: 0.1014\n",
            "Epoch 44/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 7.3492 - accuracy: 0.1005\n",
            "Epoch 45/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 7.6549 - accuracy: 0.1012\n",
            "Epoch 46/75\n",
            "59/59 [==============================] - 8s 127ms/step - loss: 7.9805 - accuracy: 0.1006\n",
            "Epoch 47/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 7.9244 - accuracy: 0.1024\n",
            "Epoch 48/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 7.6602 - accuracy: 0.0997\n",
            "Epoch 49/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 7.8648 - accuracy: 0.0999\n",
            "Epoch 50/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 7.1842 - accuracy: 0.0991\n",
            "Epoch 51/75\n",
            "59/59 [==============================] - 8s 129ms/step - loss: 7.5104 - accuracy: 0.0996\n",
            "Epoch 52/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 8.1764 - accuracy: 0.1026\n",
            "Epoch 53/75\n",
            "59/59 [==============================] - 8s 127ms/step - loss: 7.8777 - accuracy: 0.0996\n",
            "Epoch 54/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 7.2127 - accuracy: 0.1001\n",
            "Epoch 55/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 8.0982 - accuracy: 0.1001\n",
            "Epoch 56/75\n",
            "59/59 [==============================] - 8s 130ms/step - loss: 7.3874 - accuracy: 0.0987\n",
            "Epoch 57/75\n",
            "59/59 [==============================] - 8s 130ms/step - loss: 7.2895 - accuracy: 0.1012\n",
            "Epoch 58/75\n",
            "59/59 [==============================] - 8s 135ms/step - loss: 7.5416 - accuracy: 0.1009\n",
            "Epoch 59/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 7.7375 - accuracy: 0.1000\n",
            "Epoch 60/75\n",
            "59/59 [==============================] - 7s 125ms/step - loss: 8.0426 - accuracy: 0.0998\n",
            "Epoch 61/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 8.0617 - accuracy: 0.1023\n",
            "Epoch 62/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 8.1859 - accuracy: 0.0983\n",
            "Epoch 63/75\n",
            "59/59 [==============================] - 8s 130ms/step - loss: 6.9732 - accuracy: 0.1003\n",
            "Epoch 64/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 7.8635 - accuracy: 0.0998\n",
            "Epoch 65/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 7.7034 - accuracy: 0.0985\n",
            "Epoch 66/75\n",
            "59/59 [==============================] - 8s 129ms/step - loss: 7.5834 - accuracy: 0.1012\n",
            "Epoch 67/75\n",
            "59/59 [==============================] - 8s 129ms/step - loss: 7.4705 - accuracy: 0.0996\n",
            "Epoch 68/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 8.0619 - accuracy: 0.0999\n",
            "Epoch 69/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 8.5146 - accuracy: 0.1011\n",
            "Epoch 70/75\n",
            "59/59 [==============================] - 7s 126ms/step - loss: 7.7609 - accuracy: 0.1007\n",
            "Epoch 71/75\n",
            "59/59 [==============================] - 8s 129ms/step - loss: 6.7068 - accuracy: 0.1012\n",
            "Epoch 72/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 7.3900 - accuracy: 0.0999\n",
            "Epoch 73/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 7.8423 - accuracy: 0.0984\n",
            "Epoch 74/75\n",
            "59/59 [==============================] - 8s 128ms/step - loss: 7.8763 - accuracy: 0.0988\n",
            "Epoch 75/75\n",
            "59/59 [==============================] - 7s 127ms/step - loss: 8.1561 - accuracy: 0.0995\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 8.2641 - accuracy: 0.1000\n"
          ]
        }
      ],
      "source": [
        "for i in [0.01,0.1,0.25,0.5]:\n",
        "  for j in [200,500,700,850]:\n",
        "  # lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "  #   initial_learning_rate=1e-2,\n",
        "  #   decay_steps=10000,\n",
        "  #   decay_rate=0.96)\n",
        "    model.compile(optimizer=keras.optimizers.SGD(learning_rate=i), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(x_train_gray, y_train, epochs=75, batch_size=j, verbose=1)\n",
        "    score = model.evaluate(x_test_gray,y_test)\n",
        "    scores.append(score)\n",
        "    params.append((i,j,scores,'SGD'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQiRMb9JeVUr",
        "outputId": "051f9f59-392f-4604-e86e-a4d270f1449c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1.3703720569610596, 0.5403000116348267],\n",
              " [1.4366624355316162, 0.5511000156402588],\n",
              " [1.6447285413742065, 0.5529000163078308],\n",
              " [1.9340101480484009, 0.5435000061988831],\n",
              " [2.4270150661468506, 0.10000000149011612],\n",
              " [2.3416428565979004, 0.10000000149011612],\n",
              " [2.4054806232452393, 0.10000000149011612],\n",
              " [2.313795804977417, 0.10000000149011612],\n",
              " [7.562735080718994, 0.10000000149011612],\n",
              " [2.335196018218994, 0.10000000149011612],\n",
              " [15.958453178405762, 0.10000000149011612],\n",
              " [5.297934055328369, 0.10000000149011612],\n",
              " [15.307839393615723, 0.10000000149011612],\n",
              " [20.11149024963379, 0.10000000149011612],\n",
              " [16.704113006591797, 0.10000000149011612],\n",
              " [11.867432594299316, 0.10000000149011612],\n",
              " [2.3041889667510986, 0.10000000149011612],\n",
              " [2.302712917327881, 0.10000000149011612],\n",
              " [2.302716016769409, 0.10000000149011612],\n",
              " [2.302767515182495, 0.10000000149011612],\n",
              " [2.3185558319091797, 0.10000000149011612],\n",
              " [2.3054375648498535, 0.10000000149011612],\n",
              " [2.3121559619903564, 0.10000000149011612],\n",
              " [2.306952714920044, 0.10000000149011612],\n",
              " [2.4179041385650635, 0.10000000149011612],\n",
              " [2.4090356826782227, 0.10000000149011612],\n",
              " [2.548919439315796, 0.10000000149011612],\n",
              " [2.489488363265991, 0.10000000149011612],\n",
              " [9.149055480957031, 0.10000000149011612],\n",
              " [8.8053560256958, 0.10000000149011612],\n",
              " [6.860042095184326, 0.10000000149011612],\n",
              " [8.264127731323242, 0.10000000149011612]]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaskAN0rhNqn",
        "outputId": "00a7e3d1-d180-40d1-e3eb-e28501512b20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0.01,\n",
              "  200,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'Adam'),\n",
              " (0.01,\n",
              "  500,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'Adam'),\n",
              " (0.01,\n",
              "  700,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'Adam'),\n",
              " (0.01,\n",
              "  850,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'Adam'),\n",
              " (0.1,\n",
              "  200,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'Adam'),\n",
              " (0.1,\n",
              "  500,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'Adam'),\n",
              " (0.1,\n",
              "  700,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'Adam'),\n",
              " (0.1,\n",
              "  850,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'Adam'),\n",
              " (0.25,\n",
              "  200,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'Adam'),\n",
              " (0.25,\n",
              "  500,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'Adam'),\n",
              " (0.25,\n",
              "  700,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'Adam'),\n",
              " (0.25,\n",
              "  850,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'Adam'),\n",
              " (0.5,\n",
              "  200,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'Adam'),\n",
              " (0.5,\n",
              "  500,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'Adam'),\n",
              " (0.5,\n",
              "  700,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'Adam'),\n",
              " (0.5,\n",
              "  850,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'Adam'),\n",
              " (0.01,\n",
              "  200,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'SGD'),\n",
              " (0.01,\n",
              "  500,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'SGD'),\n",
              " (0.01,\n",
              "  700,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'SGD'),\n",
              " (0.01,\n",
              "  850,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'SGD'),\n",
              " (0.1,\n",
              "  200,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'SGD'),\n",
              " (0.1,\n",
              "  500,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'SGD'),\n",
              " (0.1,\n",
              "  700,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'SGD'),\n",
              " (0.1,\n",
              "  850,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'SGD'),\n",
              " (0.25,\n",
              "  200,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'SGD'),\n",
              " (0.25,\n",
              "  500,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'SGD'),\n",
              " (0.25,\n",
              "  700,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'SGD'),\n",
              " (0.25,\n",
              "  850,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'SGD'),\n",
              " (0.5,\n",
              "  200,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'SGD'),\n",
              " (0.5,\n",
              "  500,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'SGD'),\n",
              " (0.5,\n",
              "  700,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'SGD'),\n",
              " (0.5,\n",
              "  850,\n",
              "  [[1.3703720569610596, 0.5403000116348267],\n",
              "   [1.4366624355316162, 0.5511000156402588],\n",
              "   [1.6447285413742065, 0.5529000163078308],\n",
              "   [1.9340101480484009, 0.5435000061988831],\n",
              "   [2.4270150661468506, 0.10000000149011612],\n",
              "   [2.3416428565979004, 0.10000000149011612],\n",
              "   [2.4054806232452393, 0.10000000149011612],\n",
              "   [2.313795804977417, 0.10000000149011612],\n",
              "   [7.562735080718994, 0.10000000149011612],\n",
              "   [2.335196018218994, 0.10000000149011612],\n",
              "   [15.958453178405762, 0.10000000149011612],\n",
              "   [5.297934055328369, 0.10000000149011612],\n",
              "   [15.307839393615723, 0.10000000149011612],\n",
              "   [20.11149024963379, 0.10000000149011612],\n",
              "   [16.704113006591797, 0.10000000149011612],\n",
              "   [11.867432594299316, 0.10000000149011612],\n",
              "   [2.3041889667510986, 0.10000000149011612],\n",
              "   [2.302712917327881, 0.10000000149011612],\n",
              "   [2.302716016769409, 0.10000000149011612],\n",
              "   [2.302767515182495, 0.10000000149011612],\n",
              "   [2.3185558319091797, 0.10000000149011612],\n",
              "   [2.3054375648498535, 0.10000000149011612],\n",
              "   [2.3121559619903564, 0.10000000149011612],\n",
              "   [2.306952714920044, 0.10000000149011612],\n",
              "   [2.4179041385650635, 0.10000000149011612],\n",
              "   [2.4090356826782227, 0.10000000149011612],\n",
              "   [2.548919439315796, 0.10000000149011612],\n",
              "   [2.489488363265991, 0.10000000149011612],\n",
              "   [9.149055480957031, 0.10000000149011612],\n",
              "   [8.8053560256958, 0.10000000149011612],\n",
              "   [6.860042095184326, 0.10000000149011612],\n",
              "   [8.264127731323242, 0.10000000149011612]],\n",
              "  'SGD')]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoBC55-ohRNF",
        "outputId": "0f6e8dcd-91f0-4a55-83ad-ebf698c2e2cb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>200</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.01</td>\n",
              "      <td>700</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.01</td>\n",
              "      <td>850</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.10</td>\n",
              "      <td>200</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.10</td>\n",
              "      <td>500</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.10</td>\n",
              "      <td>700</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.10</td>\n",
              "      <td>850</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.25</td>\n",
              "      <td>200</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.25</td>\n",
              "      <td>500</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.25</td>\n",
              "      <td>700</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.25</td>\n",
              "      <td>850</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.50</td>\n",
              "      <td>200</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.50</td>\n",
              "      <td>500</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.50</td>\n",
              "      <td>700</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.50</td>\n",
              "      <td>850</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.01</td>\n",
              "      <td>200</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.01</td>\n",
              "      <td>700</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.01</td>\n",
              "      <td>850</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.10</td>\n",
              "      <td>200</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.10</td>\n",
              "      <td>500</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.10</td>\n",
              "      <td>700</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.10</td>\n",
              "      <td>850</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.25</td>\n",
              "      <td>200</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.25</td>\n",
              "      <td>500</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.25</td>\n",
              "      <td>700</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.25</td>\n",
              "      <td>850</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.50</td>\n",
              "      <td>200</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.50</td>\n",
              "      <td>500</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.50</td>\n",
              "      <td>700</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.50</td>\n",
              "      <td>850</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1                                                  2     3\n",
              "0   0.01  200  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "1   0.01  500  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "2   0.01  700  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "3   0.01  850  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "4   0.10  200  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "5   0.10  500  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "6   0.10  700  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "7   0.10  850  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "8   0.25  200  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "9   0.25  500  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "10  0.25  700  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "11  0.25  850  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "12  0.50  200  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "13  0.50  500  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "14  0.50  700  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "15  0.50  850  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "16  0.01  200  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "17  0.01  500  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "18  0.01  700  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "19  0.01  850  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "20  0.10  200  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "21  0.10  500  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "22  0.10  700  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "23  0.10  850  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "24  0.25  200  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "25  0.25  500  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "26  0.25  700  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "27  0.25  850  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "28  0.50  200  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "29  0.50  500  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "30  0.50  700  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "31  0.50  850  [[1.3703720569610596, 0.5403000116348267], [1....   SGD"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores_df = pandas.DataFrame(scores)\n",
        "params_df = pandas.DataFrame(params)\n",
        "params_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntOLAOH9Lsb1",
        "outputId": "55bcd5ee-3e16-4a53-9590-b4499757b3c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_63 (Conv2D)          (None, 32, 32, 64)        1664      \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_64 (Conv2D)          (None, 16, 16, 64)        102464    \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_65 (Conv2D)          (None, 8, 8, 64)          102464    \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                262208    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 469,450\n",
            "Trainable params: 469,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "feed_forward = models.Sequential()\n",
        "feed_forward.add(layers.Conv2D(64, kernel_size=5, padding=\"same\",input_shape=(32,32,1),activation=\"tanh\"))\n",
        "feed_forward.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "        # CONV => RELU => POOL\n",
        "feed_forward.add(layers.Conv2D(64, kernel_size=5, padding=\"same\",activation=\"tanh\"))\n",
        "feed_forward.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "feed_forward.add(layers.Conv2D(64, kernel_size=5, padding=\"same\",activation = \"tanh\"))\n",
        "        # Flatten => RELU layers\n",
        "feed_forward.add(layers.Flatten())\n",
        "feed_forward.add(layers.Dense(64,activation = \"tanh\"))\n",
        "        # a softmax classifier\n",
        "feed_forward.add(layers.Dense(10,activation = \"softmax\"))\n",
        "feed_forward.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdFXbITbrlOT",
        "outputId": "5fd146cb-c679-4c6b-c6ad-cb30f4324a49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "250/250 [==============================] - 85s 339ms/step - loss: 2.3330 - accuracy: 0.0995\n",
            "Epoch 2/25\n",
            "250/250 [==============================] - 102s 409ms/step - loss: 2.3289 - accuracy: 0.0989\n",
            "Epoch 3/25\n",
            "250/250 [==============================] - 103s 412ms/step - loss: 2.3287 - accuracy: 0.0976\n",
            "Epoch 4/25\n",
            "250/250 [==============================] - 101s 403ms/step - loss: 2.3253 - accuracy: 0.0995\n",
            "Epoch 5/25\n",
            "250/250 [==============================] - 102s 407ms/step - loss: 2.3287 - accuracy: 0.0986\n",
            "Epoch 6/25\n",
            "250/250 [==============================] - 101s 405ms/step - loss: 2.3310 - accuracy: 0.1027\n",
            "Epoch 7/25\n",
            "250/250 [==============================] - 101s 403ms/step - loss: 2.3251 - accuracy: 0.0997\n",
            "Epoch 8/25\n",
            "250/250 [==============================] - 101s 403ms/step - loss: 2.3295 - accuracy: 0.0991\n",
            "Epoch 9/25\n",
            "250/250 [==============================] - 102s 408ms/step - loss: 2.3244 - accuracy: 0.1001\n",
            "Epoch 10/25\n",
            "250/250 [==============================] - 101s 403ms/step - loss: 2.3275 - accuracy: 0.1010\n",
            "Epoch 11/25\n",
            "250/250 [==============================] - 102s 407ms/step - loss: 2.3296 - accuracy: 0.0987\n",
            "Epoch 12/25\n",
            "250/250 [==============================] - 101s 405ms/step - loss: 2.3281 - accuracy: 0.1002\n",
            "Epoch 13/25\n",
            "250/250 [==============================] - 102s 407ms/step - loss: 2.3283 - accuracy: 0.1004\n",
            "Epoch 14/25\n",
            "250/250 [==============================] - 102s 409ms/step - loss: 2.3263 - accuracy: 0.1012\n",
            "Epoch 15/25\n",
            "250/250 [==============================] - 101s 405ms/step - loss: 2.3334 - accuracy: 0.0970\n",
            "Epoch 16/25\n",
            "250/250 [==============================] - 101s 404ms/step - loss: 2.3295 - accuracy: 0.1010\n",
            "Epoch 17/25\n",
            "250/250 [==============================] - 101s 406ms/step - loss: 2.3305 - accuracy: 0.1010\n",
            "Epoch 18/25\n",
            "250/250 [==============================] - 103s 414ms/step - loss: 2.3277 - accuracy: 0.0995\n",
            "Epoch 19/25\n",
            "250/250 [==============================] - 102s 406ms/step - loss: 2.3238 - accuracy: 0.0998\n",
            "Epoch 20/25\n",
            "250/250 [==============================] - 101s 406ms/step - loss: 2.3273 - accuracy: 0.1007\n",
            "Epoch 21/25\n",
            "250/250 [==============================] - 102s 407ms/step - loss: 2.3306 - accuracy: 0.1006\n",
            "Epoch 22/25\n",
            "250/250 [==============================] - 101s 406ms/step - loss: 2.3265 - accuracy: 0.0957\n",
            "Epoch 23/25\n",
            "250/250 [==============================] - 102s 410ms/step - loss: 2.3292 - accuracy: 0.0985\n",
            "Epoch 24/25\n",
            "250/250 [==============================] - 102s 407ms/step - loss: 2.3268 - accuracy: 0.1022\n",
            "Epoch 25/25\n",
            "250/250 [==============================] - 101s 405ms/step - loss: 2.3287 - accuracy: 0.1004\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 8.2641 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 96s 956ms/step - loss: 2.3197 - accuracy: 0.1001\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 97s 970ms/step - loss: 2.3178 - accuracy: 0.1001\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 96s 958ms/step - loss: 2.3152 - accuracy: 0.1003\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 96s 959ms/step - loss: 2.3197 - accuracy: 0.1001\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 97s 967ms/step - loss: 2.3168 - accuracy: 0.0980\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 97s 967ms/step - loss: 2.3149 - accuracy: 0.1000\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 96s 960ms/step - loss: 2.3171 - accuracy: 0.0987\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 96s 960ms/step - loss: 2.3172 - accuracy: 0.1001\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 96s 960ms/step - loss: 2.3182 - accuracy: 0.0971\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 95s 953ms/step - loss: 2.3160 - accuracy: 0.0998\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 98s 981ms/step - loss: 2.3153 - accuracy: 0.1029\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 97s 969ms/step - loss: 2.3212 - accuracy: 0.1003\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 99s 992ms/step - loss: 2.3143 - accuracy: 0.0997\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 97s 972ms/step - loss: 2.3175 - accuracy: 0.0988\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 99s 990ms/step - loss: 2.3160 - accuracy: 0.0995\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 99s 988ms/step - loss: 2.3161 - accuracy: 0.0996\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 98s 984ms/step - loss: 2.3147 - accuracy: 0.1004\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 105s 1s/step - loss: 2.3170 - accuracy: 0.1016\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 111s 1s/step - loss: 2.3172 - accuracy: 0.0988\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 107s 1s/step - loss: 2.3170 - accuracy: 0.1000\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 102s 1s/step - loss: 2.3179 - accuracy: 0.1002\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 100s 1s/step - loss: 2.3163 - accuracy: 0.1000\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 117s 1s/step - loss: 2.3173 - accuracy: 0.0986\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 106s 1s/step - loss: 2.3153 - accuracy: 0.1007\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 105s 1s/step - loss: 2.3126 - accuracy: 0.1004\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 8.2641 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "72/72 [==============================] - 98s 1s/step - loss: 2.3259 - accuracy: 0.0985\n",
            "Epoch 2/25\n",
            "72/72 [==============================] - 98s 1s/step - loss: 2.3121 - accuracy: 0.1014\n",
            "Epoch 3/25\n",
            "72/72 [==============================] - 96s 1s/step - loss: 2.3161 - accuracy: 0.1018\n",
            "Epoch 4/25\n",
            "72/72 [==============================] - 97s 1s/step - loss: 2.3151 - accuracy: 0.0983\n",
            "Epoch 5/25\n",
            "72/72 [==============================] - 97s 1s/step - loss: 2.3172 - accuracy: 0.0979\n",
            "Epoch 6/25\n",
            "72/72 [==============================] - 97s 1s/step - loss: 2.3175 - accuracy: 0.0989\n",
            "Epoch 7/25\n",
            "72/72 [==============================] - 96s 1s/step - loss: 2.3120 - accuracy: 0.0999\n",
            "Epoch 8/25\n",
            "72/72 [==============================] - 98s 1s/step - loss: 2.3145 - accuracy: 0.0999\n",
            "Epoch 9/25\n",
            "72/72 [==============================] - 101s 1s/step - loss: 2.3136 - accuracy: 0.0980\n",
            "Epoch 10/25\n",
            "72/72 [==============================] - 113s 2s/step - loss: 2.3156 - accuracy: 0.0989\n",
            "Epoch 11/25\n",
            "72/72 [==============================] - 110s 2s/step - loss: 2.3155 - accuracy: 0.0994\n",
            "Epoch 12/25\n",
            "72/72 [==============================] - 111s 2s/step - loss: 2.3118 - accuracy: 0.1000\n",
            "Epoch 13/25\n",
            "72/72 [==============================] - 99s 1s/step - loss: 2.3134 - accuracy: 0.1012\n",
            "Epoch 14/25\n",
            "72/72 [==============================] - 97s 1s/step - loss: 2.3143 - accuracy: 0.1004\n",
            "Epoch 15/25\n",
            "72/72 [==============================] - 97s 1s/step - loss: 2.3144 - accuracy: 0.1001\n",
            "Epoch 16/25\n",
            "72/72 [==============================] - 98s 1s/step - loss: 2.3165 - accuracy: 0.0995\n",
            "Epoch 17/25\n",
            "72/72 [==============================] - 97s 1s/step - loss: 2.3154 - accuracy: 0.0992\n",
            "Epoch 18/25\n",
            "72/72 [==============================] - 97s 1s/step - loss: 2.3128 - accuracy: 0.1014\n",
            "Epoch 19/25\n",
            "72/72 [==============================] - 97s 1s/step - loss: 2.3124 - accuracy: 0.1010\n",
            "Epoch 20/25\n",
            "72/72 [==============================] - 97s 1s/step - loss: 2.3167 - accuracy: 0.0998\n",
            "Epoch 21/25\n",
            "72/72 [==============================] - 96s 1s/step - loss: 2.3168 - accuracy: 0.0990\n",
            "Epoch 22/25\n",
            "72/72 [==============================] - 97s 1s/step - loss: 2.3141 - accuracy: 0.0987\n",
            "Epoch 23/25\n",
            "72/72 [==============================] - 96s 1s/step - loss: 2.3164 - accuracy: 0.0975\n",
            "Epoch 24/25\n",
            "72/72 [==============================] - 96s 1s/step - loss: 2.3136 - accuracy: 0.0996\n",
            "Epoch 25/25\n",
            "72/72 [==============================] - 96s 1s/step - loss: 2.3145 - accuracy: 0.0994\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 8.2641 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "59/59 [==============================] - 97s 2s/step - loss: 2.3218 - accuracy: 0.1004\n",
            "Epoch 2/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3097 - accuracy: 0.0980\n",
            "Epoch 3/25\n",
            "59/59 [==============================] - 96s 2s/step - loss: 2.3127 - accuracy: 0.0992\n",
            "Epoch 4/25\n",
            "59/59 [==============================] - 96s 2s/step - loss: 2.3157 - accuracy: 0.1000\n",
            "Epoch 5/25\n",
            "59/59 [==============================] - 96s 2s/step - loss: 2.3170 - accuracy: 0.1004\n",
            "Epoch 6/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3123 - accuracy: 0.0990\n",
            "Epoch 7/25\n",
            "59/59 [==============================] - 96s 2s/step - loss: 2.3123 - accuracy: 0.0983\n",
            "Epoch 8/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3111 - accuracy: 0.1003\n",
            "Epoch 9/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3175 - accuracy: 0.0976\n",
            "Epoch 10/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3122 - accuracy: 0.0969\n",
            "Epoch 11/25\n",
            "59/59 [==============================] - 96s 2s/step - loss: 2.3099 - accuracy: 0.0994\n",
            "Epoch 12/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3131 - accuracy: 0.1008\n",
            "Epoch 13/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3141 - accuracy: 0.1014\n",
            "Epoch 14/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3136 - accuracy: 0.1013\n",
            "Epoch 15/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3137 - accuracy: 0.1014\n",
            "Epoch 16/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3108 - accuracy: 0.1004\n",
            "Epoch 17/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3160 - accuracy: 0.0990\n",
            "Epoch 18/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3119 - accuracy: 0.0997\n",
            "Epoch 19/25\n",
            "59/59 [==============================] - 96s 2s/step - loss: 2.3129 - accuracy: 0.1021\n",
            "Epoch 20/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3117 - accuracy: 0.0996\n",
            "Epoch 21/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3146 - accuracy: 0.0978\n",
            "Epoch 22/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3121 - accuracy: 0.0985\n",
            "Epoch 23/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3125 - accuracy: 0.1004\n",
            "Epoch 24/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3156 - accuracy: 0.1004\n",
            "Epoch 25/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3151 - accuracy: 0.0990\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 8.2641 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "250/250 [==============================] - 104s 415ms/step - loss: 2.6726 - accuracy: 0.1000\n",
            "Epoch 2/25\n",
            "250/250 [==============================] - 90s 360ms/step - loss: 2.4773 - accuracy: 0.0993\n",
            "Epoch 3/25\n",
            "250/250 [==============================] - 91s 365ms/step - loss: 2.4699 - accuracy: 0.1008\n",
            "Epoch 4/25\n",
            "250/250 [==============================] - 90s 362ms/step - loss: 2.4869 - accuracy: 0.0988\n",
            "Epoch 5/25\n",
            "250/250 [==============================] - 95s 380ms/step - loss: 2.5022 - accuracy: 0.0990\n",
            "Epoch 6/25\n",
            "250/250 [==============================] - 92s 370ms/step - loss: 2.4860 - accuracy: 0.1002\n",
            "Epoch 7/25\n",
            "250/250 [==============================] - 97s 390ms/step - loss: 2.4802 - accuracy: 0.0994\n",
            "Epoch 8/25\n",
            "250/250 [==============================] - 98s 390ms/step - loss: 2.4945 - accuracy: 0.0992\n",
            "Epoch 9/25\n",
            "250/250 [==============================] - 93s 370ms/step - loss: 2.4533 - accuracy: 0.1000\n",
            "Epoch 10/25\n",
            "250/250 [==============================] - 98s 390ms/step - loss: 2.4913 - accuracy: 0.0994\n",
            "Epoch 11/25\n",
            "250/250 [==============================] - 94s 377ms/step - loss: 2.5291 - accuracy: 0.0978\n",
            "Epoch 12/25\n",
            "250/250 [==============================] - 101s 404ms/step - loss: 2.4848 - accuracy: 0.1009\n",
            "Epoch 13/25\n",
            "250/250 [==============================] - 99s 396ms/step - loss: 2.4716 - accuracy: 0.0996\n",
            "Epoch 14/25\n",
            "250/250 [==============================] - 99s 395ms/step - loss: 2.4832 - accuracy: 0.0998\n",
            "Epoch 15/25\n",
            "250/250 [==============================] - 99s 395ms/step - loss: 2.4788 - accuracy: 0.0977\n",
            "Epoch 16/25\n",
            "250/250 [==============================] - 99s 395ms/step - loss: 2.4727 - accuracy: 0.1003\n",
            "Epoch 17/25\n",
            "250/250 [==============================] - 98s 393ms/step - loss: 2.4718 - accuracy: 0.1019\n",
            "Epoch 18/25\n",
            "250/250 [==============================] - 99s 394ms/step - loss: 2.4602 - accuracy: 0.1011\n",
            "Epoch 19/25\n",
            "250/250 [==============================] - 99s 394ms/step - loss: 2.4796 - accuracy: 0.0998\n",
            "Epoch 20/25\n",
            "250/250 [==============================] - 99s 396ms/step - loss: 2.4798 - accuracy: 0.0993\n",
            "Epoch 21/25\n",
            "250/250 [==============================] - 99s 395ms/step - loss: 2.4956 - accuracy: 0.0988\n",
            "Epoch 22/25\n",
            "250/250 [==============================] - 98s 394ms/step - loss: 2.5619 - accuracy: 0.0994\n",
            "Epoch 23/25\n",
            "250/250 [==============================] - 98s 392ms/step - loss: 2.4745 - accuracy: 0.1007\n",
            "Epoch 24/25\n",
            "250/250 [==============================] - 98s 393ms/step - loss: 2.4707 - accuracy: 0.1007\n",
            "Epoch 25/25\n",
            "250/250 [==============================] - 98s 394ms/step - loss: 2.5147 - accuracy: 0.0996\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 8.2641 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 92s 917ms/step - loss: 3.0612 - accuracy: 0.0998\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 88s 881ms/step - loss: 2.3603 - accuracy: 0.1002\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 91s 906ms/step - loss: 2.3717 - accuracy: 0.1010\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 90s 899ms/step - loss: 2.3665 - accuracy: 0.0985\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 89s 889ms/step - loss: 2.4050 - accuracy: 0.1012\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 89s 888ms/step - loss: 2.4287 - accuracy: 0.0988\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 93s 926ms/step - loss: 2.3890 - accuracy: 0.0993\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 89s 884ms/step - loss: 2.4099 - accuracy: 0.1012\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 90s 902ms/step - loss: 2.4123 - accuracy: 0.1004\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 92s 917ms/step - loss: 2.3847 - accuracy: 0.0981\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 89s 894ms/step - loss: 2.4063 - accuracy: 0.0998\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 88s 882ms/step - loss: 2.4373 - accuracy: 0.0993\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 91s 909ms/step - loss: 2.3930 - accuracy: 0.1033\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 93s 930ms/step - loss: 2.4599 - accuracy: 0.1010\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 92s 916ms/step - loss: 2.6925 - accuracy: 0.1026\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 90s 902ms/step - loss: 2.4722 - accuracy: 0.0997\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 93s 926ms/step - loss: 2.3977 - accuracy: 0.1002\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 94s 941ms/step - loss: 2.3739 - accuracy: 0.0984\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 94s 936ms/step - loss: 2.4245 - accuracy: 0.0997\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 94s 937ms/step - loss: 2.4183 - accuracy: 0.1010\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 94s 938ms/step - loss: 2.4108 - accuracy: 0.1001\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 94s 935ms/step - loss: 2.3987 - accuracy: 0.0981\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 95s 949ms/step - loss: 2.3961 - accuracy: 0.0996\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 94s 945ms/step - loss: 2.3942 - accuracy: 0.0976\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 96s 965ms/step - loss: 2.4119 - accuracy: 0.0986\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 8.2641 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 2.9232 - accuracy: 0.1023\n",
            "Epoch 2/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 2.3451 - accuracy: 0.1000\n",
            "Epoch 3/25\n",
            "72/72 [==============================] - 93s 1s/step - loss: 2.3645 - accuracy: 0.0984\n",
            "Epoch 4/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 2.4099 - accuracy: 0.0990\n",
            "Epoch 5/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 2.3790 - accuracy: 0.0997\n",
            "Epoch 6/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 2.3835 - accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 2.3758 - accuracy: 0.0972\n",
            "Epoch 8/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 2.4016 - accuracy: 0.1014\n",
            "Epoch 9/25\n",
            "72/72 [==============================] - 93s 1s/step - loss: 2.4388 - accuracy: 0.1021\n",
            "Epoch 10/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 2.3796 - accuracy: 0.0997\n",
            "Epoch 11/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 2.3616 - accuracy: 0.0997\n",
            "Epoch 12/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 2.4312 - accuracy: 0.0990\n",
            "Epoch 13/25\n",
            "72/72 [==============================] - 91s 1s/step - loss: 2.3865 - accuracy: 0.0982\n",
            "Epoch 14/25\n",
            "72/72 [==============================] - 89s 1s/step - loss: 2.4593 - accuracy: 0.0997\n",
            "Epoch 15/25\n",
            "72/72 [==============================] - 91s 1s/step - loss: 2.4680 - accuracy: 0.1001\n",
            "Epoch 16/25\n",
            "72/72 [==============================] - 92s 1s/step - loss: 2.7156 - accuracy: 0.1001\n",
            "Epoch 17/25\n",
            "72/72 [==============================] - 92s 1s/step - loss: 2.3696 - accuracy: 0.0984\n",
            "Epoch 18/25\n",
            "72/72 [==============================] - 92s 1s/step - loss: 2.3826 - accuracy: 0.0981\n",
            "Epoch 19/25\n",
            "72/72 [==============================] - 92s 1s/step - loss: 2.3739 - accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 2.3612 - accuracy: 0.0978\n",
            "Epoch 21/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 2.3631 - accuracy: 0.0999\n",
            "Epoch 22/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 2.3823 - accuracy: 0.0986\n",
            "Epoch 23/25\n",
            "72/72 [==============================] - 93s 1s/step - loss: 2.3961 - accuracy: 0.1007\n",
            "Epoch 24/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 2.3959 - accuracy: 0.0988\n",
            "Epoch 25/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 2.3739 - accuracy: 0.1001\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 8.2641 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 3.2513 - accuracy: 0.1021\n",
            "Epoch 2/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3323 - accuracy: 0.1003\n",
            "Epoch 3/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3393 - accuracy: 0.0987\n",
            "Epoch 4/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3366 - accuracy: 0.1008\n",
            "Epoch 5/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3590 - accuracy: 0.0998\n",
            "Epoch 6/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.4017 - accuracy: 0.0994\n",
            "Epoch 7/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3578 - accuracy: 0.1006\n",
            "Epoch 8/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3523 - accuracy: 0.0982\n",
            "Epoch 9/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3753 - accuracy: 0.0993\n",
            "Epoch 10/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3713 - accuracy: 0.0992\n",
            "Epoch 11/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3870 - accuracy: 0.0972\n",
            "Epoch 12/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3622 - accuracy: 0.0981\n",
            "Epoch 13/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3747 - accuracy: 0.1007\n",
            "Epoch 14/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3784 - accuracy: 0.1010\n",
            "Epoch 15/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3903 - accuracy: 0.1004\n",
            "Epoch 16/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3551 - accuracy: 0.1012\n",
            "Epoch 17/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3904 - accuracy: 0.1012\n",
            "Epoch 18/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.4111 - accuracy: 0.0999\n",
            "Epoch 19/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3919 - accuracy: 0.1028\n",
            "Epoch 20/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3869 - accuracy: 0.1019\n",
            "Epoch 21/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3964 - accuracy: 0.1006\n",
            "Epoch 22/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3738 - accuracy: 0.0987\n",
            "Epoch 23/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3705 - accuracy: 0.1002\n",
            "Epoch 24/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3833 - accuracy: 0.0999\n",
            "Epoch 25/25\n",
            "59/59 [==============================] - 96s 2s/step - loss: 2.3783 - accuracy: 0.0998\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 8.2641 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "250/250 [==============================] - 99s 397ms/step - loss: 4.9982 - accuracy: 0.1007\n",
            "Epoch 2/25\n",
            "250/250 [==============================] - 100s 401ms/step - loss: 5.6962 - accuracy: 0.0972\n",
            "Epoch 3/25\n",
            "250/250 [==============================] - 100s 401ms/step - loss: 2.5952 - accuracy: 0.1008\n",
            "Epoch 4/25\n",
            "250/250 [==============================] - 100s 401ms/step - loss: 6.3088 - accuracy: 0.0991\n",
            "Epoch 5/25\n",
            "250/250 [==============================] - 100s 400ms/step - loss: 2.6080 - accuracy: 0.1013\n",
            "Epoch 6/25\n",
            "250/250 [==============================] - 100s 398ms/step - loss: 3.9101 - accuracy: 0.1015\n",
            "Epoch 7/25\n",
            "250/250 [==============================] - 99s 394ms/step - loss: 5.8652 - accuracy: 0.0989\n",
            "Epoch 8/25\n",
            "250/250 [==============================] - 100s 400ms/step - loss: 2.7505 - accuracy: 0.1002\n",
            "Epoch 9/25\n",
            "250/250 [==============================] - 101s 404ms/step - loss: 5.0629 - accuracy: 0.0993\n",
            "Epoch 10/25\n",
            "250/250 [==============================] - 99s 396ms/step - loss: 2.5932 - accuracy: 0.0982\n",
            "Epoch 11/25\n",
            "250/250 [==============================] - 99s 398ms/step - loss: 5.7453 - accuracy: 0.0997\n",
            "Epoch 12/25\n",
            "250/250 [==============================] - 99s 396ms/step - loss: 2.8573 - accuracy: 0.0993\n",
            "Epoch 13/25\n",
            "250/250 [==============================] - 100s 399ms/step - loss: 2.6682 - accuracy: 0.1015\n",
            "Epoch 14/25\n",
            "250/250 [==============================] - 99s 397ms/step - loss: 5.0286 - accuracy: 0.1011\n",
            "Epoch 15/25\n",
            "250/250 [==============================] - 100s 398ms/step - loss: 6.6342 - accuracy: 0.1003\n",
            "Epoch 16/25\n",
            "250/250 [==============================] - 100s 400ms/step - loss: 2.6564 - accuracy: 0.0994\n",
            "Epoch 17/25\n",
            "250/250 [==============================] - 108s 430ms/step - loss: 2.5711 - accuracy: 0.1025\n",
            "Epoch 18/25\n",
            "250/250 [==============================] - 110s 439ms/step - loss: 5.9720 - accuracy: 0.1003\n",
            "Epoch 19/25\n",
            "250/250 [==============================] - 101s 403ms/step - loss: 6.1314 - accuracy: 0.0990\n",
            "Epoch 20/25\n",
            "250/250 [==============================] - 100s 401ms/step - loss: 2.5767 - accuracy: 0.1001\n",
            "Epoch 21/25\n",
            "250/250 [==============================] - 101s 402ms/step - loss: 2.8511 - accuracy: 0.0988\n",
            "Epoch 22/25\n",
            "250/250 [==============================] - 101s 402ms/step - loss: 3.6231 - accuracy: 0.0996\n",
            "Epoch 23/25\n",
            "250/250 [==============================] - 102s 410ms/step - loss: 7.8627 - accuracy: 0.0980\n",
            "Epoch 24/25\n",
            "250/250 [==============================] - 100s 400ms/step - loss: 2.5837 - accuracy: 0.1006\n",
            "Epoch 25/25\n",
            "250/250 [==============================] - 100s 400ms/step - loss: 3.4135 - accuracy: 0.0997\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 8.2641 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 97s 970ms/step - loss: 8.8543 - accuracy: 0.1013\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 95s 951ms/step - loss: 2.3884 - accuracy: 0.1015\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 95s 948ms/step - loss: 3.1681 - accuracy: 0.0989\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 95s 951ms/step - loss: 8.7211 - accuracy: 0.1020\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 95s 947ms/step - loss: 2.5090 - accuracy: 0.1002\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 95s 946ms/step - loss: 2.4059 - accuracy: 0.0985\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 95s 950ms/step - loss: 2.4207 - accuracy: 0.1006\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 96s 957ms/step - loss: 2.4844 - accuracy: 0.0993\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 95s 945ms/step - loss: 9.8291 - accuracy: 0.0995\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 95s 946ms/step - loss: 8.0185 - accuracy: 0.0984\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 96s 955ms/step - loss: 6.2330 - accuracy: 0.0974\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 97s 969ms/step - loss: 2.8277 - accuracy: 0.0993\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 94s 945ms/step - loss: 2.3722 - accuracy: 0.0985\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 95s 950ms/step - loss: 2.3692 - accuracy: 0.1013\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 95s 947ms/step - loss: 2.3831 - accuracy: 0.0996\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 97s 967ms/step - loss: 2.3795 - accuracy: 0.1008\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 96s 958ms/step - loss: 2.4745 - accuracy: 0.1033\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 95s 950ms/step - loss: 2.9567 - accuracy: 0.1022\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 95s 949ms/step - loss: 9.6048 - accuracy: 0.1008\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 98s 979ms/step - loss: 8.6844 - accuracy: 0.1015\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 96s 954ms/step - loss: 6.4582 - accuracy: 0.1002\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 95s 948ms/step - loss: 2.9020 - accuracy: 0.1001\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 95s 949ms/step - loss: 2.3959 - accuracy: 0.0999\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 95s 949ms/step - loss: 2.3682 - accuracy: 0.0973\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 95s 946ms/step - loss: 2.4122 - accuracy: 0.0974\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 8.2641 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "72/72 [==============================] - 96s 1s/step - loss: 7.6657 - accuracy: 0.1017\n",
            "Epoch 2/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 2.3698 - accuracy: 0.1000\n",
            "Epoch 3/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 2.4972 - accuracy: 0.0972\n",
            "Epoch 4/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 8.8095 - accuracy: 0.0988\n",
            "Epoch 5/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 5.8510 - accuracy: 0.1008\n",
            "Epoch 6/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 2.4611 - accuracy: 0.1001\n",
            "Epoch 7/25\n",
            "72/72 [==============================] - 93s 1s/step - loss: 2.3509 - accuracy: 0.0988\n",
            "Epoch 8/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 2.3736 - accuracy: 0.1012\n",
            "Epoch 9/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 2.3742 - accuracy: 0.0984\n",
            "Epoch 10/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 2.4127 - accuracy: 0.0978\n",
            "Epoch 11/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 2.4259 - accuracy: 0.1006\n",
            "Epoch 12/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 7.8450 - accuracy: 0.0988\n",
            "Epoch 13/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 12.0702 - accuracy: 0.1000\n",
            "Epoch 14/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 7.6073 - accuracy: 0.1012\n",
            "Epoch 15/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 4.6255 - accuracy: 0.0987\n",
            "Epoch 16/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 2.8753 - accuracy: 0.1035\n",
            "Epoch 17/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 2.3605 - accuracy: 0.1017\n",
            "Epoch 18/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 2.3586 - accuracy: 0.0982\n",
            "Epoch 19/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 2.3781 - accuracy: 0.0973\n",
            "Epoch 20/25\n",
            "72/72 [==============================] - 96s 1s/step - loss: 2.3915 - accuracy: 0.1010\n",
            "Epoch 21/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 2.3670 - accuracy: 0.1009\n",
            "Epoch 22/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 2.4063 - accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 2.4033 - accuracy: 0.0986\n",
            "Epoch 24/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 2.4107 - accuracy: 0.0997\n",
            "Epoch 25/25\n",
            "72/72 [==============================] - 96s 1s/step - loss: 3.0661 - accuracy: 0.1000\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 8.2641 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 10.3823 - accuracy: 0.0993\n",
            "Epoch 2/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3962 - accuracy: 0.1004\n",
            "Epoch 3/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3640 - accuracy: 0.0999\n",
            "Epoch 4/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3537 - accuracy: 0.1015\n",
            "Epoch 5/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.4398 - accuracy: 0.1016\n",
            "Epoch 6/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 7.1376 - accuracy: 0.0995\n",
            "Epoch 7/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 9.6071 - accuracy: 0.0991\n",
            "Epoch 8/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 5.7790 - accuracy: 0.1008\n",
            "Epoch 9/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.8566 - accuracy: 0.1006\n",
            "Epoch 10/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 2.3599 - accuracy: 0.0999\n",
            "Epoch 11/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3519 - accuracy: 0.0996\n",
            "Epoch 12/25\n",
            "59/59 [==============================] - 93s 2s/step - loss: 2.3635 - accuracy: 0.1012\n",
            "Epoch 13/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3754 - accuracy: 0.1007\n",
            "Epoch 14/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3573 - accuracy: 0.0992\n",
            "Epoch 15/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3651 - accuracy: 0.1013\n",
            "Epoch 16/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.4502 - accuracy: 0.0988\n",
            "Epoch 17/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.7169 - accuracy: 0.1021\n",
            "Epoch 18/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 9.7003 - accuracy: 0.0976\n",
            "Epoch 19/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 10.2536 - accuracy: 0.0998\n",
            "Epoch 20/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 9.3774 - accuracy: 0.1020\n",
            "Epoch 21/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 3.5140 - accuracy: 0.1000\n",
            "Epoch 22/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3482 - accuracy: 0.0987\n",
            "Epoch 23/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 2.3565 - accuracy: 0.0984\n",
            "Epoch 24/25\n",
            "59/59 [==============================] - 96s 2s/step - loss: 2.3456 - accuracy: 0.1016\n",
            "Epoch 25/25\n",
            "59/59 [==============================] - 99s 2s/step - loss: 2.3357 - accuracy: 0.0998\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 8.2641 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "250/250 [==============================] - 111s 442ms/step - loss: 15.4784 - accuracy: 0.1009\n",
            "Epoch 2/25\n",
            "250/250 [==============================] - 110s 438ms/step - loss: 12.6449 - accuracy: 0.0973\n",
            "Epoch 3/25\n",
            "250/250 [==============================] - 101s 404ms/step - loss: 12.4303 - accuracy: 0.0975\n",
            "Epoch 4/25\n",
            "250/250 [==============================] - 101s 403ms/step - loss: 11.2919 - accuracy: 0.0978\n",
            "Epoch 5/25\n",
            "250/250 [==============================] - 101s 405ms/step - loss: 11.4913 - accuracy: 0.0991\n",
            "Epoch 6/25\n",
            "250/250 [==============================] - 101s 404ms/step - loss: 10.5310 - accuracy: 0.0997\n",
            "Epoch 7/25\n",
            "250/250 [==============================] - 101s 404ms/step - loss: 10.0979 - accuracy: 0.0991\n",
            "Epoch 8/25\n",
            "250/250 [==============================] - 102s 408ms/step - loss: 13.0103 - accuracy: 0.1030\n",
            "Epoch 9/25\n",
            "250/250 [==============================] - 101s 402ms/step - loss: 12.0154 - accuracy: 0.1010\n",
            "Epoch 10/25\n",
            "250/250 [==============================] - 101s 404ms/step - loss: 12.1181 - accuracy: 0.0986\n",
            "Epoch 11/25\n",
            "250/250 [==============================] - 102s 407ms/step - loss: 11.9093 - accuracy: 0.1018\n",
            "Epoch 12/25\n",
            "250/250 [==============================] - 103s 412ms/step - loss: 11.0958 - accuracy: 0.1021\n",
            "Epoch 13/25\n",
            "250/250 [==============================] - 101s 405ms/step - loss: 12.4868 - accuracy: 0.1001\n",
            "Epoch 14/25\n",
            "250/250 [==============================] - 101s 404ms/step - loss: 12.7606 - accuracy: 0.0995\n",
            "Epoch 15/25\n",
            "250/250 [==============================] - 101s 406ms/step - loss: 10.5361 - accuracy: 0.0997\n",
            "Epoch 16/25\n",
            "250/250 [==============================] - 101s 403ms/step - loss: 11.6547 - accuracy: 0.0999\n",
            "Epoch 17/25\n",
            "250/250 [==============================] - 101s 404ms/step - loss: 11.4857 - accuracy: 0.0992\n",
            "Epoch 18/25\n",
            "250/250 [==============================] - 100s 399ms/step - loss: 10.5393 - accuracy: 0.0985\n",
            "Epoch 19/25\n",
            "250/250 [==============================] - 101s 404ms/step - loss: 11.4813 - accuracy: 0.0986\n",
            "Epoch 20/25\n",
            "250/250 [==============================] - 102s 406ms/step - loss: 11.8280 - accuracy: 0.1003\n",
            "Epoch 21/25\n",
            "250/250 [==============================] - 101s 404ms/step - loss: 11.4029 - accuracy: 0.0994\n",
            "Epoch 22/25\n",
            "250/250 [==============================] - 103s 413ms/step - loss: 11.6590 - accuracy: 0.0995\n",
            "Epoch 23/25\n",
            "250/250 [==============================] - 102s 409ms/step - loss: 12.9335 - accuracy: 0.1019\n",
            "Epoch 24/25\n",
            "250/250 [==============================] - 101s 405ms/step - loss: 12.2261 - accuracy: 0.1011\n",
            "Epoch 25/25\n",
            "250/250 [==============================] - 101s 405ms/step - loss: 10.9827 - accuracy: 0.1008\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 8.2641 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 97s 967ms/step - loss: 24.5603 - accuracy: 0.1007\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 96s 957ms/step - loss: 9.9670 - accuracy: 0.0997\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 95s 951ms/step - loss: 11.8941 - accuracy: 0.1005\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 96s 960ms/step - loss: 10.3691 - accuracy: 0.1001\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 96s 958ms/step - loss: 12.0728 - accuracy: 0.0994\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 96s 956ms/step - loss: 13.9070 - accuracy: 0.0964\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 95s 952ms/step - loss: 11.0126 - accuracy: 0.0964\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 95s 949ms/step - loss: 11.1011 - accuracy: 0.0988\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 95s 950ms/step - loss: 10.0708 - accuracy: 0.0985\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 97s 966ms/step - loss: 11.7663 - accuracy: 0.0996\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 96s 956ms/step - loss: 11.5622 - accuracy: 0.1001\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 96s 955ms/step - loss: 11.5131 - accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 96s 955ms/step - loss: 11.5737 - accuracy: 0.1000\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 95s 952ms/step - loss: 11.9757 - accuracy: 0.0999\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 95s 949ms/step - loss: 13.1495 - accuracy: 0.1004\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 95s 951ms/step - loss: 12.3634 - accuracy: 0.1010\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 96s 958ms/step - loss: 10.4039 - accuracy: 0.0978\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 95s 954ms/step - loss: 13.5269 - accuracy: 0.1000\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 98s 978ms/step - loss: 12.0655 - accuracy: 0.0991\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 97s 967ms/step - loss: 10.5499 - accuracy: 0.0963\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 95s 948ms/step - loss: 13.8810 - accuracy: 0.1000\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 96s 963ms/step - loss: 13.0890 - accuracy: 0.1008\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 95s 952ms/step - loss: 12.2749 - accuracy: 0.0991\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 96s 960ms/step - loss: 12.9545 - accuracy: 0.0991\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 95s 953ms/step - loss: 10.5824 - accuracy: 0.0991\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 8.2641 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "72/72 [==============================] - 96s 1s/step - loss: 22.7597 - accuracy: 0.0996\n",
            "Epoch 2/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 11.9534 - accuracy: 0.0994\n",
            "Epoch 3/25\n",
            "72/72 [==============================] - 97s 1s/step - loss: 9.8209 - accuracy: 0.0988\n",
            "Epoch 4/25\n",
            "72/72 [==============================] - 96s 1s/step - loss: 10.6292 - accuracy: 0.0996\n",
            "Epoch 5/25\n",
            "72/72 [==============================] - 96s 1s/step - loss: 10.8934 - accuracy: 0.0993\n",
            "Epoch 6/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 9.4708 - accuracy: 0.1008\n",
            "Epoch 7/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 12.5314 - accuracy: 0.1005\n",
            "Epoch 8/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 12.9143 - accuracy: 0.1020\n",
            "Epoch 9/25\n",
            "72/72 [==============================] - 96s 1s/step - loss: 12.9257 - accuracy: 0.1027\n",
            "Epoch 10/25\n",
            "72/72 [==============================] - 94s 1s/step - loss: 11.2987 - accuracy: 0.0977\n",
            "Epoch 11/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 10.1130 - accuracy: 0.0989\n",
            "Epoch 12/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 12.7778 - accuracy: 0.1003\n",
            "Epoch 13/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 11.4154 - accuracy: 0.1017\n",
            "Epoch 14/25\n",
            "72/72 [==============================] - 96s 1s/step - loss: 13.6498 - accuracy: 0.0981\n",
            "Epoch 15/25\n",
            "72/72 [==============================] - 93s 1s/step - loss: 12.1132 - accuracy: 0.1002\n",
            "Epoch 16/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 10.0490 - accuracy: 0.0971\n",
            "Epoch 17/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 11.6823 - accuracy: 0.0974\n",
            "Epoch 18/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 13.1581 - accuracy: 0.1013\n",
            "Epoch 19/25\n",
            "72/72 [==============================] - 96s 1s/step - loss: 12.4526 - accuracy: 0.1018\n",
            "Epoch 20/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 13.6821 - accuracy: 0.0992\n",
            "Epoch 21/25\n",
            "72/72 [==============================] - 95s 1s/step - loss: 11.9152 - accuracy: 0.0994\n",
            "Epoch 22/25\n",
            "72/72 [==============================] - 97s 1s/step - loss: 11.4033 - accuracy: 0.0979\n",
            "Epoch 23/25\n",
            "72/72 [==============================] - 99s 1s/step - loss: 9.7889 - accuracy: 0.0998\n",
            "Epoch 24/25\n",
            "72/72 [==============================] - 100s 1s/step - loss: 12.4258 - accuracy: 0.0989\n",
            "Epoch 25/25\n",
            "72/72 [==============================] - 98s 1s/step - loss: 14.2445 - accuracy: 0.0986\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 8.2641 - accuracy: 0.1000\n",
            "Epoch 1/25\n",
            "59/59 [==============================] - 97s 2s/step - loss: 33.8742 - accuracy: 0.1001\n",
            "Epoch 2/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 9.7630 - accuracy: 0.1000\n",
            "Epoch 3/25\n",
            "59/59 [==============================] - 96s 2s/step - loss: 12.3739 - accuracy: 0.0992\n",
            "Epoch 4/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 13.2781 - accuracy: 0.1003\n",
            "Epoch 5/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 11.2161 - accuracy: 0.1017\n",
            "Epoch 6/25\n",
            "59/59 [==============================] - 97s 2s/step - loss: 10.7280 - accuracy: 0.1014\n",
            "Epoch 7/25\n",
            "59/59 [==============================] - 97s 2s/step - loss: 10.1464 - accuracy: 0.1009\n",
            "Epoch 8/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 11.9784 - accuracy: 0.0996\n",
            "Epoch 9/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 12.8129 - accuracy: 0.1015\n",
            "Epoch 10/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 9.5635 - accuracy: 0.0998\n",
            "Epoch 11/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 11.9050 - accuracy: 0.0980\n",
            "Epoch 12/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 8.4258 - accuracy: 0.1010\n",
            "Epoch 13/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 9.5071 - accuracy: 0.1006\n",
            "Epoch 14/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 14.2074 - accuracy: 0.1001\n",
            "Epoch 15/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 12.7293 - accuracy: 0.1010\n",
            "Epoch 16/25\n",
            "59/59 [==============================] - 97s 2s/step - loss: 11.0534 - accuracy: 0.1006\n",
            "Epoch 17/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 10.2505 - accuracy: 0.0987\n",
            "Epoch 18/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 10.8520 - accuracy: 0.1013\n",
            "Epoch 19/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 8.8580 - accuracy: 0.0995\n",
            "Epoch 20/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 13.6514 - accuracy: 0.0981\n",
            "Epoch 21/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 10.8798 - accuracy: 0.0979\n",
            "Epoch 22/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 10.0924 - accuracy: 0.0999\n",
            "Epoch 23/25\n",
            "59/59 [==============================] - 96s 2s/step - loss: 10.4740 - accuracy: 0.0998\n",
            "Epoch 24/25\n",
            "59/59 [==============================] - 94s 2s/step - loss: 9.9502 - accuracy: 0.1018\n",
            "Epoch 25/25\n",
            "59/59 [==============================] - 95s 2s/step - loss: 11.9227 - accuracy: 0.0997\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 8.2641 - accuracy: 0.1000\n"
          ]
        }
      ],
      "source": [
        "scores_ffd = []\n",
        "params_ffd = []\n",
        "for i in [0.01,0.1,0.25,0.5]:\n",
        "  for j in [200,500,700,850]:\n",
        "  # lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "  #   initial_learning_rate=1e-2,\n",
        "  #   decay_steps=10000,\n",
        "  #   decay_rate=0.96)\n",
        "    feed_forward.compile(optimizer=keras.optimizers.Adam(learning_rate=i), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    feed_forward.fit(x_train_gray, y_train, epochs=25, batch_size=j, verbose=1)\n",
        "    score_ffd = model.evaluate(x_test_gray,y_test)\n",
        "    scores_ffd.append(score_ffd)\n",
        "    params_ffd.append((i,j,'Adam',scores_ffd))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsV8-KiRhRNG",
        "outputId": "e882f4cf-8f94-4d92-dcea-acbbeb88ed3a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>200</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.01</td>\n",
              "      <td>700</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.01</td>\n",
              "      <td>850</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.10</td>\n",
              "      <td>200</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.10</td>\n",
              "      <td>500</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.10</td>\n",
              "      <td>700</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.10</td>\n",
              "      <td>850</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.25</td>\n",
              "      <td>200</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.25</td>\n",
              "      <td>500</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.25</td>\n",
              "      <td>700</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.25</td>\n",
              "      <td>850</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.50</td>\n",
              "      <td>200</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.50</td>\n",
              "      <td>500</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.50</td>\n",
              "      <td>700</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.50</td>\n",
              "      <td>850</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1     2                                                  3\n",
              "0   0.01  200  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "1   0.01  500  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "2   0.01  700  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "3   0.01  850  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "4   0.10  200  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "5   0.10  500  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "6   0.10  700  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "7   0.10  850  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "8   0.25  200  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "9   0.25  500  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "10  0.25  700  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "11  0.25  850  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "12  0.50  200  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "13  0.50  500  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "14  0.50  700  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "15  0.50  850  Adam  [[8.264127731323242, 0.10000000149011612], [8...."
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ffd_df = pandas.DataFrame(params_ffd)\n",
        "ffd_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65i4QhFqr-05"
      },
      "outputs": [],
      "source": [
        "X = np.array([[[7], [5], [0], [0], [3], [2]],\n",
        "                   [[6], [4], [5], [1], [4], [8]],\n",
        "                   [[9], [0], [2], [2], [5], [4]],\n",
        "                   [[6], [3], [4], [7], [9], [8]],\n",
        "                   [[5], [7], [5], [6], [9], [0]],\n",
        "                   [[7], [9], [0], [8], [2], [3]]])\n",
        "\n",
        "f = np.array([[1, 0, -1],[2, 0, -2],[1, 0, -1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZAj1zlwtCEe",
        "outputId": "b589b67b-fe35-4663-cf84-25ad0564e7c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-l-bZkeBtG1r"
      },
      "source": [
        "Dimensions of X is 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNaXwq65tFCN",
        "outputId": "aaa2d49e-720c-4bd9-b4c5-dd4138770b3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teMe8PthtPT7"
      },
      "source": [
        "Dimensions of filter is 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8xxGtGXtNzl",
        "outputId": "1d9b52cf-1512-43f4-a013-790ca5702f81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f.shape[0] * f.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUqzGtkQtVMJ"
      },
      "source": [
        "Parameters of kernel is 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNLO0NIKxC4Q"
      },
      "source": [
        "Formula to Convolution layer C = ((n-f+2p)/s)+1 \n",
        "\n",
        "n = size of input matrix\n",
        "\n",
        "f = size of the filter\n",
        "\n",
        "p is the Padding\n",
        "\n",
        "s = Stride\n",
        "\n",
        "SO, n= 6,f =3,p=0,s =1\n",
        "\n",
        "C=((6-3+2x0)/1)+1=4\n",
        "\n",
        "Output Convolutional matrix will be of size  4 X 4.\n",
        "\n",
        "Calculating Matrix \n",
        "\n",
        "=>7*1+5*0+0*-1+6*2+4*0+5*-2+9*1+0*0+(-1)*2 =>7+0+0+12+0-10+9=28-10=18\n",
        "\n",
        "=> 5*1+0+0+4*2+0+1*-2+0+0+2*-1 =>9\n",
        "\n",
        "=> 0+0+-3+5*2+0+4*-2+2*1+0+5*-1 => -4\n",
        "\n",
        "=> 0+0+2*-1+1*2+0+8*-2+2*1+0+4*-1 => -18\n",
        "\n",
        "Similarly \n",
        "2nd row => 17,-3,10,-12\n",
        "3rd row => 11,-9,-17,2\n",
        "4rth row => 9, -1, -15, 16\n",
        "\n",
        "Entire Convolutional Matrix is\n",
        "\n",
        "\n",
        "18\t9\t-4\t-18\n",
        "17\t-3\t-10\t-12\n",
        "11\t-9\t-17\t2\n",
        "9\t-1\t-15\t16\n",
        "\n",
        "\n",
        "\n",
        "Max pooling \n",
        "\n",
        "This selects the max values of all the matrix in each filter which is 3 X 3 with stride 1 from the convolutional matrix above\n",
        "\n",
        "max(18,9,-4,17,-3,-10,11,-9,-17)=18\n",
        "max(9,-4,-18,-3,-10,-12,-9,-17,2) = 9\n",
        "max(17,-3,-10,11,-9,-17,9,-1,-15) = 17\n",
        "max(9-3,-10,-12,-9,-17,2,-1,-15,16) = 16\n",
        "\n",
        "Hence the final Max pooling matrix is \n",
        "18\t9\n",
        "17\t16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Spj6mbM-hRNJ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-EtQwcJhRNJ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz7LdaD-hRNK"
      },
      "source": [
        "**Question 1**\n",
        "\n",
        "\n",
        "I have created dataframes of all the learning rates and batch sizes for every cnn netwrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9unPWzshRNK"
      },
      "source": [
        "Evaluaition of CNN network with increasing filter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb1D4auUhRNK",
        "outputId": "3f5b080e-fa7e-42db-cb9a-344452f77193"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>250</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[0.05969966575503349, 0.9810000061988831]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[0.050209105014801025, 0.9861000180244446]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.01</td>\n",
              "      <td>750</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[0.048151686787605286, 0.9860000014305115]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.10</td>\n",
              "      <td>250</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.10</td>\n",
              "      <td>500</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.10</td>\n",
              "      <td>750</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.25</td>\n",
              "      <td>250</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.25</td>\n",
              "      <td>500</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.25</td>\n",
              "      <td>750</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.50</td>\n",
              "      <td>250</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.50</td>\n",
              "      <td>500</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.50</td>\n",
              "      <td>750</td>\n",
              "      <td>SGD</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1    2                                           3\n",
              "0   0.01  250  SGD   [0.05969966575503349, 0.9810000061988831]\n",
              "1   0.01  500  SGD  [0.050209105014801025, 0.9861000180244446]\n",
              "2   0.01  750  SGD  [0.048151686787605286, 0.9860000014305115]\n",
              "3   0.10  250  SGD                  [nan, 0.09799999743700027]\n",
              "4   0.10  500  SGD                  [nan, 0.09799999743700027]\n",
              "5   0.10  750  SGD                  [nan, 0.09799999743700027]\n",
              "6   0.25  250  SGD                  [nan, 0.09799999743700027]\n",
              "7   0.25  500  SGD                  [nan, 0.09799999743700027]\n",
              "8   0.25  750  SGD                  [nan, 0.09799999743700027]\n",
              "9   0.50  250  SGD                  [nan, 0.09799999743700027]\n",
              "10  0.50  500  SGD                  [nan, 0.09799999743700027]\n",
              "11  0.50  750  SGD                  [nan, 0.09799999743700027]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySVGJXqHhRNK"
      },
      "source": [
        "It is evident that with learning rate 0.01 and batch size 250 and SGD opimizers, the network perfomed well with loss of 0.596 and accuracy of 0.981.\n",
        "It is also evident that the batch size didnt effect the model untill or unless learning rate has been changed. Performance of the model is diminished as learnig rate is increased from 0.01 to 0.1,0.25,0.5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IePXCKbAhRNK"
      },
      "source": [
        "Evaluation of CNN Network with Decreasing filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PK4kQaZPhRNK",
        "outputId": "107e43d1-a1f3-487c-c449-19b556cbd496"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>250</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.01</td>\n",
              "      <td>750</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.10</td>\n",
              "      <td>250</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.10</td>\n",
              "      <td>500</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.10</td>\n",
              "      <td>750</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.25</td>\n",
              "      <td>250</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.25</td>\n",
              "      <td>500</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.25</td>\n",
              "      <td>750</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1     2                           3\n",
              "0  0.01  250  Adam  [nan, 0.09799999743700027]\n",
              "1  0.01  500  Adam  [nan, 0.09799999743700027]\n",
              "2  0.01  750  Adam  [nan, 0.09799999743700027]\n",
              "3  0.10  250  Adam  [nan, 0.09799999743700027]\n",
              "4  0.10  500  Adam  [nan, 0.09799999743700027]\n",
              "5  0.10  750  Adam  [nan, 0.09799999743700027]\n",
              "6  0.25  250  Adam  [nan, 0.09799999743700027]\n",
              "7  0.25  500  Adam  [nan, 0.09799999743700027]\n",
              "8  0.25  750  Adam  [nan, 0.09799999743700027]"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decrease_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alGiWSjMhRNL"
      },
      "source": [
        "Having been used Adam as an optimizer, this decreasing filters model doesnt perform very well whose accuray is always same with different learning rates and different batch sizes.\n",
        "Its accuracy is 0.097 which is same all along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSQ4B_f9hRNL"
      },
      "source": [
        "Evaluation of Hour Glass model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFL54MOIhRNL"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngmEkv2qhRNL",
        "outputId": "376f258f-32dd-492d-f349-4f4bd7ed30d8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>250</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.01</td>\n",
              "      <td>750</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.10</td>\n",
              "      <td>250</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.10</td>\n",
              "      <td>500</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.10</td>\n",
              "      <td>750</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.25</td>\n",
              "      <td>250</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.25</td>\n",
              "      <td>500</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.25</td>\n",
              "      <td>750</td>\n",
              "      <td>RMS</td>\n",
              "      <td>[nan, 0.09799999743700027]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1    2                           3\n",
              "0  0.01  250  RMS  [nan, 0.09799999743700027]\n",
              "1  0.01  500  RMS  [nan, 0.09799999743700027]\n",
              "2  0.01  750  RMS  [nan, 0.09799999743700027]\n",
              "3  0.10  250  RMS  [nan, 0.09799999743700027]\n",
              "4  0.10  500  RMS  [nan, 0.09799999743700027]\n",
              "5  0.10  750  RMS  [nan, 0.09799999743700027]\n",
              "6  0.25  250  RMS  [nan, 0.09799999743700027]\n",
              "7  0.25  500  RMS  [nan, 0.09799999743700027]\n",
              "8  0.25  750  RMS  [nan, 0.09799999743700027]"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hourglass_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glFME5n6hRNL"
      },
      "source": [
        "Hourglass model with RMSprop as an optimizer performed very low as same as Adam optimizer in the decreasing filter model. Batch size and filter size seemed no effect on the the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NEmsOBhhRNL"
      },
      "source": [
        "**Question 2** \n",
        "\n",
        "\n",
        "For Question 2 I have created a model with 4 learning rates\n",
        "\n",
        "[0.01,0.1,0.25,0.5]\n",
        "\n",
        "and also with 4 different bacth sizes of [250,500,750,800]\n",
        "with both Adam and SGD as optimizers\n",
        "\n",
        "I have chosen 'Tanh' Activation function for the convolutional layers and 'softmax' at the output layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rt51K1zhRNL"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUx8elDihRNL",
        "outputId": "394fbc8e-e159-442b-a344-512b071f5b0b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>200</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.01</td>\n",
              "      <td>700</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.01</td>\n",
              "      <td>850</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.10</td>\n",
              "      <td>200</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.10</td>\n",
              "      <td>500</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.10</td>\n",
              "      <td>700</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.10</td>\n",
              "      <td>850</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.25</td>\n",
              "      <td>200</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.25</td>\n",
              "      <td>500</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.25</td>\n",
              "      <td>700</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.25</td>\n",
              "      <td>850</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.50</td>\n",
              "      <td>200</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.50</td>\n",
              "      <td>500</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.50</td>\n",
              "      <td>700</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.50</td>\n",
              "      <td>850</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>Adam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.01</td>\n",
              "      <td>200</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.01</td>\n",
              "      <td>700</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.01</td>\n",
              "      <td>850</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.10</td>\n",
              "      <td>200</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.10</td>\n",
              "      <td>500</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.10</td>\n",
              "      <td>700</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.10</td>\n",
              "      <td>850</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.25</td>\n",
              "      <td>200</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.25</td>\n",
              "      <td>500</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.25</td>\n",
              "      <td>700</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.25</td>\n",
              "      <td>850</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.50</td>\n",
              "      <td>200</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.50</td>\n",
              "      <td>500</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.50</td>\n",
              "      <td>700</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.50</td>\n",
              "      <td>850</td>\n",
              "      <td>[[1.3703720569610596, 0.5403000116348267], [1....</td>\n",
              "      <td>SGD</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1                                                  2     3\n",
              "0   0.01  200  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "1   0.01  500  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "2   0.01  700  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "3   0.01  850  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "4   0.10  200  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "5   0.10  500  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "6   0.10  700  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "7   0.10  850  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "8   0.25  200  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "9   0.25  500  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "10  0.25  700  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "11  0.25  850  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "12  0.50  200  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "13  0.50  500  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "14  0.50  700  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "15  0.50  850  [[1.3703720569610596, 0.5403000116348267], [1....  Adam\n",
              "16  0.01  200  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "17  0.01  500  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "18  0.01  700  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "19  0.01  850  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "20  0.10  200  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "21  0.10  500  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "22  0.10  700  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "23  0.10  850  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "24  0.25  200  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "25  0.25  500  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "26  0.25  700  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "27  0.25  850  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "28  0.50  200  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "29  0.50  500  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "30  0.50  700  [[1.3703720569610596, 0.5403000116348267], [1....   SGD\n",
              "31  0.50  850  [[1.3703720569610596, 0.5403000116348267], [1....   SGD"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql1sBLkBhRNL"
      },
      "source": [
        "For the question to take Adam as an optimizer and with epoch size of 25, the performance decreased as the learning rate and batch size is increaed. The best accuracy of the model is 0.54 for the leanring rate 0.01 with different batch sizes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHQtQtLChRNM"
      },
      "source": [
        "For the hyperparameter tuning I have chooses epoch size as 75 and with same learning rates and batch sizes, but the optimizer is SGD.\n",
        "Both the performance of Adam and SGD are almost same with all the learning rate and batch sizes. Accuracy remained same all the way through the evalution with these parameters which is 0.54"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C_UYCeUhRNM"
      },
      "source": [
        "Feed forward Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q8ukze5hRNN",
        "outputId": "869b1a4e-aaa0-4d2e-fd01-e63db588ac86"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>200</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.01</td>\n",
              "      <td>500</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.01</td>\n",
              "      <td>700</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.01</td>\n",
              "      <td>850</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.10</td>\n",
              "      <td>200</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.10</td>\n",
              "      <td>500</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.10</td>\n",
              "      <td>700</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.10</td>\n",
              "      <td>850</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.25</td>\n",
              "      <td>200</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.25</td>\n",
              "      <td>500</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.25</td>\n",
              "      <td>700</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.25</td>\n",
              "      <td>850</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.50</td>\n",
              "      <td>200</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.50</td>\n",
              "      <td>500</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.50</td>\n",
              "      <td>700</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.50</td>\n",
              "      <td>850</td>\n",
              "      <td>Adam</td>\n",
              "      <td>[[8.264127731323242, 0.10000000149011612], [8....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1     2                                                  3\n",
              "0   0.01  200  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "1   0.01  500  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "2   0.01  700  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "3   0.01  850  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "4   0.10  200  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "5   0.10  500  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "6   0.10  700  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "7   0.10  850  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "8   0.25  200  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "9   0.25  500  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "10  0.25  700  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "11  0.25  850  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "12  0.50  200  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "13  0.50  500  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "14  0.50  700  Adam  [[8.264127731323242, 0.10000000149011612], [8....\n",
              "15  0.50  850  Adam  [[8.264127731323242, 0.10000000149011612], [8...."
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ffd_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9nbOvAChRNN"
      },
      "source": [
        "For the Feed Forward Neural Network of same filters through out the model, I have chosen 'Tanh' for the convo2d layers and 'softmax' at the output layer with the same learning rate [0.01,0.1,0.25,0.50] and batch sizes of [200,500,700,800] and optimizer 'Adam'. The performance of this model, is not the best when compared to the LeNEt model. This models accuracy is just 0.1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "d751d0f1e09f4c1c89108cd8ca17b8d6b2fbc92b17fdc28381b858678eee3b2a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}